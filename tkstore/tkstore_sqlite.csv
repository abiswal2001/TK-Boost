mem_id,instance_id,scope,sql_operations,table,column,data_type,nulls,rule
0,sf001,db,cte_definition;inner join,weather_data,weather_data.DATE_VALID_STD,date,all,VERIFY: The query must include a WITH timestamps CTE that defines the seven specific DATE_VALID_STD values and then NATURAL INNER JOIN to timestamps on DATE_VALID_STD | CONTEXT: The weather_data table contains a DATE_VALID_STD column representing measurement dates; joining to a timestamps CTE ensures only the seven target week dates are returned rather than relying on hard-coded ranges | WHEN_TO_CHECK: When filtering for the latest seven days of data based on DATE_VALID_STD | EXAMPLE_USAGE: Correct: WITH timestamps AS ( SELECT DATE '2024-06-01' AS DATE_VALID_STD UNION ALL SELECT DATE '2024-06-02' UNION ALL … UNION ALL SELECT DATE '2024-06-07' SELECT wd.* FROM weather_data wd NATURAL JOIN timestamps; Incorrect: SELECT * FROM weather_data WHERE DATE_VALID_STD BETWEEN '2024-06-01' AND '2024-06-07';
1,sf001,db,filter,weather_data,weather_data.snowfall,numeric,all,VERIFY: The snowfall filter must use the decimal literal > 6.0 instead of > 6 to match the snowfall column’s precision | CONTEXT: The snowfall column is defined as a decimal; using > 6.0 prevents implicit type conversion and ensures the comparison aligns with the column’s scale | WHEN_TO_CHECK: When applying thresholds to the snowfall column | EXAMPLE_USAGE: Correct: SELECT * FROM weather_data WHERE snowfall > 6.0; Incorrect: SELECT * FROM weather_data WHERE snowfall > 6;
2,sf001,generic,cte_definition;join;filter,all,all,all,all,"VERIFY: Filters for rolling or shifting time windows should be implemented by generating date lists in a CTE and joining against the main table | PRINCIPLE: Joining on a set of dates produced dynamically ensures queries automatically adapt to changing data windows without manual date updates | WHEN_TO_APPLY: Whenever filtering data over the last N days/weeks instead of using fixed date literals | EXAMPLE_USAGE: Correct: WITH dates AS ( SELECT CURRENT_DATE - INTERVAL seq DAY AS dt FROM generate_series(0,6) AS seq SELECT mt.* FROM main_table mt JOIN dates d ON mt.date_col = d.dt; Incorrect: SELECT * FROM main_table WHERE date_col BETWEEN '2024-06-01' AND '2024-06-07';"
3,sf001,generic,filter,all,all,numeric,all,VERIFY: Numeric comparisons should use literals matching the column’s data type (integer vs. decimal) to avoid unintended type coercion | PRINCIPLE: Consistent literal types prevent implicit casts and rounding differences | WHEN_TO_APPLY: When filtering numeric columns by threshold values | EXAMPLE_USAGE: Correct: SELECT * FROM sales WHERE amount > 100.00; Incorrect: SELECT * FROM sales WHERE amount > 100
4,sf001,question,NA,NA,NA,NA,NA,The original query’s hardcoded date range returned no data; adding the timestamps CTE and joining on DATE_VALID_STD replicates the GOLD SQL’s dynamic week calculation and restores the correct rows.
5,sf_bq012,db,filter,traces,traces.call_type,str,Yes,"VERIFY: filtered_traces CTE uses a negative filter on call_type (NOT IN ('delegatecall','callcode','staticcall') OR call_type IS NULL) instead of restricting to call_type = 'call' | CONTEXT: The filtered_traces CTE extracts call traces from the traces table; using call_type = 'call' excludes valid call events (e.g., where call_type is NULL or other acceptable types) leading to missing data | WHEN_TO_CHECK: When defining the filtered_traces CTE to capture all relevant call events | EXAMPLE_USAGE: Incorrect: WITH filtered_traces AS ( SELECT * FROM traces WHERE block_number >= 0 AND call_type = 'call' Correct: WITH filtered_traces AS ( SELECT * FROM traces WHERE block_number >= 0 AND (call_type NOT IN ('delegatecall','callcode','staticcall') OR call_type IS NULL)"
6,sf_bq012,db,filter,transactions,transactions.receipt_status,bool,Yes,"VERIFY: gas_deductions CTE does not include any receipt_status filter | CONTEXT: The gas_deductions CTE calculates gas fees by joining filtered_traces with transactions; filtering on receipt_status (IS NULL OR =1) would omit gas fees for transactions with other statuses, undercounting total gas usage | WHEN_TO_CHECK: When building the gas_deductions CTE for fee aggregation | EXAMPLE_USAGE: Incorrect: gas_deductions AS ( SELECT tx.hash, tx.block_number, t.gas_used FROM transactions tx JOIN filtered_traces t ON tx.hash = t.transaction_hash WHERE (tx.receipt_status IS NULL OR tx.receipt_status = 1) Correct: gas_deductions AS ( SELECT tx.hash, tx.block_number, t.gas_used FROM transactions tx JOIN filtered_traces t ON tx.hash = t.transaction_hash"
7,sf_bq012,db,filter,filtered_traces,filtered_traces.receipt_status,bool,Yes,"VERIFY: miner_rewards CTE does not filter on t.receipt_status | CONTEXT: The miner_rewards CTE aggregates miner payouts by joining transactions and filtered_traces; excluding by receipt_status would drop rewards from transactions flagged as failed or pending, skewing reward totals | WHEN_TO_CHECK: When defining the miner_rewards CTE to compute miner payouts | EXAMPLE_USAGE: Incorrect: miner_rewards AS ( SELECT tx.block_number, tx.miner, t.reward FROM transactions tx JOIN filtered_traces t ON tx.hash = t.transaction_hash WHERE (t.receipt_status IS NULL OR t.receipt_status = 1) Correct: miner_rewards AS ( SELECT tx.block_number, tx.miner, t.reward FROM transactions tx JOIN filtered_traces t ON tx.hash = t.transaction_hash"
8,sf_bq012,generic,filter,all,all,all,Yes,"VERIFY: When filtering by an enumerated or categorical column, use NOT IN to exclude only specific values and explicitly allow NULLs rather than equalities that drop unexpected types | PRINCIPLE: Equality filters on categorical columns can unintentionally omit valid or new categories (including NULL); negative filters with OR NULL ensure only designated exclusions | WHEN_TO_APPLY: Whenever selecting a subset of rows based on a type or category and you want to exclude known unwanted types but keep everything else | EXAMPLE_USAGE: Incorrect: SELECT * FROM logs WHERE log_type = 'error'; (This drops all non-'error' logs including NULLs and new categories) Correct: SELECT * FROM logs WHERE log_type NOT IN ('debug','trace') OR log_type IS NULL; (This excludes only debug/trace but retains nulls and other log types)"
9,sf_bq012,generic,filter,all,all,all,all,"VERIFY: Avoid applying status‐based filters too early when building CTEs or intermediate datasets needed for full aggregations | PRINCIPLE: Early filtering on status flags can permanently remove records required for accurate summary metrics; if some analyses need all records, either remove the filter or apply it later | WHEN_TO_APPLY: When creating CTEs or staging tables that feed into aggregations or joins where you might need both successful and unsuccessful records | EXAMPLE_USAGE: Incorrect: WITH base AS ( SELECT * FROM events WHERE status = 'active' SELECT COUNT(*) FROM base; (This excludes 'inactive' events from the base even if you later need total counts) Correct: WITH base AS ( SELECT * FROM events SELECT COUNT(*) FROM base WHERE status = 'active'; (This preserves all events in the CTE and applies the status filter at the final aggregation)"
10,sf_bq012,question,NA,NA,NA,NA,NA,"The original query restricted traces to only call_type='call' and excluded transactions with non-successful receipt_status, omitting valid transfers and gas fees; loosening the call_type filter and removing receipt_status filters restores the full dataset and yields the correct average."
11,sf018,db,filter,shared_open_hour,shared_open_hour.TIME,numeric,all,"VERIFY: The shared_open_hour CTE WHERE clause filters on the numeric ""TIME"" column instead of the timestamp ""SF_CREATED_AT"" | CONTEXT: shared_open_hour CTE defines hourly event buckets using epoch seconds stored in TIME; comparing SF_CREATED_AT (a timestamp) to numeric epoch literals returns incorrect row counts | WHEN_TO_CHECK: When applying epoch-based range filters inside the shared_open_hour CTE’s WHERE clause | EXAMPLE_USAGE: Incorrect: WITH shared_open_hour AS ( … WHERE SF_CREATED_AT BETWEEN 1622505600 AND 1622591999 Correct: WITH shared_open_hour AS ( … WHERE TIME BETWEEN 1622505600 AND 1622591999"
12,sf018,generic,filter,all,all,all,all,"VERIFY: Numeric range filters must compare against columns of matching numeric types rather than timestamp or date types | PRINCIPLE: Mismatched data types in BETWEEN or range comparisons can cause implicit conversions or no rows to match, leading to wrong result counts | WHEN_TO_APPLY: Whenever filtering by epoch or numeric intervals across any table | EXAMPLE_USAGE: For a table with 'created_timestamp' (TIMESTAMP) and 'created_epoch' (INTEGER): Incorrect: SELECT * FROM logs WHERE created_timestamp BETWEEN 1609459200 AND 1609545599; Correct: SELECT * FROM logs WHERE created_epoch BETWEEN 1609459200 AND 1609545599;"
13,sf018,question,NA,NA,NA,NA,NA,"Fixed shared_open_hour filter to use the numeric ""TIME"" column (epoch seconds) instead of the timestamp column, restoring correct counts."
14,sf_bq043,db,cte_definition,TCGA.TCGA_VERSIONED.SOMATIC_MUTATION_HG19_DCC_2017_02,gene,str,all,VERIFY: The cdkn2a_mutated_cases CTE uses SOMATIC_MUTATION_HG19_DCC_2017_02 instead of SOMATIC_MUTATION_HG19_MC3_2017_02 | CONTEXT: The cdkn2a_mutated_cases CTE pulls mutation records from the versioned somatic mutation tables; using the DCC table ensures the filtered cases match the expected mutated-sample list and align with the GOLD output | WHEN_TO_CHECK: When defining or reviewing the cdkn2a_mutated_cases CTE in the query | EXAMPLE_USAGE:
15,sf_bq043,generic,all,all,all,all,all,"VERIFY: Use the intended table version when multiple snapshots exist | PRINCIPLE: When datasets are published in multiple versions or pipeline outputs, referencing the correct version is critical to maintain data consistency and match expected results | WHEN_TO_APPLY: Whenever there are two or more tables representing different versions or pipeline releases of the same data domain | EXAMPLE_USAGE:"
16,sf_bq043,generic,cte_definition,all,all,all,all,"VERIFY: Validate every CTE’s source reference against the expected schema | PRINCIPLE: Mistakes in early-stage CTE source tables propagate through downstream logic, causing missing or extra rows in final outputs | WHEN_TO_APPLY: During query review or debugging when the final result set deviates from the expected | EXAMPLE_USAGE:"
17,sf_bq043,question,NA,NA,NA,NA,NA,The core issue was using the MC3 mutation table; switching to the DCC version aligned the mutation filter with the GOLD SQL and produced the exact expected two rows.
18,sf_bq068,db,flatten,CRYPTO.CRYPTO_BITCOIN_CASH.TRANSACTIONS,CRYPTO.CRYPTO_BITCOIN_CASH.TRANSACTIONS.inputs,all,all,"VERIFY: Use LATERAL FLATTEN on CRYPTO.CRYPTO_BITCOIN_CASH.TRANSACTIONS t to expand t.""inputs"" and t.""outputs"" arrays instead of querying INPUTS or OUTPUTS tables | CONTEXT: The TRANSACTIONS table contains nested VARIANT arrays ""inputs"" and ""outputs""; separate INPUTS/OUTPUTS tables return no rows | WHEN_TO_CHECK: When extracting debit and credit entries for each transaction | EXAMPLE_USAGE:"
19,sf_bq068,db,all,all,all,str,all,"VERIFY: Convert flattened alias.value:addresses array to a comma-separated string with ARRAY_TO_STRING(alias.value:addresses, ',') | CONTEXT: The variant field value:addresses is an array of addresses and must be a string for grouping and joins | WHEN_TO_CHECK: When selecting or grouping by address in address_balances CTE | EXAMPLE_USAGE:"
20,sf_bq068,db,cast,all,all,all,all,"VERIFY: Extract the TYPE and VALUE from variant fields by casting alias.value:type::STRING and alias.value:value::NUMBER, and negate inputs values | CONTEXT: JSON VARIANT fields need explicit casting and input amounts should be negative to reflect debits | WHEN_TO_CHECK: In the double_entry_book CTE when computing account movements | EXAMPLE_USAGE:"
21,sf_bq068,db,timestamp,CRYPTO.CRYPTO_BITCOIN_CASH.TRANSACTIONS,CRYPTO.CRYPTO_BITCOIN_CASH.TRANSACTIONS.block_timestamp,date,all,"VERIFY: Apply TO_TIMESTAMP(t.""block_timestamp""/1000000) for date filtering rather than comparing raw block_timestamp | CONTEXT: block_timestamp is stored in microseconds; dividing by 1e6 and wrapping in TO_TIMESTAMP produces a proper TIMESTAMP | WHEN_TO_CHECK: In the WHERE clause restricting to March 2014 transactions | EXAMPLE_USAGE:"
22,sf_bq068,generic,flatten,all,all,all,all,"VERIFY: Use LATERAL FLATTEN to expand nested arrays in JSON/VARIANT columns into separate rows | PRINCIPLE: Flattening nested arrays is necessary for individual row access, aggregation, and joins | WHEN_TO_APPLY: Whenever a column contains a JSON/VARIANT array you need to query element-level data | EXAMPLE_USAGE:"
23,sf_bq068,generic,cast,all,all,all,all,"VERIFY: Always cast extracted JSON/VARIANT values to the appropriate SQL types before performing calculations or grouping | PRINCIPLE: JSON/VARIANT data is typeless and must be converted to NUMBER or STRING for arithmetic or string operations | WHEN_TO_APPLY: When using JSON-extracted fields in WHERE, SELECT, JOIN, or aggregation clauses | EXAMPLE_USAGE:"
24,sf_bq068,generic,timestamp,all,all,date,all,VERIFY: Convert integer epoch timestamps to TIMESTAMP using division and to_timestamp functions before date comparisons | PRINCIPLE: Numeric timestamps often represent epochs in milliseconds or microseconds and must be scaled to seconds for SQL timestamp functions | WHEN_TO_APPLY: When filtering or computing on date ranges from numeric timestamp columns | EXAMPLE_USAGE:
25,sf_bq068,question,NA,NA,NA,NA,NA,"The original query used separate INPUTS/OUTPUTS tables and raw block_timestamp strings, yielding no data. Switching to flattening the VARIANT inputs/outputs arrays from TRANSACTIONS with TO_TIMESTAMP conversion corrected the data source and time filter, producing the expected balances."
26,sf_bq072,db,aggregation;group by,deaths,all,all,all,"VERIFY: Use SUM(CASE WHEN ""cause_type"" = 'vehicle' THEN 1 ELSE 0 END) AS ""Vehicle_Total"", SUM(CASE WHEN ""cause_type"" = 'vehicle' THEN ""is_black"" ELSE 0 END) AS ""Vehicle_Black"", SUM(CASE WHEN ""cause_type"" = 'firearm' THEN 1 ELSE 0 END) AS ""Gun_Total"", and SUM(CASE WHEN ""cause_type"" = 'firearm' THEN ""is_black"" ELSE 0 END) AS ""Gun_Black"" instead of COUNT(*) and SUM(""is_black"") grouped by both ""Age"" and ""cause_type"" | CONTEXT: The source table contains columns ""Age"", ""cause_type"", and ""is_black""; pivoting by cause_type ensures a single row per Age with separate counts for vehicle and firearm events | WHEN_TO_CHECK: When aggregating death counts and black-death sums by age across cause types | EXAMPLE_USAGE: Incorrect: SELECT ""Age"", ""cause_type"", COUNT(*) AS total_deaths, SUM(""is_black"") AS black_deaths FROM deaths GROUP BY ""Age"",""cause_type""; Correct: SELECT ""Age"", SUM(CASE WHEN ""cause_type"" = 'vehicle' THEN 1 ELSE 0 END) AS Vehicle_Total, SUM(CASE WHEN ""cause_type"" = 'vehicle' THEN ""is_black"" ELSE 0 END) AS Vehicle_Black, SUM(CASE WHEN ""cause_type"" = 'firearm' THEN 1 ELSE 0 END) AS Gun_Total, SUM(CASE WHEN ""cause_type"" = 'firearm' THEN ""is_black"" ELSE 0 END) AS Gun_Black FROM deaths GROUP BY ""Age"";"
27,sf_bq072,db,aggregation;group by,deaths,deaths.cause_type,str,all,"VERIFY: Ensure GROUP BY clause includes only ""Age"" when using pivoted SUM(CASE WHEN ...) aggregates on ""cause_type"" | CONTEXT: After moving cause_type into conditional aggregates, grouping by it would recreate multiple rows per age and invalidate the pivot | WHEN_TO_CHECK: When the SELECT list uses multiple SUM(CASE WHEN ""cause_type"" …) columns and no longer selects cause_type directly | EXAMPLE_USAGE: Incorrect: SELECT ""Age"", SUM(CASE WHEN ""cause_type""='vehicle' THEN 1 ELSE 0 END) AS Vehicle_Total FROM deaths GROUP BY ""Age"",""cause_type""; Correct: SELECT ""Age"", SUM(CASE WHEN ""cause_type""='vehicle' THEN 1 ELSE 0 END) AS Vehicle_Total FROM deaths GROUP BY ""Age"";"
28,sf_bq072,db,order by,deaths,deaths.cause_type,str,all,"VERIFY: Order results by ""Age"" only, not by ""cause_type"", when pivoting cause_type into columns | CONTEXT: The pivot removes cause_type from the result set and grouping, so ordering by it is invalid or yields unpredictable sorting | WHEN_TO_CHECK: After replacing grouping by cause_type with conditional SUM(CASE WHEN ...) columns | EXAMPLE_USAGE: Incorrect: SELECT ""Age"", SUM(...) AS Vehicle_Total, SUM(...) AS Gun_Total FROM deaths GROUP BY ""Age"" ORDER BY ""Age"", ""cause_type""; Correct: SELECT ""Age"", SUM(...) AS Vehicle_Total, SUM(...) AS Gun_Total FROM deaths GROUP BY ""Age"" ORDER BY ""Age"" ASC;"
29,sf_bq072,generic,aggregation,all,all,all,all,"VERIFY: Use conditional aggregation to pivot categories into separate columns | PRINCIPLE: When you need one row per key with multiple category-specific metrics, apply SUM(CASE WHEN category = value THEN measure ELSE 0 END) instead of grouping by the category | WHEN_TO_APPLY: Whenever you want to transform rows for different category values into columns on a single row per grouping key | EXAMPLE_USAGE: Incorrect: SELECT key, category, COUNT(*) FROM sales GROUP BY key, category; Correct: SELECT key, SUM(CASE WHEN category = 'online' THEN 1 ELSE 0 END) AS online_sales, SUM(CASE WHEN category = 'retail' THEN 1 ELSE 0 END) AS retail_sales FROM sales GROUP BY key;"
30,sf_bq072,generic,aggregation;group by,all,all,all,all,"VERIFY: Remove pivoted categorical columns from GROUP BY when using CASE-based aggregates | PRINCIPLE: Once a column’s values are handled via conditional aggregation, that column no longer drives row-level grouping and should be excluded from GROUP BY to prevent extra rows | WHEN_TO_APPLY: After converting grouped-by categories into SUM(CASE WHEN…) expressions | EXAMPLE_USAGE: Original: SELECT date, type, COUNT(*) FROM events GROUP BY date, type; Pivoted: SELECT date, SUM(CASE WHEN type='A' THEN 1 ELSE 0 END) AS A_count FROM events GROUP BY date;"
31,sf_bq072,generic,order by,all,all,all,all,"VERIFY: Align ORDER BY with the revised SELECT and GROUP BY lists | PRINCIPLE: Sorting should only reference columns present in the final output; removing or pivoting columns requires updating ORDER BY to avoid referencing nonexistent or extraneous fields | WHEN_TO_APPLY: Every time SELECT or GROUP BY clauses change, especially when pivoting or dropping columns | EXAMPLE_USAGE: Before change: SELECT id, type, COUNT(*) FROM logs GROUP BY id, type ORDER BY id, type; After change: SELECT id, SUM(CASE WHEN type='error' THEN 1 ELSE 0 END) AS error_count FROM logs GROUP BY id ORDER BY id;"
32,sf_bq072,question,NA,NA,NA,NA,NA,Pivoted the cause_type aggregation into separate columns and removed grouping and ordering by cause_type to match the GOLD output format.
33,sf_bq083,db,cast;aggregation;group by;order by,CRYPTO.CRYPTO_ETHEREUM.TRANSACTIONS,CRYPTO.CRYPTO_ETHEREUM.TRANSACTIONS.block_timestamp,int,all,"VERIFY: Consistent conversion of block_timestamp (in microseconds) to date using TO_DATE(TO_TIMESTAMP_NTZ(block_timestamp/1000000)) | CONTEXT: The CRYPTO.CRYPTO_ETHEREUM.TRANSACTIONS table stores block_timestamp as microseconds; converting it to a DATE is required for correct daily aggregation | WHEN_TO_CHECK: When selecting, filtering, grouping, or ordering by Date derived from block_timestamp | EXAMPLE_USAGE: Correct:"
34,sf_bq083,db,filter;like,CRYPTO.CRYPTO_ETHEREUM.TRANSACTIONS,all,str,all,"VERIFY: Filtering by to_address and input prefixes to isolate USDC mint/burn events | CONTEXT: In CRYPTO.CRYPTO_ETHEREUM.TRANSACTIONS, the to_address column identifies the USDC contract, and the input column’s hex prefixes identify mint (0x42966c68) or burn (0x40c10f19) functions | WHEN_TO_CHECK: When constructing the WHERE clause for market value change queries | EXAMPLE_USAGE: Correct:"
35,sf_bq083,db,aggregation;cast,CRYPTO.CRYPTO_ETHEREUM.TRANSACTIONS,CRYPTO.CRYPTO_ETHEREUM.TRANSACTIONS.parsed_value,numeric,all,"VERIFY: Applying SUM on numeric parsed input values before formatting to a string | CONTEXT: The TRANSACTIONS table’s input values must be parsed to a numeric field, aggregated, and only then formatted as currency—formatting before summation yields incorrect totals | WHEN_TO_CHECK: When defining the “Δ Total Market Value” column in the SELECT clause | EXAMPLE_USAGE: Correct:"
36,sf_bq083,generic,aggregation;group by;order by,all,all,all,all,"VERIFY: GROUP BY expressions must exactly match SELECT and ORDER BY expressions for derived columns | PRINCIPLE: In aggregate queries, using the same expression in SELECT, GROUP BY, and ORDER BY ensures the data groups and sort order align correctly | WHEN_TO_APPLY: Whenever a query derives a column via an expression or function and then groups or orders by it | EXAMPLE_USAGE: Correct:"
37,sf_bq083,generic,filter;like,all,all,str,all,VERIFY: Filters on string prefixes must use LIKE with a '%' wildcard to match any suffix | PRINCIPLE: SQL’s LIKE operator requires '%' to denote variable-length sequences; omitting it turns the pattern into an exact match and misses intended rows | WHEN_TO_APPLY: Any time you filter rows based on the beginning of a string value | EXAMPLE_USAGE: Correct:
38,sf_bq083,generic,filter;aggregation,all,all,all,all,"VERIFY: Apply WHERE filters before aggregation rather than in HAVING | PRINCIPLE: WHERE restricts input rows prior to GROUP BY and aggregation, ensuring aggregates compute only over the intended subset; using HAVING for non-aggregate filters can degrade performance and yield incorrect groupings | WHEN_TO_APPLY: Queries that involve GROUP BY and need to filter raw rows before aggregation | EXAMPLE_USAGE: Correct:"
39,sf_bq083,question,NA,NA,NA,NA,NA,"The original query only returned a static message; changing the SELECT to compute date and sum of signed parsed input values, adding the correct FROM, WHERE, GROUP BY, and ORDER BY clauses fixed the logic and produced the expected daily USDC mint/burn market value changes for 2023."
40,sf_bq099,db,unnest;cast,patents,patents.assignee_harmonized,all,all,"VERIFY: Use LATERAL FLATTEN on assignee_harmonized and cast a.value:\""name\"" to STRING as main_assignee | CONTEXT: The patents table stores harmonized assignee data in a JSON ARRAY column named assignee_harmonized; extracting each assignee’s name requires flattening this specific field and casting the JSON value to STRING | WHEN_TO_CHECK: When flattening JSON arrays to extract assignee names from assignee_harmonized | EXAMPLE_USAGE:"
41,sf_bq099,db,filter,all,all,str,all,"VERIFY: The filter on main_assignee uses the exact IN-list ('LELY NV C VAN DER','DEERE & CO','TEXAS INDUSTRIES INC') | CONTEXT: Filtering the harmonized assignee names must match the exact list of top filers without lowercasing or other transformations to include DEERE & CO correctly | WHEN_TO_CHECK: When applying the WHERE clause to limit main_assignee to the target companies | EXAMPLE_USAGE:"
42,sf_bq099,db,order by,all,all,all,all,"VERIFY: Final SELECT aliases and column ordering matches: total_applications AS total_count, main_assignee AS assignee_name, applications_in_year AS year_cnt, filing_year AS filing_year, country_code AS country_code | CONTEXT: The report’s schema requires specific column names and order for consumption by downstream processes | WHEN_TO_CHECK: In the final SELECT clause that builds the output result set | EXAMPLE_USAGE:"
43,sf_bq099,generic,unnest;cast,all,all,all,all,"VERIFY: Array flattening uses the correct array column and explicit casting of JSON values | PRINCIPLE: When extracting elements from a JSON ARRAY or VARIANT field, the query must flatten the intended column and cast the JSON path to the desired SQL type to avoid type mismatches or missing data | WHEN_TO_APPLY: Whenever a JSON or VARIANT column contains nested arrays of objects and a specific subfield is required in the SELECT output | EXAMPLE_USAGE:"
44,sf_bq099,generic,filter,all,all,str,all,"VERIFY: Filters on string-based domains should use exact-match values without unnecessary transformations | PRINCIPLE: Applying functions like LOWER or UPPER before filtering can cause mismatches if the domain values have specific formatting, punctuation, or spaces; use the exact expected strings for reliability | WHEN_TO_APPLY: When filtering on known categorical fields such as company names, codes, or standardized labels | EXAMPLE_USAGE:"
45,sf_bq099,generic,order by,all,all,all,all,"VERIFY: Output columns are explicitly aliased and ordered to match expected schema definitions | PRINCIPLE: Downstream systems and consumers often rely on a fixed column order and naming convention; queries should define both alias and position to avoid misalignment | WHEN_TO_APPLY: At the end of any query feeding into reports, exports, or visualization tools with predefined schemas | EXAMPLE_USAGE:"
46,sf_bq099,question,NA,NA,NA,NA,NA,"Replaced the original “assignee” array logic with the harmonized field, updated the filter list to include DEERE & CO, and reordered/renamed the SELECT columns to align exactly with the GOLD result format."
47,sf_bq104,db,distinct;limit,target_week_data,target_week_data.term,str,all,"VERIFY: The query selecting from target_week_data must use “SELECT DISTINCT term” along with “LIMIT 1” | CONTEXT: The target_week_data table can contain duplicate term values aggregated across weeks, and the requirement is to return exactly one unique term | WHEN_TO_CHECK: When querying target_week_data to retrieve a single term result | EXAMPLE_USAGE: Correct: SELECT DISTINCT term FROM target_week_data LIMIT 1; Incorrect (returns all rows): SELECT term FROM target_week_data; Incorrect (dedupes but returns all unique terms): SELECT DISTINCT term FROM target_week_data;"
48,sf_bq104,generic,limit,all,all,all,all,"VERIFY: Queries intended to yield a single value must include a LIMIT 1 clause | PRINCIPLE: SQL returns all matching rows by default; adding LIMIT 1 enforces that only one row is returned for scalar outputs | WHEN_TO_APPLY: Whenever a query is designed to retrieve exactly one record (e.g., top-ranked, max/min, or arbitrary single value) | EXAMPLE_USAGE: Correct: SELECT name FROM employees WHERE department = 'Sales' ORDER BY hire_date DESC LIMIT 1; Incorrect (may return multiple rows): SELECT name FROM employees WHERE department = 'Sales' ORDER BY hire_date DESC;"
49,sf_bq104,generic,distinct;limit,all,all,all,all,"VERIFY: Use DISTINCT when you need to deduplicate values before applying LIMIT | PRINCIPLE: DISTINCT filters out duplicate entries at the column level, ensuring that LIMIT 1 returns a unique value rather than an arbitrary duplicate | WHEN_TO_APPLY: When extracting a single entry from a column that may contain repeated values | EXAMPLE_USAGE: Correct: SELECT DISTINCT category FROM products LIMIT 1; Incorrect (may return a duplicate if the first row is repeated): SELECT category FROM products LIMIT 1;"
50,sf_bq104,question,NA,NA,NA,NA,NA,"The outer query was simplified to only select the distinct term with a LIMIT 1, ensuring a single top-ranked term is returned."
51,sf_bq121,db,filter;cast,users,users.creation_date,int,all,"VERIFY: The WHERE clause in the eligible_users CTE must convert the creation_date from microseconds to a DATE before comparing it | CONTEXT: eligible_users.creation_date is stored as microseconds since epoch, so comparing the raw integer to a date cutoff yields incorrect user sets | WHEN_TO_CHECK: When filtering eligible_users by creation_date to include only users on or before 2021-10-01 | EXAMPLE_USAGE: Correct: ```sql WITH eligible_users AS ( SELECT user_id FROM users WHERE TO_TIMESTAMP(""creation_date""/1000000)::DATE <= DATE '2021-10-01' ``` Incorrect: ```sql WHERE ""creation_date"" <= 1633046400000000 ```"
52,sf_bq121,generic,division;cast;filter,all,all,all,all,"VERIFY: Epoch timestamp columns stored as integers must be converted and cast before comparing to date literals | PRINCIPLE: Direct numeric comparison between integer epoch values (especially in microseconds) and date constants produces invalid filters; you must divide by the correct factor, apply TO_TIMESTAMP, and cast to DATE to align data types | WHEN_TO_APPLY: Whenever filtering or joining on a timestamp column stored as an integer epoch against a DATE or timestamp literal | EXAMPLE_USAGE: Incorrect: ```sql WHERE event_epoch_us <= 1609459200000000 ``` Correct: ```sql WHERE TO_TIMESTAMP(event_epoch_us/1000000)::DATE <= DATE '2021-01-01' ```"
53,sf_bq121,question,NA,NA,NA,NA,NA,The core issue was filtering by raw microsecond value; switching to a DATE comparison fixes the eligible user set.
54,sf_bq150,db,cte_definition;where,SOMATIC_MUTATION_MC3,SOMATIC_MUTATION_MC3.Variant_Type,str,all,"VERIFY: The tp53_mut CTE queries from TCGA_HG19_DATA_V0.TCGA_HG19_DATA_V0.SOMATIC_MUTATION_MC3 and selects the ""Variant_Type"" column | CONTEXT: tp53_mut CTE was originally using SOMATIC_MUTATION_DCC and the wrong classification field, leading to mismatched mutation definitions for TP53 | WHEN_TO_CHECK: When defining or reviewing the tp53_mut CTE to ensure it pulls mutation data for p53 correctly | EXAMPLE_USAGE: Correct: WITH tp53_mut AS ( SELECT sample_id, ""Variant_Type"" FROM SOMATIC_MUTATION_MC3 WHERE Hugo_Symbol = 'TP53' Incorrect: WITH tp53_mut AS ( SELECT sample_id, ""Variant_Classification"" FROM SOMATIC_MUTATION_DCC WHERE Hugo_Symbol = 'TP53'"
55,sf_bq150,db,aggregation;group by,SOMATIC_MUTATION_MC3,SOMATIC_MUTATION_MC3.Variant_Type,str,all,"VERIFY: The expr_mut CTE aliases m.""Variant_Type"" AS ""Variant_Classification"" to maintain consistent mutation type naming for downstream ANOVA grouping | CONTEXT: expr_mut was grouping by ""Variant_Classification"" but originally referenced the field from the wrong CTE, causing group mismatches | WHEN_TO_CHECK: When constructing expr_mut or any subsequent CTE that groups or filters by classification | EXAMPLE_USAGE: Correct: WITH expr_mut AS ( SELECT e.sample_id, m.""Variant_Type"" AS ""Variant_Classification"", e.expression FROM expression_data e JOIN SOMATIC_MUTATION_MC3 m ON e.sample_id = m.sample_id Incorrect: WITH expr_mut AS ( SELECT e.sample_id, m.""Variant_Classification"", e.expression FROM expression_data e JOIN SOMATIC_MUTATION_MC3 m ON e.sample_id = m.sample_id"
56,sf_bq150,generic,all,all,all,all,all,"VERIFY: When switching to a newer or alternative data source table, confirm the new table and column references deliver the same logical data as before | PRINCIPLE: Upgrading or changing underlying tables requires verifying semantics to avoid silent data shifts | WHEN_TO_APPLY: Any time a query is refactored to use a different versioned table for the same data domain | EXAMPLE_USAGE: Correct refactor: - Old source SELECT id, status FROM old_status_table; - New source SELECT id, state AS status FROM new_status_table; Verify that new_status_table.state corresponds exactly to old_status_table.status. Incorrect refactor: SELECT id, state FROM new_status_table; (omits alias, leading to mismatched column naming and potential downstream errors)"
57,sf_bq150,generic,group by,all,all,all,all,"VERIFY: Whenever a CTE or subquery renames a column used later for grouping or joining, ensure the alias aligns with downstream references | PRINCIPLE: Consistent aliasing prevents grouping errors and join mismatches when chaining query steps | WHEN_TO_APPLY: In multi-CTE queries where one CTE defines or renames fields consumed by subsequent CTEs or the final SELECT | EXAMPLE_USAGE: Correct: WITH step1 AS ( SELECT order_id AS oid, amount FROM orders , step2 AS ( SELECT oid, SUM(amount) AS total_amount FROM step1 GROUP BY oid Incorrect: WITH step1 AS ( SELECT order_id AS oid, amount FROM orders , step2 AS ( SELECT order_id, SUM(amount) AS total_amount  -- uses original name instead of alias FROM step1 (renaming inconsistency causes ""order_id"" to be unknown in step2)"
58,sf_bq150,question,NA,NA,NA,NA,NA,"Switched mutation source to SOMATIC_MUTATION_MC3’s ""Variant_Type"" and aliased it as ""Variant_Classification"" in expr_mut, correcting group definitions and matching the expected ANOVA metrics."
59,sf_bq158,db,all,histology_mut_stats,histology_mut_stats.histological_type,str,all,"VERIFY: The final SELECT list includes only the column histological_type and excludes total_patients, cdh1_mutated_patients, and percent_cdh1_mutated | CONTEXT: The query’s output must match the schema that returns only the histological_type values without any aggregates or additional metrics | WHEN_TO_CHECK: When defining the final SELECT clause for histological type results | EXAMPLE_USAGE:"
60,sf_bq158,generic,all,all,all,all,all,VERIFY: SELECT lists must exactly match the expected output columns with no extras | PRINCIPLE: Including columns beyond those specified by the result schema causes mismatched structures and test failures | WHEN_TO_APPLY: Whenever the problem specification or test case demands a precise set of output columns | EXAMPLE_USAGE:
61,sf_bq158,question,NA,NA,NA,NA,NA,Reduced the final SELECT to a single column (`histological_type`) to match the GOLD output’s single-column result.
62,sf_bq166,db,round;division,frequency_calc,frequency_calc.frequency_percent,numeric,all,VERIFY: The ROUND function in frequency_calc uses 6 decimal places for frequency_percent | CONTEXT: frequency_calc computes percentage by dividing n_cases by total cases (517) | WHEN_TO_CHECK: When defining frequency_percent in the frequency_calc subquery | EXAMPLE_USAGE:
63,sf_bq166,db,aggregation;group by,frequency_calc,all,all,all,"VERIFY: The final SELECT pivots subtype rows into columns freq_amp, freq_gain, freq_homodel, freq_heterodel, freq_normal and includes 517 AS total | CONTEXT: frequency_calc table has one row per cytoband and subtype; final result must show one row per cytoband with separate columns | WHEN_TO_CHECK: When aggregating frequency_calc by chromosome and cytoband_name to produce the report | EXAMPLE_USAGE:"
64,sf_bq166,db,null_handling;aggregation,all,freq_homodel,numeric,Yes,"ENSURE: The homozygous_deletion frequency is wrapped with NVL to default NULLs to 0.0 | CONTEXT: Without NVL, MAX(CASE WHEN subtype='homozygous_deletion'...) returns NULL for cytobands without that subtype | WHEN_TO_CHECK: When defining the freq_homodel column in the pivoted result | EXAMPLE_USAGE:"
65,sf_bq166,generic,round;numeric_precision,all,all,numeric,all,"VERIFY: ROUND functions use the required number of decimal places based on output precision requirements | PRINCIPLE: Applying incorrect precision during rounding can cause mismatches with expected results, especially for percentage or ratio calculations | WHEN_TO_APPLY: Whenever computing derived numeric columns that require specific decimal precision | EXAMPLE_USAGE:"
66,sf_bq166,generic,aggregation;group by,all,all,all,all,"ENSURE: Pivoting rows into columns uses conditional aggregation with CASE WHEN and an aggregate function | PRINCIPLE: To transform categorical row values into separate columns, you must GROUP BY the key columns and use MAX or SUM over CASE WHEN expressions for each category | WHEN_TO_APPLY: Whenever you need one row per group with multiple category-based columns | EXAMPLE_USAGE:"
67,sf_bq166,generic,null_handling;aggregation,all,all,all,Yes,VERIFY: Conditional aggregation results must handle NULLs to represent missing categories as zeros | PRINCIPLE: Aggregates over CASE WHEN return NULL when no rows match the condition; COALESCE or NVL should replace NULL with a default value | WHEN_TO_APPLY: When pivoting or summarizing data across multiple categories where absence should be zero | EXAMPLE_USAGE:
68,sf_bq166,question,NA,NA,NA,NA,NA,"Pivoted subtype rows into separate frequency columns (adding total) and NVL’ed homozygous deletion frequency to 0, while increasing rounding precision to 6 decimals to match the GOLD output."
69,sf_bq182,db,all,"GITHUB_REPOS_DATE.DAY.""_20230118""",all,all,all,"VERIFY: The FROM clause must reference the GITHUB_REPOS_DATE.DAY.""_20230118"" table, not the MONTH partition | CONTEXT: The schema partitions GitHub repo data by day and by month; daily analyses require the DAY table suffixed with the exact date | WHEN_TO_CHECK: When querying daily pull request metrics for a specific date | EXAMPLE_USAGE: Incorrect: SELECT * FROM GITHUB_REPOS_DATE.MONTH.""_202301"" pr; Correct: SELECT * FROM GITHUB_REPOS_DATE.DAY.""_20230118"" pr;"
70,sf_bq182,db,filter;where,daily_pr_events,daily_pr_events.created_at,numeric,all,"VERIFY: Queries against daily_pr_events should not include an extra TO_DATE(DATEADD(...)) = 'YYYY-MM-DD' filter | CONTEXT: The daily_pr_events table is already partitioned to a single date, so adding a date filter on created_at is redundant and may exclude or duplicate data | WHEN_TO_CHECK: When retrieving pull request events from a DAY partition table | EXAMPLE_USAGE: Incorrect: SELECT user_id, event_type FROM daily_pr_events WHERE TO_DATE(DATEADD('second', created_at/1000000, '1970-01-01')) = '2023-01-18'; Correct: SELECT user_id, event_type FROM daily_pr_events;"
71,sf_bq182,db,aggregation;where,repo_pr_counts,repo_pr_counts.total_prs,int,No,"VERIFY: The threshold on total_prs must be set to >= 5 for daily aggregates rather than a monthly threshold like >= 100 | CONTEXT: Daily pull request volume is much lower than monthly; using a high threshold filters out valid daily contributors | WHEN_TO_CHECK: When filtering aggregated PR counts in a daily analysis query | EXAMPLE_USAGE: Incorrect: SELECT language, total_prs FROM repo_pr_counts WHERE total_prs >= 100; Correct: SELECT language, total_prs FROM repo_pr_counts WHERE total_prs >= 5;"
72,sf_bq182,generic,all,all,all,all,all,"VERIFY: Use the correct partition granularity in your FROM clause when querying time-partitioned tables | PRINCIPLE: Tables partitioned by time (e.g., day vs. month) contain only the scoped data for that partition; using the wrong partition returns either too much or too little data | WHEN_TO_APPLY: Anytime you query a partitioned table, ensure the partition suffix matches the analysis period | EXAMPLE_USAGE: Situation: You need daily sales for Jan 18, 2023. Incorrect: FROM sales_month_202301 Correct: FROM sales_day_20230118"
73,sf_bq182,generic,filter;where,all,all,all,all,VERIFY: Do not apply redundant date filters on columns when querying a table already partitioned by that date | PRINCIPLE: Partitioned tables implicitly limit rows to the partition key; extra WHERE filters on the same column are unnecessary and can harm performance | WHEN_TO_APPLY: When a table name or metadata indicates it is already scoped to a specific date | EXAMPLE_USAGE: Situation: Selecting from orders_day_20230118. Incorrect: WHERE order_date = '2023-01-18' Correct: (no WHERE on order_date)
74,sf_bq182,generic,aggregation;having;where,all,all,all,all,VERIFY: Tailor aggregation thresholds to the data’s time window to avoid over- or under-filtering | PRINCIPLE: The appropriate numeric filter value depends on the volume of data in the chosen time frame; thresholds valid for a month will differ from those valid for a day | WHEN_TO_APPLY: When adding HAVING or WHERE clauses on aggregated counts or sums | EXAMPLE_USAGE: Situation: Counting daily logins vs. monthly logins. Incorrect: HAVING COUNT(*) >= 100 (for daily data) Correct: HAVING COUNT(*) >= 5 (for daily data)
75,sf_bq182,question,NA,NA,NA,NA,NA,"Switched to the DAY._20230118 table and removed the redundant date filter in daily_pr_events, and lowered the total_prs threshold to 5 to match the expected result counts."
76,sf_bq221,db,all,all,all,all,all,"VERIFY: The SELECT clause must alias d.""titleFull"" AS ""titleFull"", b.cpc5_symbol AS ""cpc_group"", and b.best_year AS ""best_filing_year"" | CONTEXT: patent_details (alias d) provides the full title, and patent_groups (alias b) provides the CPC symbol and best filing year. Correct aliases ensure the output columns match the expected report schema. | WHEN_TO_CHECK: When building the final SELECT for the patent distribution report. | EXAMPLE_USAGE:"
77,sf_bq221,db,order by,all,all,all,all,"VERIFY: The ORDER BY clause must sort by d.""titleFull"" then b.cpc5_symbol | CONTEXT: Results should be ordered alphabetically by patent title and then by CPC group, matching the expected GOLD output ordering. | WHEN_TO_CHECK: When defining the ORDER BY for the final query output. | EXAMPLE_USAGE:"
78,sf_bq221,generic,all,all,all,all,all,"VERIFY: Explicit column aliases in SELECT should match the required output field names | PRINCIPLE: Explicit aliases guarantee that query outputs adhere to a predefined schema or report layout, avoiding mismatches or surprises in column names. | WHEN_TO_APPLY: Whenever a query’s output feeds downstream processes, reports, or API consumers expecting specific field names. | EXAMPLE_USAGE:"
79,sf_bq221,generic,order by,all,all,all,all,VERIFY: ORDER BY must reference columns or aliases included in the SELECT list | PRINCIPLE: Sorting on visible output fields prevents confusion or errors that arise when ordering by hidden or unselected columns. | WHEN_TO_APPLY: Whenever adding an ORDER BY clause to ensure the sort aligns with displayed data. | EXAMPLE_USAGE:
80,sf_bq221,question,NA,NA,NA,NA,NA,Adjusted the final SELECT column aliases and ORDER BY to align with the GOLD output’s column order and sorting.
81,sf_bq222,db,filter,dec_2016_grants,"dec_2016_grants.value:""first""",bool,all,"VERIFY: The WHERE clause on the dec_2016_grants table alias “c” includes c.value:""first"" = TRUE | CONTEXT: dec_2016_grants holds CPC code entries with a boolean flag “value:'first'” marking primary codes; filtering on this flag ensures only primary CPC codes are used in peak-year calculations | WHEN_TO_CHECK: When filtering CPC code records from dec_2016_grants for primary codes | EXAMPLE_USAGE: Correct: ```sql SELECT … FROM dec_2016_grants c WHERE c.value:""first"" = TRUE …; ``` Incorrect (missing filter): ```sql SELECT … FROM dec_2016_grants c …; ``` includes non-primary codes and skews results."
82,sf_bq222,db,all,all,m.peak_ema,numeric,all,"VERIFY: The SELECT list omits m.peak_ema | CONTEXT: The alias “m” includes a column peak_ema that is not part of the required output schema and was removed to match expectations | WHEN_TO_CHECK: When defining the final projection of columns | EXAMPLE_USAGE: Correct: ```sql SELECT m.group_symbol, m.peak_year, d.""titleFull"" … ``` Incorrect (extraneous column): ```sql SELECT m.group_symbol, m.peak_ema, m.peak_year, d.""titleFull"" … ``` adds an unwanted column."
83,sf_bq222,db,order by,all,all,all,all,"VERIFY: The ORDER BY clause uses d.""titleFull"", m.group_symbol | CONTEXT: The expected output is sorted alphabetically by the full title (alias “d”) then by group_symbol (alias “m”); previous ORDER BY on m.peak_ema was incorrect | WHEN_TO_CHECK: When specifying result ordering to match expected sequence | EXAMPLE_USAGE: Correct: ```sql … ORDER BY d.""titleFull"", m.group_symbol; ``` Incorrect: ```sql … ORDER BY m.peak_ema DESC, m.group_symbol; ``` yields wrong ordering."
84,sf_bq222,generic,filter,items,items.is_active,bool,all,"VERIFY: WHERE clauses include all required boolean flag filters | PRINCIPLE: Omitting necessary flag-based conditions allows unintended rows to pass, distorting subsets and aggregates | WHEN_TO_APPLY: Any time a query filters by boolean or categorical indicators | EXAMPLE_USAGE: Correct: ```sql SELECT … FROM items WHERE is_active = TRUE; ``` Incorrect (no filter): ```sql SELECT … FROM items; ``` includes inactive items."
85,sf_bq222,generic,all,table_x,all,all,all,"VERIFY: SELECT lists match the defined output schema without extra columns | PRINCIPLE: Including unspecified columns causes schema mismatches and breaks downstream expectations | WHEN_TO_APPLY: When constructing result sets against a known specification | EXAMPLE_USAGE: Correct: ```sql SELECT col_a, col_b FROM table_x; ``` Incorrect: ```sql SELECT col_a, extra_col, col_b FROM table_x; ``` introduces an unwanted column."
86,sf_bq222,generic,order by,all,all,all,all,"VERIFY: ORDER BY clauses follow the specification’s sort keys and directions | PRINCIPLE: Using wrong keys or order directions changes row sequence and fails output requirements | WHEN_TO_APPLY: When row ordering is part of the query specification | EXAMPLE_USAGE: Correct: ```sql SELECT … ORDER BY name, date; ``` Incorrect: ```sql SELECT … ORDER BY date DESC, name; ``` produces a different sequence."
87,sf_bq222,question,NA,NA,NA,NA,NA,"Filtered only primary CPC codes (`c.value:""first""=TRUE`) to fix the F16 peak year, removed the extra peak_ema column, and reordered by title to match expected output."
88,sf_bq223,db,left join;substr;group by;count,citing_details,citing_details.cpc_code,str,all,"VERIFY: The LEFT JOIN between citing_details and cpc_titles uses only the first four characters of citing_details.cpc_code | CONTEXT: citing_details.cpc_code holds full CPC classification strings (e.g., ‘A01B33/00’), while cpc_titles.cpc_code stores four-character subclass identifiers (e.g., ‘A01B’); matching on the full string misaligns subclass titles and overcounts citations | WHEN_TO_CHECK: When joining citing_details to cpc_titles to aggregate citation counts by subclass | EXAMPLE_USAGE: - Incorrect: SELECT t.cpc_code, COUNT(*) FROM citing_details d LEFT JOIN cpc_titles t ON d.cpc_code = t.cpc_code GROUP BY t.cpc_code; - Correct: SELECT t.cpc_code, COUNT(*) FROM citing_details d LEFT JOIN cpc_titles t ON SUBSTR(d.cpc_code, 1, 4) = t.cpc_code GROUP BY t.cpc_code;"
89,sf_bq223,generic,join;substr;aggregation,all,all,all,all,"VERIFY: Join conditions must match the aggregation’s code granularity | PRINCIPLE: When data is grouped or reported at a higher-level code (e.g., subclass), the JOIN key must use the same substring or truncated segment rather than full detailed codes to avoid misalignment | WHEN_TO_APPLY: Whenever joining tables on hierarchical or composite codes where one side uses broader category prefixes and the other side uses more detailed codes | EXAMPLE_USAGE: - Given table A with full codes ‘XYZ12345’ and table B with prefix codes ‘XYZ1’: Incorrect: … FROM A JOIN B ON A.code = B.code Correct: … FROM A JOIN B ON SUBSTR(A.code, 1, 4) = B.code"
90,sf_bq223,question,NA,NA,NA,NA,NA,"The CPC join was originally using full codes, causing overcounting; switching to SUBSTR(...,1,4) correctly matches 4-digit subclasses and fixes the counts."
91,sf_bq224,db,filter,GITHUB_REPOS_DATE.GITHUB_REPOS.LICENSES,license,str,all,VERIFY: The allowed_repos CTE filters LICENSES by an explicit list of SPDX identifiers | CONTEXT: The CTE reads from GITHUB_REPOS_DATE.GITHUB_REPOS.LICENSES selecting repo_name and license | WHEN_TO_CHECK: When constructing allowed_repos to limit to approved licenses | EXAMPLE_USAGE:
92,sf_bq224,db,join;aggregation;group by,GITHUB_REPOS_DATE.MONTH._202204,all,str,all,"VERIFY: watch_counts CTE uses TRY_PARSE_JSON(""repo""):""name""::STRING to extract repo names consistently for grouping and joining | CONTEXT: Aggregates distinct actor logins for WatchEvent in GITHUB_REPOS_DATE.MONTH.""_202204"" | WHEN_TO_CHECK: When building watch_counts to ensure the repo key matches other CTEs | EXAMPLE_USAGE:"
93,sf_bq224,db,aggregation;group by,GITHUB_REPOS_DATE.MONTH._202204,all,int,all,"VERIFY: issue_counts CTE counts all IssuesEvent occurrences grouped by the same JSON‐parsed repo name | CONTEXT: Queries GITHUB_REPOS_DATE.MONTH.""_202204"" for type='IssuesEvent' | WHEN_TO_CHECK: When calculating issue_events to align on repo name with forks and watches | EXAMPLE_USAGE:"
94,sf_bq224,db,aggregation;group by,GITHUB_REPOS_DATE.MONTH._202204,all,int,all,VERIFY: fork_counts CTE counts forks by grouping on the JSON-extracted repo name | CONTEXT: Aggregates ForkEvent counts in the same source table and month | WHEN_TO_CHECK: When building fork_counts to align with other event CTEs | EXAMPLE_USAGE:
95,sf_bq224,db,inner join,all,all,all,all,"VERIFY: The final SELECT joins allowed_repos (ar) to fork_counts, issue_counts, and watch_counts on ar.""repo_name"" = ct.""repo"" for all three tables | CONTEXT: Ensures only repos with entries in all three event CTEs are considered | WHEN_TO_CHECK: When combining CTEs to compute total events | EXAMPLE_USAGE:"
96,sf_bq224,db,aggregation;order by,all,all,all,all,VERIFY: ORDER BY uses the sum (fc.forks + ic.issue_events + wc.watches) to rank repos correctly | CONTEXT: Ranks licensed repos by combined event counts for April 2022 | WHEN_TO_CHECK: When ordering aggregated metrics across multiple CTEs | EXAMPLE_USAGE:
97,sf_bq224,generic,filter,all,all,all,all,VERIFY: Composite filters in an IN() clause match the column’s data type and naming exactly | PRINCIPLE: Ensuring the filter clause uses correct literals prevents accidental inclusion/exclusion of rows | WHEN_TO_APPLY: Whenever filtering a dimension by a whitelist of values | EXAMPLE_USAGE:
98,sf_bq224,generic,aggregation;join;cast,all,all,all,all,"VERIFY: JSON-extracted keys must be parsed and cast identically across all aggregations and joins | PRINCIPLE: Consistent parsing prevents mismatches and join failures when the same logical key is derived from JSON objects | WHEN_TO_APPLY: When using JSON columns to group, aggregate, or join | EXAMPLE_USAGE:"
99,sf_bq224,generic,inner join,all,all,all,all,VERIFY: Inner joins across multiple aggregated CTEs ensure only common keys are retained | PRINCIPLE: Using INNER JOIN across event-count CTEs guarantees completeness across all event types | WHEN_TO_APPLY: When combining multiple metric sources to form a unified view | EXAMPLE_USAGE:
100,sf_bq224,generic,aggregation;order by,all,all,all,all,VERIFY: Ordering by a single computed expression is less error-prone than multiple ORDER BY columns | PRINCIPLE: Summing metrics into one expression avoids lexicographical ordering pitfalls | WHEN_TO_APPLY: When ranking entities by total of several metrics | EXAMPLE_USAGE:
101,sf_bq224,generic,aggregation,all,all,all,all,"VERIFY: When grouping counts of distinct values, always use COUNT(DISTINCT ...) to avoid duplicates | PRINCIPLE: COUNT(DISTINCT) prevents inflated counts when multiple events occur for the same entity | WHEN_TO_APPLY: When counting unique occurrences across repeated event records | EXAMPLE_USAGE:"
102,sf_bq224,question,NA,NA,NA,NA,NA,"The original query only counted licenses; to answer which licensed repo had the most forks, issues, and watches in April 2022, CTEs for allowed licenses and event counts (forks, issues, watches) on MONTH.""_202204"" were added and joined, then ordered by the sum of those counts and limited to the top result."
103,sf_bq255,db,filter,GITHUB_REPOS.GITHUB_REPOS.LICENSES,GITHUB_REPOS.GITHUB_REPOS.LICENSES.license,str,all,"VERIFY: The filter on the license column uses LIKE 'apache-2.0' instead of wrapping the column in LOWER(TRIM(...)) | CONTEXT: The table contains a column named ""license"" whose values are stored in a consistent case and format; avoiding functions on the column allows index usage and simplifies the query | WHEN_TO_CHECK: When filtering rows by license type in any query against this table | EXAMPLE_USAGE:"
104,sf_bq255,db,filter,GITHUB_REPOS.GITHUB_REPOS.SAMPLE_COMMITS,GITHUB_REPOS.GITHUB_REPOS.SAMPLE_COMMITS.message,str,all,"VERIFY: Commit messages are excluded using three explicit NOT LIKE clauses on LOWER(c.""message"") for banned prefixes merge, update, and test | CONTEXT: The commits table alias c has a column ""message"" that should not start with certain keywords; replacing REGEXP_LIKE with explicit LIKE conditions improves clarity and performance | WHEN_TO_CHECK: When filtering out commits whose messages begin with common automation or irrelevant prefixes | EXAMPLE_USAGE:"
105,sf_bq255,generic,filter,all,all,all,all,"VERIFY: Avoid wrapping columns in functions when a direct comparison or LIKE can achieve the same match | PRINCIPLE: Applying functions like LOWER or TRIM to columns can prevent index usage and degrade performance; if the stored data is already normalized or exact-case, use LIKE or direct equality | WHEN_TO_APPLY: Whenever filtering on text columns for exact or simple prefix matches without case sensitivity | EXAMPLE_USAGE:"
106,sf_bq255,generic,filter,all,all,all,all,"VERIFY: Replace simple regex-based filters with explicit NOT LIKE (or LIKE) clauses when the pattern is a fixed prefix or suffix | PRINCIPLE: Regular expressions are powerful but can be overkill for fixed-string patterns; using LIKE for starts-with or ends-with improves readability and can be more efficient | WHEN_TO_APPLY: Whenever the regex pattern only tests for a set of literal prefixes or suffixes, without complex grouping or lookarounds | EXAMPLE_USAGE:"
107,sf_bq255,question,NA,NA,NA,NA,NA,"The license filter was simplified to a LIKE comparison, and the regex filter for banned commit‐message prefixes was replaced by explicit LOWER(message) NOT LIKE clauses, correcting the commit count to 1094."
108,sf_bq263,db,join,THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.PRODUCTS,THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.PRODUCTS.category,str,all,"VERIFY: The JOIN between order_items (oi) and THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.PRODUCTS (p) includes both matching oi.""product_id"" = p.""id"" and p.""category"" = 'Sleep & Lounge' | CONTEXT: order_items contains each sold item’s product_id; PRODUCTS holds id, category, and cost. Including the category filter in the JOIN ensures only Sleep & Lounge products’ costs are retrieved for profit calculations. | WHEN_TO_CHECK: When retrieving cost data for Sleep & Lounge products in sales/cost analyses | EXAMPLE_USAGE: Correct: … FROM order_items oi JOIN THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.PRODUCTS p ON oi.""product_id"" = p.""id"" AND p.""category"" = 'Sleep & Lounge' … Incorrect (missing category filter or extra inventory join): … FROM order_items oi JOIN inventory_items ii ON oi.""product_id"" = ii.""id"" JOIN THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.PRODUCTS p ON ii.""product_id"" = p.""id"" …"
109,sf_bq263,db,group by,all,all,str,all,"VERIFY: The final SELECT wraps the month column with TO_CHAR(""month"", 'YYYY-MM') AS ""month"" to produce a string in 'YYYY-MM' format | CONTEXT: The month column originates from a DATE_TRUNC or timestamp field; formatting aligns the output with the GOLD report’s month labels | WHEN_TO_CHECK: When grouping or presenting monthly metrics in a report | EXAMPLE_USAGE: Correct: SELECT TO_CHAR(month, 'YYYY-MM') AS month, … Incorrect (raw timestamp): SELECT month AS month, …"
110,sf_bq263,generic,join,all,all,all,all,"VERIFY: Dimension attributes should be fetched via a direct JOIN to the reference table with any necessary filters, avoiding unnecessary intermediate tables | PRINCIPLE: Directly joining to the correct dimension table simplifies the query, reduces join complexity, and prevents mismatches or missing data | WHEN_TO_APPLY: When looking up properties (e.g., cost, category, description) for foreign-key relationships | EXAMPLE_USAGE: Correct pattern: FROM fact_table f JOIN dimension_table d ON f.dim_id = d.id AND d.type = 'DesiredType' Incorrect pattern (unnecessary intermediate): FROM fact_table f JOIN intermediate_table i ON f.dim_id = i.id JOIN dimension_table d ON i.dim_id = d.id"
111,sf_bq263,generic,all,all,all,all,all,"VERIFY: Date and timestamp columns used for grouping or labeling must be formatted to match the expected output string pattern rather than returned in raw form | PRINCIPLE: Applying the appropriate date‐formatting function ensures consistency with reporting specifications and prevents downstream parsing issues | WHEN_TO_APPLY: Whenever a report requires dates in a specific string format (e.g., 'YYYY-MM', 'MM/DD/YYYY') | EXAMPLE_USAGE: Correct: SELECT TO_CHAR(date_col, 'YYYY-MM') AS period Incorrect: SELECT date_col AS period"
112,sf_bq263,question,NA,NA,NA,NA,NA,The key fixes were sourcing cost directly from PRODUCTS with the correct category filter and formatting the month via TO_CHAR to match the GOLD report.
113,sf_bq264,db,filter;where;between;cast;timestamp,THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.USERS,THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.USERS.created_at,date,all,VERIFY: The WHERE clause on the created_at column uses TO_TIMESTAMP('2022-04-30 00:00:00') instead of TO_TIMESTAMP('2022-04-30 23:59:59') to define the correct cutoff | CONTEXT: Queries filtering rows by created_at must align with the intended inclusion/exclusion of April 30 records | WHEN_TO_CHECK: When applying a date filter up to April 30 in any SELECT or subquery that limits by created_at | EXAMPLE_USAGE: Incorrect: … WHERE created_at BETWEEN TO_TIMESTAMP('2022-04-01 00:00:00') AND TO_TIMESTAMP('2022-04-30 23:59:59') Correct: … WHERE created_at BETWEEN TO_TIMESTAMP('2022-04-01 00:00:00') AND TO_TIMESTAMP('2022-04-30 00:00:00')
114,sf_bq264,db,aggregation;subquery,extreme_counts,all,int,all,"VERIFY: The final SELECT subtracts the count at min_age from the count at max_age by using MAX(CASE WHEN ""age"" = (SELECT max_age FROM bounds) THEN age_count END) minus MAX(CASE WHEN ""age"" = (SELECT min_age FROM bounds) THEN age_count END) | CONTEXT: The extreme_counts table contains rows of age and age_count; the bounds table holds min_age and max_age values | WHEN_TO_CHECK: When calculating the difference between the highest‐age count and the lowest‐age count in one pass | EXAMPLE_USAGE: Incorrect: SELECT oldest_count - youngest_count AS diff FROM ( SELECT age_count AS youngest_count FROM extreme_counts WHERE age = (SELECT min_age FROM bounds), age_count AS oldest_count   FROM extreme_counts WHERE age = (SELECT max_age FROM bounds) t; Correct: SELECT (MAX(CASE WHEN age = (SELECT max_age FROM bounds) THEN age_count END) MAX(CASE WHEN age = (SELECT min_age FROM bounds) THEN age_count END)) AS diff FROM extreme_counts;"
115,sf_bq264,generic,filter;where;between,all,all,date,all,"VERIFY: Date range filters should use half-open intervals ([start, end)) rather than inclusive end-of-day timestamps | PRINCIPLE: Defining upper bounds at the start of the next day avoids missing or double-counting boundary records due to time components | WHEN_TO_APPLY: Whenever filtering rows by a date column for a full day or multiple days | EXAMPLE_USAGE: Incorrect: … WHERE event_date BETWEEN '2023-01-01' AND '2023-01-31 23:59:59' Correct: … WHERE event_date >= '2023-01-01' AND event_date < '2023-02-01'"
116,sf_bq264,generic,aggregation;group by;subquery,all,all,int,all,"VERIFY: Use conditional aggregation with CASE inside an aggregate function (MAX or SUM) to pivot multiple row values into separate columns before performing arithmetic | PRINCIPLE: Wrapping CASE expressions in MAX/SUM ensures that each desired value is captured as a scalar for downstream calculations | WHEN_TO_APPLY: When you need to compute differences, ratios, or other operations between row-specific values in one aggregated result | EXAMPLE_USAGE: Incorrect: SELECT (COUNT(*) FILTER (WHERE status = 'active') COUNT(*) FILTER (WHERE status = 'inactive')) AS diff FROM user_status; Correct: SELECT (MAX(CASE WHEN status = 'active'   THEN count_per_status END) MAX(CASE WHEN status = 'inactive' THEN count_per_status END)) AS diff FROM ( SELECT status, COUNT(*) AS count_per_status FROM user_status GROUP BY status summary;"
117,sf_bq264,question,NA,NA,NA,NA,NA,Adjusting the date boundary to midnight on April 30 and selecting only the computed difference aligned the result to the expected value.
118,sf_bq265,db,filter;group by;aggregation,order_items,order_items.created_at,date,all,"VERIFY: The order_totals CTE must include a WHERE clause converting oi.""created_at"" from microseconds to a timestamp and filtering for dates >= '2019-01-01' and < '2020-01-01' | CONTEXT: order_totals aggregates data from order_items (oi) by user_id and relies on created_at to restrict to the 2019 calendar year | WHEN_TO_CHECK: When defining the order_totals CTE before any grouping or aggregation | EXAMPLE_USAGE:"
119,sf_bq265,db,aggregation,order_totals,order_totals.order_total,numeric,all,"VERIFY: The user_avg_value CTE should calculate only AVG(ot.""order_total"") and not include SUM or COUNT aggregates that aren’t used downstream | CONTEXT: user_avg_value derives the average order_total per user from the order_totals CTE | WHEN_TO_CHECK: When constructing the user_avg_value CTE and defining its SELECT list | EXAMPLE_USAGE:"
120,sf_bq265,db,all,users,users.email,str,all,"VERIFY: The final SELECT must return only u.""email"" and exclude uv.avg_order_value or any other columns | CONTEXT: The expected output of the query is strictly a list of user email addresses | WHEN_TO_CHECK: When writing the final SELECT clause after joining users (u) with user_avg_value (uv) | EXAMPLE_USAGE:"
121,sf_bq265,generic,filter;group by;aggregation,all,all,all,all,"VERIFY: Filters on raw data should be applied before any GROUP BY or aggregation | PRINCIPLE: Applying WHERE conditions early ensures only relevant rows feed into aggregates, preventing inclusion of unwanted data in summaries | WHEN_TO_APPLY: Whenever a query involves aggregating over a subset of data defined by conditions (e.g., date ranges, status flags) | EXAMPLE_USAGE:"
122,sf_bq265,generic,all,all,all,all,all,"VERIFY: The SELECT clause should include only the columns needed for the final output contract | PRINCIPLE: Returning extra columns can break downstream processing, leak sensitive data, or fail automated tests expecting a specific schema | WHEN_TO_APPLY: When crafting the final output of a query, especially for reports or API responses with defined schemas | EXAMPLE_USAGE:"
123,sf_bq265,question,NA,NA,NA,NA,NA,Filtered order_items by 2019 dates and trimmed the final output to email only to match the expected result.
124,sf_bq271,db,group by;filter,ORDERS,ORDERS.created_at,date,all,"VERIFY: The “order_month” column is derived using DATE_TRUNC('MONTH', TO_DATE(TO_TIMESTAMP_NTZ(o.""created_at""/1000000))) instead of string formatting | CONTEXT: The orders table stores created_at as microsecond timestamps, so converting to a date and truncating by month yields a proper date type for grouping and sorting by month | WHEN_TO_CHECK: When extracting a monthly bucket from o.""created_at"" for grouping or filtering | EXAMPLE_USAGE:"
125,sf_bq271,db,aggregation;round,all,all,numeric,all,"VERIFY: The profit calculation wraps SUM(product_retail_price - cost) in ROUND(..., 9) | CONTEXT: Profit is defined as the total of product_retail_price minus cost across order details and requires consistent precision to nine decimal places | WHEN_TO_CHECK: When aggregating profit in the orders or order_items table | EXAMPLE_USAGE:"
126,sf_bq271,db,order by,all,all,all,all,"VERIFY: The final ORDER BY uses the ""order_month"" alias rather than multiple raw expressions | CONTEXT: After grouping results by month, sorting by the alias ensures clarity and matches expected output order | WHEN_TO_CHECK: When ordering grouped results by month in queries against orders | EXAMPLE_USAGE:"
127,sf_bq271,generic,group by;filter,all,all,all,all,"VERIFY: Use DATE_TRUNC on date/time types for bucketing instead of TO_CHAR formatting | PRINCIPLE: DATE_TRUNC preserves date semantics and allows proper grouping, filtering, and sorting, whereas formatting to strings loses type information | WHEN_TO_APPLY: Whenever you need to group or filter by calendar periods (month, week, day) | EXAMPLE_USAGE:"
128,sf_bq271,generic,aggregation;round,all,all,numeric,all,"VERIFY: Round aggregated numeric results to the required decimal precision immediately after aggregation | PRINCIPLE: Aggregation functions can produce high-precision floats; applying ROUND over the aggregation ensures uniform precision and avoids floating-point artifacts | WHEN_TO_APPLY: After computing SUM, AVG, or other aggregates on monetary or precise numeric fields | EXAMPLE_USAGE:"
129,sf_bq271,generic,order by,all,all,all,all,"VERIFY: Reference column aliases in ORDER BY for readability and to avoid repeating complex expressions | PRINCIPLE: Aliases improve maintainability and make it clear which computed column is being used for sorting | WHEN_TO_APPLY: When ordering by computed, aggregated, or otherwise complex expressions that have been aliased | EXAMPLE_USAGE:"
130,sf_bq271,question,NA,NA,NA,NA,NA,"Converted the month field to a date truncated to month, rounded the profit calculation to 9 decimal places, and simplified the ORDER BY clause to match the GOLD result."
131,sf_bq273,db,filter;cast;where,orders,orders.created_at,int,all,"VERIFY: The orders.created_at filter uses TO_TIMESTAMP_NTZ(o.""created_at""/1000000) BETWEEN TO_TIMESTAMP_NTZ('2022-07-01') AND TO_TIMESTAMP_NTZ('2023-11-30') | CONTEXT: orders table stores created_at in microseconds, so conversion to TIMESTAMP_NTZ ensures correct date filtering across the full period | WHEN_TO_CHECK: When filtering the orders table by creation date for any date‐range analysis | EXAMPLE_USAGE: Correct: WHERE TO_TIMESTAMP_NTZ(o.""created_at""/1000000) BETWEEN TO_TIMESTAMP_NTZ('2022-07-01') AND TO_TIMESTAMP_NTZ('2023-11-30'); Incorrect: WHERE o.""created_at"" BETWEEN '2022-07-01' AND '2023-11-30'  -- mismatched units/types causes wrong results."
132,sf_bq273,db,join,order_items,order_items.product_id,int,all,"VERIFY: The join between order_items oi and products p on oi.""product_id"" = p.""id"" | CONTEXT: order_items references product_id, and products.id holds the cost needed for profit calculations | WHEN_TO_CHECK: When joining order_items with products to retrieve unit cost for each item | EXAMPLE_USAGE: Correct: JOIN THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.PRODUCTS p ON oi.""product_id"" = p.""id"" Incorrect: JOIN INVENTORY_ITEMS ii ON oi.""product_id"" = ii.""product_id""  -- joins wrong table, missing official cost data."
133,sf_bq273,db,cast;aggregation;group by,orders,orders.delivered_at,int,all,"VERIFY: delivery_month is defined as DATE_TRUNC('MONTH', TO_TIMESTAMP_NTZ(oi.""delivered_at""/1000000)) | CONTEXT: delivered_at stored in microseconds, and grouping by month needs a DATE type for arithmetic and joins | WHEN_TO_CHECK: In the monthly_profits CTE when aggregating deliveries by month | EXAMPLE_USAGE: Correct: DATE_TRUNC('MONTH', TO_TIMESTAMP_NTZ(oi.""delivered_at""/1000000)) AS delivery_month Incorrect: TO_CHAR(TO_TIMESTAMP_NTZ(oi.""delivered_at""/1000000), 'YYYY-MM') AS delivery_month_str  -- yields string, breaks date joins."
134,sf_bq273,db,left join,monthly_profits,monthly_profits.delivery_month,date,all,"VERIFY: The self-join on monthly_profits pairs current and prior months using current_month.delivery_month = DATEADD(MONTH, -1, previous_month.delivery_month) | CONTEXT: Ensures profit_vs_prior_month correctly matches each month to its immediate predecessor | WHEN_TO_CHECK: When calculating month‐over‐month profit changes in the mom_changes CTE | EXAMPLE_USAGE: Correct: LEFT JOIN monthly_profits AS previous_month ON current_month.delivery_month = DATEADD(MONTH, -1, previous_month.delivery_month) Incorrect: LAG(monthly_profit) OVER (ORDER BY delivery_month)  -- does not handle missing months or allow explicit joins."
135,sf_bq273,db,filter;where,mom_changes,mom_changes.delivery_month,date,all,"VERIFY: The final WHERE clause filters WHERE delivery_month >= '2022-08-01' to exclude July data | CONTEXT: Excludes the first incomplete month where prior data is unavailable for comparison | WHEN_TO_CHECK: In the final SELECT of monthly profit changes to remove initial rows without valid prior-month data | EXAMPLE_USAGE: Correct: WHERE delivery_month >= '2022-08-01' Incorrect: No filter on delivery_month  -- includes July with profit_vs_prior_month = 0, skewing trends."
136,sf_bq273,db,select,mom_changes,mom_changes.delivery_month,date,all,"VERIFY: Final SELECT projects only delivery_month and profit_vs_prior_month | CONTEXT: Limits output to required metrics, avoiding leakage of intermediate columns | WHEN_TO_CHECK: When outputting the final results after all CTEs | EXAMPLE_USAGE: Correct: SELECT delivery_month, profit_vs_prior_month FROM mom_changes; Incorrect: SELECT * FROM mom_changes;  -- returns unnecessary fields like total_cost, total_revenue."
137,sf_bq273,generic,filter;cast;where,all,all,all,all,VERIFY: Date‐range filters on numeric timestamp fields must convert the stored value and literal to the same datetime type | PRINCIPLE: Ensuring both sides of a comparison share the same unit and data type prevents exclusion of valid records | WHEN_TO_APPLY: Any time you filter a column stored as an integer or bigint representing epoch time | EXAMPLE_USAGE: Correct: WHERE TO_TIMESTAMP(col_ms/1000) BETWEEN '2022-01-01' AND '2022-12-31'; Incorrect: WHERE col_ms BETWEEN '2022-01-01' AND '2022-12-31'  -- mismatches units and types.
138,sf_bq273,generic,aggregation;group by,all,all,all,all,"VERIFY: Grouping by period should use a native DATE or TIMESTAMP truncated value, not a formatted string | PRINCIPLE: DATE_TRUNC or equivalent maintains date semantics for joins and arithmetic, whereas string formats cannot be directly manipulated or compared as dates | WHEN_TO_APPLY: When aggregating or partitioning data by month, quarter, or year | EXAMPLE_USAGE: Correct: SELECT DATE_TRUNC('MONTH', ts_col) AS period, SUM(amount) FROM sales GROUP BY period; Incorrect: SELECT TO_CHAR(ts_col, 'YYYY-MM') AS period, SUM(amount) FROM sales GROUP BY period;  -- results in strings, breaks date functions."
139,sf_bq273,generic,join;coalesce,all,all,all,all,"VERIFY: Month‐over‐month or period‐over‐period calculations can employ self‐ joins using date arithmetic to handle missing periods explicitly | PRINCIPLE: Self‐ joins on shifted period values give explicit control over matching, making it easy to apply COALESCE for missing data | WHEN_TO_APPLY: When calculating differences between consecutive time periods and you need to handle gaps or absent prior periods | EXAMPLE_USAGE: Correct: LEFT JOIN periods prev ON curr.period = DATEADD(MONTH, -1, prev.period); SELECT curr.period, curr.value - COALESCE(prev.value, 0) FROM periods curr; Incorrect: SELECT period, value - LAG(value) OVER (ORDER BY period) FROM periods;  -- leaves first row null, unclear handling of gaps."
140,sf_bq273,generic,select,all,all,all,all,"VERIFY: Final query projections should explicitly list required columns rather than using SELECT * | PRINCIPLE: Explicit column lists improve clarity, performance, and prevent accidental exposure of intermediate or sensitive fields | WHEN_TO_APPLY: When presenting the end‐user result set after multiple transformations or CTEs | EXAMPLE_USAGE: Correct: SELECT month, change_pct FROM performance; Incorrect: SELECT * FROM performance;  -- may include debug or intermediate columns."
141,sf_bq273,question,NA,NA,NA,NA,NA,"Switched to PRODUCTS for cost, aligned created_at bounds using TO_TIMESTAMP_NTZ, converted delivery_month to DATE for self-join, replaced LAG with a LEFT JOIN + COALESCE, filtered out July, and selected only the two required columns to match GOLD."
142,sf_bq295,db,join,SAMPLE_FILES,SAMPLE_FILES.id,int,all,"VERIFY: The JOIN between SAMPLE_FILES (alias f) and SAMPLE_CONTENTS (alias c) includes f.""id"" = c.""id"" | CONTEXT: SAMPLE_FILES contains file metadata (repo_name, path) while SAMPLE_CONTENTS holds file contents (size, content). Without joining on id, repo_name cannot be aligned with content-based filters and path criteria. | WHEN_TO_CHECK: When constructing the filtered_python_samples CTE that filters by file path, size, and content. | EXAMPLE_USAGE: Correct: ```sql FROM GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_FILES AS f JOIN GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_CONTENTS AS c ON f.""id"" = c.""id"" WHERE f.""path"" LIKE '%.py' AND c.""size"" < 15000 AND POSITION('def ' IN c.""content"") > 0 ``` Incorrect (missing join): ```sql FROM GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_CONTENTS AS c WHERE c.""size"" < 15000 AND POSITION('def ' IN c.""content"") > 0 ```"
143,sf_bq295,db,filter;null_handling,SAMPLE_FILES,SAMPLE_FILES.repo_name,str,Yes,"VERIFY: The WHERE clause includes f.""repo_name"" IS NOT NULL to exclude entries lacking repository association | CONTEXT: SAMPLE_FILES may contain records not linked to any repo; filtering out NULL repo_name ensures only valid repositories are analyzed. | WHEN_TO_CHECK: When selecting sample_repo_name in filtered_python_samples CTE. | EXAMPLE_USAGE: Correct: ```sql WHERE f.""repo_name"" IS NOT NULL ``` Incorrect (omitting the check): ```sql - No filter on repo_name, may include rows where repo_name IS NULL ```"
144,sf_bq295,generic,join,all,all,all,all,"VERIFY: Ensure all necessary joins are in place when selecting columns and applying filters across multiple tables | PRINCIPLE: When a query references columns from different tables, a join on the shared key(s) is required to correlate rows properly and avoid orphaned or misaligned data. | WHEN_TO_APPLY: Whenever SELECT or WHERE clauses involve columns from more than one table. | EXAMPLE_USAGE: Situation: You need metadata from TableA and content filters from TableB. Incorrect: ```sql SELECT b.repo_id FROM TableB b WHERE b.content LIKE '%keyword%' ``` Correct: ```sql SELECT a.repo_id FROM TableA a JOIN TableB b ON a.id = b.id WHERE b.content LIKE '%keyword%' ```"
145,sf_bq295,generic,distinct;join,all,all,all,all,VERIFY: Use DISTINCT to deduplicate results when joining one-to-many relationships | PRINCIPLE: Joins between parent and child tables can produce multiple rows for the same parent key; applying DISTINCT ensures each parent appears only once in the output. | WHEN_TO_APPLY: When selecting parent-level identifiers from a joined set where children may have multiple entries per parent. | EXAMPLE_USAGE: Incorrect: ```sql SELECT a.parent_id FROM ParentTable a JOIN ChildTable b ON a.id = b.parent_id ``` Correct: ```sql SELECT DISTINCT a.parent_id FROM ParentTable a JOIN ChildTable b ON a.id = b.parent_id ``` Ensures each parent_id appears only once.
146,sf_bq295,question,NA,NA,NA,NA,NA,"The initial query filtered only SAMPLE_CONTENTS and missed linking files to repos; adding the join to SAMPLE_FILES and selecting f.""repo_name"" fixed the repo key alignment, producing the correct top repos."
147,sf_bq320,db,filter,IDC.IDC_V17.DICOM_PIVOT,all,all,all,"VERIFY: Final SELECT must source from IDC.IDC_V17.DICOM_PIVOT as ""dicom_pivot"" rather than directly from the filtered_pivot CTE | CONTEXT: The filtered_pivot CTE yields only distinct StudyInstanceUIDs; counting should occur on full pivot rows in DICOM_PIVOT filtered by these IDs | WHEN_TO_CHECK: In the final SELECT clause when replacing FROM filtered_pivot | EXAMPLE_USAGE: Incorrect:"
148,sf_bq320,db,filter,IDC.IDC_V17.DICOM_PIVOT,dicom_pivot.StudyInstanceUID,str,all,CHECK: WHERE clause must filter dicom_pivot.StudyInstanceUID using the list from filtered_pivot | CONTEXT: Ensures only rows in the main pivot table corresponding to the CTE’s StudyInstanceUIDs are counted | WHEN_TO_CHECK: When applying the IN filter in the final SELECT on DICOM_PIVOT | EXAMPLE_USAGE: Incorrect:
149,sf_bq320,db,aggregation;distinct,IDC.IDC_V17.DICOM_PIVOT,StudyInstanceUID,str,all,"ENSURE: Use COUNT(*) instead of COUNT(DISTINCT ""StudyInstanceUID"") to compute total_count | CONTEXT: Counting DISTINCT StudyInstanceUID returns the number of unique IDs, not the total row count in DICOM_PIVOT | WHEN_TO_CHECK: In the aggregation clause of the final SELECT | EXAMPLE_USAGE: Incorrect:"
150,sf_bq320,generic,aggregation;distinct,all,all,all,all,"VERIFY: Using COUNT(DISTINCT column) only returns the number of unique values, not the total rows; use COUNT(*) for total rows | PRINCIPLE: COUNT(*) counts all rows that satisfy the query criteria, whereas COUNT(DISTINCT) removes duplicate values of the specified column | WHEN_TO_APPLY: When the requirement is to count every matching row rather than unique key occurrences | EXAMPLE_USAGE:"
151,sf_bq320,generic,cte_definition;filter,all,all,all,all,"ENSURE: When a CTE produces a list of keys, filter the base table with IN (SELECT key FROM CTE) to count or retrieve full rows | PRINCIPLE: CTEs often derive key lists for filtering, but final row-level queries should reference the source table for complete data and accurate aggregations | WHEN_TO_APPLY: Whenever a CTE yields filtering criteria but the final output requires rows or aggregates from the original table | EXAMPLE_USAGE:"
152,sf_bq320,question,NA,NA,NA,NA,NA,"The original query counted distinct IDs in the CTE; the GOLD SQL counts all rows in DICOM_PIVOT whose StudyInstanceUID is in that set and renames the column to total_count, so the final SELECT was rewritten to match that structure."
153,sf_bq321,db,aggregation;distinct,IDC.IDC_V17.DICOM_ALL,IDC.IDC_V17.DICOM_ALL.StudyInstanceUID,int,all,"VERIFY: The FROM clause uses IDC.IDC_V17.DICOM_ALL when counting distinct StudyInstanceUIDs | CONTEXT: DICOM_PIVOT is a transformed subset view that omits some StudyInstanceUID rows, while DICOM_ALL contains the complete set of studies | WHEN_TO_CHECK: When writing queries to count or list unique StudyInstanceUID values for reporting or validation | EXAMPLE_USAGE: Correct: SELECT COUNT(DISTINCT StudyInstanceUID) AS unique_study_instance_uids FROM IDC.IDC_V17.DICOM_ALL; Incorrect: SELECT COUNT(DISTINCT StudyInstanceUID) AS unique_study_instance_uids FROM IDC.IDC_V17.DICOM_PIVOT;  -- yields fewer results because it’s a pivot view"
154,sf_bq321,generic,aggregation;distinct;group by,all,all,all,all,"VERIFY: Use the table or view that provides full data coverage for aggregations | PRINCIPLE: Aggregate functions like COUNT(DISTINCT) require a source that includes every relevant row; using a summary view may undercount or misrepresent totals | WHEN_TO_APPLY: Anytime you perform a DISTINCT count or full-data aggregation and notice unexpected low results | EXAMPLE_USAGE: When you need total unique user IDs, compare: - Full table version (correct) SELECT COUNT(DISTINCT user_id) FROM user_transactions_full; - Summary view version (may miss some users) SELECT COUNT(DISTINCT user_id) FROM user_transactions_summary; If the summary view returns fewer users, switch to the full table to capture all records."
155,sf_bq321,question,NA,NA,NA,NA,NA,Switched the source table from DICOM_PIVOT to DICOM_ALL to correctly count 28 unique StudyInstanceUIDs.
156,sf_bq346,db,filter,IDC.IDC_V17.DICOM_ALL,all,all,all,"VERIFY: filtered_segs CTE uses IDC.IDC_V17.DICOM_ALL as the source table instead of IDC.IDC_V17.DICOM_PIVOT | CONTEXT: filtered_segs should pull segmentation records along with reference SOPInstanceUID data from the full DICOM_ALL table | WHEN_TO_CHECK: When defining the filtered_segs CTE to filter segmentations | EXAMPLE_USAGE: Correct: WITH filtered_segs AS ( SELECT ""SOPInstanceUID"" AS ""seg_SOPInstanceUID"", … FROM IDC.IDC_V17.DICOM_ALL … Incorrect: FROM IDC.IDC_V17.DICOM_PIVOT"
157,sf_bq346,db,coalesce,IDC.IDC_V17.DICOM_ALL,all,all,all,"VERIFY: filtered_segs CTE selects ""SOPInstanceUID"" AS ""seg_SOPInstanceUID"" and COALESCE(...) AS ""referenced_sop"" | CONTEXT: aliasing the segmentation UID and coalescing multiple reference columns ensures you have a single join key for originals | WHEN_TO_CHECK: When projecting segmentation identifiers and reference pointers in filtered_segs | EXAMPLE_USAGE: Correct: SELECT ""SOPInstanceUID"" AS ""seg_SOPInstanceUID"", COALESCE(referencedSOPInstanceUID, ReferencedSOPInstanceUIDStudy, ReferencedSOPInstanceUIDSeries) AS ""referenced_sop"" FROM IDC.IDC_V17.DICOM_ALL Incorrect: SELECT ""SOPInstanceUID"", referencedSOPInstanceUID AS ""referenced_sop"""
158,sf_bq346,db,join,all,all,all,all,"VERIFY: category_counts CTE joins seg CTE (alias s) to filtered_segs (alias f) using s.""SOPInstanceUID"" = f.""seg_SOPInstanceUID"" | CONTEXT: ensures each segmentation record aligns with its filtered CTE counterpart by matching the correct UID alias | WHEN_TO_CHECK: When joining the seg and filtered_segs CTEs in category_counts | EXAMPLE_USAGE: Correct: INNER JOIN filtered_segs f ON s.""SOPInstanceUID"" = f.""seg_SOPInstanceUID"" Incorrect: ON s.""SOPInstanceUID"" = f.""SOPInstanceUID"""
159,sf_bq346,db,join,IDC.IDC_V17.DICOM_ALL,all,all,all,"VERIFY: category_counts CTE includes INNER JOIN IDC.IDC_V17.DICOM_ALL orig ON f.""referenced_sop"" = orig.""SOPInstanceUID"" | CONTEXT: linking to the original DICOM records via the referenced_sop alias retrieves category metadata correctly | WHEN_TO_CHECK: When joining filtered_segs alias f to the original DICOM_ALL table in category_counts | EXAMPLE_USAGE: Correct: INNER JOIN IDC.IDC_V17.DICOM_ALL orig ON f.""referenced_sop"" = orig.""SOPInstanceUID"" Incorrect: Joining f to DICOM_PIVOT or using f.""referenced_sop"" = f.""seg_SOPInstanceUID"""
160,sf_bq346,generic,join,all,all,all,all,"VERIFY: downstream joins reference the aliased column names defined in an upstream CTE | PRINCIPLE: once a column is given an alias, only the alias should be used in subsequent query parts to avoid ambiguous or invalid column references | WHEN_TO_APPLY: whenever a CTE or subquery projects columns with AS aliases | EXAMPLE_USAGE: CTE A defines id AS user_id; correct join: JOIN A ON orders.user_id = A.user_id incorrect: JOIN A ON orders.user_id = A.id"
161,sf_bq346,generic,join,all,all,all,all,"VERIFY: when replacing a filtered or pivot table with a full source table, update all FROM clauses and join conditions to reference the new table and its columns | PRINCIPLE: altering the source table requires revising dependent query parts to maintain correct joins and filters | WHEN_TO_APPLY: when refactoring queries to use broader data tables instead of specialized ones | EXAMPLE_USAGE: Original: FROM recent_orders JOIN recent_orders_summary … Updated: FROM orders_all JOIN order_summaries ON orders_all.id = order_summaries.order_id"
162,sf_bq346,generic,join,all,all,all,all,"VERIFY: joins on derived or coalesced key columns must use the resolved derivation for linking tables | PRINCIPLE: if a key is computed via COALESCE or other expression, the join must reference the expression’s alias so that null fallbacks are correctly handled | WHEN_TO_APPLY: when joining tables on keys computed through functions or expressions | EXAMPLE_USAGE: CTE defines derived_key AS COALESCE(key_main, key_backup); correct join: ON main_table.id = derived_table.derived_key incorrect: ON main_table.id = derived_table.key_main"
163,sf_bq346,question,NA,NA,NA,NA,NA,"Switched filtering CTE from DICOM_PIVOT to DICOM_ALL to extract and join by the referenced original SOPInstanceUID, ensuring counts reflect only segmentations that reference originals."
164,sf_bq349,db,inner join;group by;count distinct;aggregation,administrative_boundaries,administrative_boundaries.boundary_geom,all,all,"VERIFY: The JOIN between administrative_boundaries (ab) and annotated_pois (an) in the boundary_poi_counts CTE uses an inner JOIN with ST_DWITHIN(ab.boundary_geom, an.poi.geom, 0.0) | CONTEXT: boundary_poi_counts CTE aggregates POI counts by boundary; using ST_DWITHIN with zero tolerance ensures points exactly on the boundary are included and unmatched boundaries are excluded | WHEN_TO_CHECK: When constructing the boundary_poi_counts CTE to count POIs per boundary | EXAMPLE_USAGE: Correct: FROM administrative_boundaries ab JOIN annotated_pois an ON ST_DWithin(ab.boundary_geom, an.poi_geom, 0.0) Incorrect: FROM administrative_boundaries ab LEFT JOIN annotated_pois an ON ST_Contains(ab.boundary_geom, an.poi.geom)"
165,sf_bq349,generic,join,all,all,all,all,"VERIFY: Spatial joins that require exact geometry containment should use ST_DWITHIN with a zero‐distance parameter rather than ST_CONTAINS | PRINCIPLE: ST_CONTAINS excludes points lying exactly on polygon edges, while ST_DWITHIN(...,0) captures both interior and boundary‐touching points | WHEN_TO_APPLY: Whenever performing a spatial join to determine if point geometries fall within or on the edges of polygon geometries | EXAMPLE_USAGE: Correct: ON ST_DWithin(polygon.geom, point.geom, 0) Incorrect: ON ST_Contains(polygon.geom, point.geom)"
166,sf_bq349,generic,inner join;left join;count;group by;where;aggregation,all,all,all,Yes,"VERIFY: When counting only matched records across two tables, prefer an inner JOIN over a left JOIN to automatically exclude non‐matching rows | PRINCIPLE: Inner joins filter out unmatched rows, preventing nulls in aggregated counts and simplifying query logic | WHEN_TO_APPLY: When aggregating or counting related records and only matched pairs are desired | EXAMPLE_USAGE: Correct: SELECT a.id, COUNT(*) FROM A a JOIN B b ON a.key = b.key GROUP BY a.id; Incorrect: SELECT a.id, COUNT(*) FROM A a LEFT JOIN B b ON a.key = b.key GROUP BY a.id;  (requires extra WHERE b.key IS NOT NULL)"
167,sf_bq349,question,NA,NA,NA,NA,NA,Switched to an inner join using ST_DWITHIN with a zero-distance parameter in the boundary_poi_counts CTE to align spatial containment logic with the GOLD query.
168,sf_bq358,db,join,ZIP_CODES,ZIP_CODES.zip_code_geom,all,all,"VERIFY: Use ST_GEOGFROMWKB for both sides of the spatial join instead of casting with ::GEOGRAPHY | CONTEXT: The tables aliased as sz and ez each have a column ""zip_code_geom"" stored as WKB; spatial predicate ST_WITHIN requires true geography objects to match ZIP areas correctly | WHEN_TO_CHECK: Whenever performing a spatial join between sz.""zip_code_geom"" and ez.""zip_code_geom"" using ST_WITHIN | EXAMPLE_USAGE:"
169,sf_bq358,db,all,ZIP_CODES,ZIP_CODES.zip_code,str,all,"VERIFY: Only select sz.""zip_code"" AS start_zip and ez.""zip_code"" AS end_zip when determining ZIP-to-ZIP relationships | CONTEXT: The query’s purpose is to return only the starting and ending ZIP codes; extraneous columns add overhead and can obscure results | WHEN_TO_CHECK: At the SELECT clause when building the final output for start_zip and end_zip | EXAMPLE_USAGE:"
170,sf_bq358,db,filter,ZIP_CODES,ZIP_CODES.zip_code,str,Yes,"ENSURE: Filter out NULL values in ez.""zip_code"" before returning end_zip | CONTEXT: Null end ZIP codes indicate unmatched or invalid geometries and would produce incorrect or incomplete trip results | WHEN_TO_CHECK: In the WHERE clause of the ZIP lookup query | EXAMPLE_USAGE:"
171,sf_bq358,generic,join,all,all,all,all,"VERIFY: Spatial joins must convert geometry literals via proper functions rather than rely on type casts | PRINCIPLE: Geospatial functions often require explicit constructors (e.g., ST_GeomFromWKB/TEXT) to ensure data is interpreted correctly | WHEN_TO_APPLY: Any time a spatial predicate (ST_Within, ST_Intersects, etc.) is used on raw geometry or WKB columns | EXAMPLE_USAGE:"
172,sf_bq358,generic,all,all,all,all,all,"CHECK: SELECT only the columns needed for the task to avoid unnecessary data transfer and confusion | PRINCIPLE: Pruning the SELECT list improves readability, performance, and reduces network overhead | WHEN_TO_APPLY: Whenever building a report or result set that requires a limited set of fields | EXAMPLE_USAGE:"
173,sf_bq358,generic,filter,all,all,all,Yes,ENSURE: Exclude NULL join keys to prevent incomplete or spurious matches in the result set | PRINCIPLE: NULLs in join columns break equality and can lead to missing or invalid join outcomes | WHEN_TO_APPLY: Before or after JOIN operations where join key integrity is critical | EXAMPLE_USAGE:
174,sf_bq358,question,NA,NA,NA,NA,NA,The original query’s spatial join cast (::GEOGRAPHY) prevented proper geometry matching; replacing it with ST_GEOGFROMWKB fixed ZIP lookups. We also pruned SELECT to only the two ZIP columns and filtered out NULL end_zips to yield the correct 10001 → 11211 trip.
175,sf_bq390,db,join,all,all,str,all,"VERIFY: The JOIN between IDC.IDC_V17.DICOM_ALL AS dicom_all_seg and IDC.IDC_V17.SEGMENTATIONS AS segmentations on dicom_all_seg.""SOPInstanceUID"" = segmentations.""SOPInstanceUID"" ensures segmentation records are scoped to the correct image instances | CONTEXT: DICOM_ALL holds study metadata with ""collection_id"", SEGMENTATIONS holds segmentation JSON keyed by ""SOPInstanceUID"". Without this join, filters on collection_id cannot limit segmentation rows to the qin_prostate_repeatability dataset | WHEN_TO_CHECK: When constructing the peripheral_zone_studies CTE to isolate prostate repeatability studies | EXAMPLE_USAGE: Correct: FROM IDC.IDC_V17.DICOM_ALL AS dicom_all_seg JOIN IDC.IDC_V17.SEGMENTATIONS AS segmentations ON dicom_all_seg.""SOPInstanceUID"" = segmentations.""SOPInstanceUID"" WHERE dicom_all_seg.""collection_id"" = 'qin_prostate_repeatability' Incorrect: FROM IDC.IDC_V17.SEGMENTATIONS AS segmentations WHERE segmentations.""collection_id"" = 'qin_prostate_repeatability'  -- SEGMENTATIONS has no collection_id and misses the proper link to DICOM_ALL"
176,sf_bq390,db,where,SEGMENTATIONS,all,str,all,"VERIFY: The segmentation filters must use segmentations.""SegmentedPropertyCategory"":CodeMeaning::STRING = 'Anatomical Structure' AND CONTAINS(segmentations.""SegmentedPropertyType"":CodeMeaning::STRING, 'Peripheral zone') to accurately isolate peripheral zone structures | CONTEXT: SEGMENTATIONS stores properties in JSON form; the Category field denotes that it’s an anatomical structure and Type contains the specific region name. Using the correct JSON paths and functions avoids including unrelated segmentation types | WHEN_TO_CHECK: When filtering SEGMENTATIONS rows within peripheral_zone_studies CTE | EXAMPLE_USAGE: Correct: WHERE segmentations.""SegmentedPropertyCategory"":CodeMeaning::STRING = 'Anatomical Structure' AND CONTAINS(segmentations.""SegmentedPropertyType"":CodeMeaning::STRING, 'Peripheral zone') Incorrect: WHERE segmentations.""AnatomicRegion"" = 'Peripheral zone'  -- wrong column name and misses JSON structure"
177,sf_bq390,generic,join;where,all,all,all,all,"VERIFY: JOIN clauses include all necessary key columns before applying filters from joined tables | PRINCIPLE: Ensuring that join conditions correctly match primary keys prevents implicit cross-joins or misaligned filtering when you limit on fields from the secondary table | WHEN_TO_APPLY: Whenever combining two tables where one constrains the dataset (e.g., metadata table limiting IDs for a detail table) | EXAMPLE_USAGE: Situation: Table A(id, value), Table B(id, type) Correct: SELECT * FROM A JOIN B ON A.id = B.id WHERE B.type = 'desired' Incorrect: SELECT * FROM A, B WHERE B.type = 'desired'  -- missing A.id = B.id causes cartesian product and misfiltered rows"
178,sf_bq390,generic,where,all,all,all,all,"VERIFY: Use database JSON extraction or search functions when filtering nested JSON fields instead of direct pattern matching on text | PRINCIPLE: JSON-specific functions accurately target keys and values in nested structures, avoiding false matches or misses due to formatting differences | WHEN_TO_APPLY: Whenever you need to filter rows based on the contents of a JSON or variant-typed column | EXAMPLE_USAGE: Situation: table T(json_col) where json_col = '{""property"":{""category"":""X"",""type"":""Y""}}' Correct: SELECT * FROM T WHERE JSON_VALUE(json_col, '$.property.category') = 'X' AND CONTAINS(JSON_QUERY(json_col, '$.property.type'), 'Y') Incorrect: SELECT * FROM T WHERE json_col LIKE '%""category"":""X""%' AND json_col LIKE '%""type"":""Y""%'  -- can match unintended text or miss nested formats"
179,sf_bq390,question,NA,NA,NA,NA,NA,The peripheral_zone_studies CTE was modified to join through DICOM_ALL on SOPInstanceUID (ensuring correct collection filtering) and use the appropriate segmentation JSON fields (SegmentedPropertyCategory and SegmentedPropertyType) to isolate “Peripheral zone” structures.
180,sf002,db,filter;where,FINANCE__ECONOMICS.CYBERSYN.financial_institution_timeseries,FINANCE__ECONOMICS.CYBERSYN.financial_institution_timeseries.variable,str,all,"VERIFY: The big_banks CTE must filter ts.""VARIABLE"" = 'ASSET' instead of 'ASSET5' | CONTEXT: big_banks CTE selects total asset values from the time series table ts and entity table ent, so using the correct variable identifier is essential to retrieve actual asset figures | WHEN_TO_CHECK: When defining or reviewing the big_banks CTE’s WHERE clause on ts.""VARIABLE"" | EXAMPLE_USAGE: Correct: … WITH big_banks AS ( SELECT ent.""NAME"", ts.""VALUE"" FROM time_series AS ts JOIN entities AS ent ON ts.""ENTITY_ID"" = ent.""ID"" WHERE ts.""VARIABLE"" = 'ASSET' … Incorrect: WHERE ts.""VARIABLE"" = 'ASSET5'  -- this returns no or wrong data"
181,sf002,db,join;inner join;filter,FINANCE__ECONOMICS.CYBERSYN.FINANCIAL_INSTITUTION_ATTRIBUTES,all,str,all,"VERIFY: The INNER JOIN between ts and FINANCE__ECONOMICS.CYBERSYN.FINANCIAL_INSTITUTION_ATTRIBUTES (alias att) must include both ts.""VARIABLE"" = att.""VARIABLE"" AND att.""VARIABLE_NAME"" = '% Insured (Estimated)' AND att.""FREQUENCY"" = 'Quarterly' | CONTEXT: Ensures that only the estimated insured deposit ratios at a quarterly frequency are joined in, replacing manual deposit calculations | WHEN_TO_CHECK: Whenever joining time series data with the attributes table for percent-insured metrics | EXAMPLE_USAGE: Correct: … FROM time_series AS ts INNER JOIN FINANCE__ECONOMICS.CYBERSYN.FINANCIAL_INSTITUTION_ATTRIBUTES AS att ON ts.""VARIABLE"" = att.""VARIABLE"" AND att.""VARIABLE_NAME"" = '% Insured (Estimated)' AND att.""FREQUENCY"" = 'Quarterly' … Incorrect: INNER JOIN FINANCE__ECONOMICS.CYBERSYN.FINANCIAL_INSTITUTION_ATTRIBUTES AS att ON ts.""VARIABLE"" = att.""VARIABLE""  -- missing attribute filters"
182,sf002,db,select,FINANCE__ECONOMICS.CYBERSYN.FINANCIAL_INSTITUTION_ENTITIES,FINANCE__ECONOMICS.CYBERSYN.FINANCIAL_INSTITUTION_ENTITIES.name,str,all,"VERIFY: The final SELECT clause should include only ent.""NAME"" and no other columns | CONTEXT: The business requirement is to output a ranked list of bank names, so extraneous columns must be removed | WHEN_TO_CHECK: At the end of the query before ORDER BY | EXAMPLE_USAGE: Correct: SELECT ent.""NAME"" FROM … Incorrect: SELECT ent.""NAME"", ts.""VALUE""  -- returns unwanted metric values"
183,sf002,db,order by,FINANCE__ECONOMICS.CYBERSYN.financial_institution_timeseries,FINANCE__ECONOMICS.CYBERSYN.financial_institution_timeseries.value,numeric,all,"VERIFY: The ORDER BY clause must use (1 - ts.""VALUE"") DESC to rank banks by uninsured deposit ratio in descending order | CONTEXT: Sorting by the complement of the insured ratio yields the banks with the highest uninsured exposure first | WHEN_TO_CHECK: When adding or reviewing the ORDER BY on the final query | EXAMPLE_USAGE: Correct: … ORDER BY (1 - ts.""VALUE"") DESC Incorrect: ORDER BY ts.""VALUE"" ASC  -- sorts by insured ratio instead"
184,sf002,question,NA,NA,NA,NA,NA,"The original query used the wrong asset variable (`ASSET5`) and manual deposit calculations. The fix switches to the `ASSET` variable CTE, joins the attributes table to directly use the '% Insured (Estimated)' variable, and adjusts the SELECT and ORDER BY to match the GOLD SQL’s single-column name list."
185,sf_bq028,db,window;partition by;order by,DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONS,all,all,all,"VERIFY: HighestReleases CTE uses a window function on DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONS to select only the latest Version per Name | CONTEXT: PACKAGEVERSIONS table contains multiple Version entries per package Name; selecting the latest version requires partitioning by Name and ordering by Version DESC | WHEN_TO_CHECK: When defining the HighestReleases CTE | EXAMPLE_USAGE: Correct: WITH HighestReleases AS ( SELECT Name, Version, ROW_NUMBER() OVER(PARTITION BY Name ORDER BY Version DESC) AS rn FROM DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONS SELECT Name, Version FROM HighestReleases WHERE rn = 1; Incorrect: WITH Latest AS ( SELECT Name, MAX(Version) AS Version FROM DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONS GROUP BY Name)"
186,sf_bq028,db,where;filter,DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONTOPROJECT,all,all,all,"VERIFY: PVP CTE filters DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONTOPROJECT on System='NPM' and ProjectType='GITHUB' before joining to HighestReleases | CONTEXT: PACKAGEVERSIONTOPROJECT contains multiple systems and project types; filtering early limits rows to relevant NPM GitHub projects | WHEN_TO_CHECK: When constructing the PVP CTE | EXAMPLE_USAGE: Correct: WITH PVP AS ( SELECT Name, Version, ProjectName, ProjectType FROM DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONTOPROJECT WHERE System = 'NPM' AND ProjectType = 'GITHUB' Incorrect: WITH PVP AS ( SELECT Name, Version, ProjectName, ProjectType FROM DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONTOPROJECT PVP JOIN HighestReleases HR ON PVP.Name = HR.Name AND PVP.Version = HR.Version - Filters applied after join can multiply rows"
187,sf_bq028,db,join,DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONTOPROJECT,all,all,all,"VERIFY: PVP CTE join to HighestReleases includes both Name and Version equality conditions | CONTEXT: Ensures only releases matching the computed latest versions are selected | WHEN_TO_CHECK: When joining PVP to HighestReleases in the CTE definition | EXAMPLE_USAGE: Correct: WITH PVP AS ( SELECT PVP.Name, PVP.Version, PVP.ProjectName, PVP.ProjectType FROM DEPS_DEV_V1.DEPS_DEV_V1.PACKAGEVERSIONTOPROJECT PVP JOIN HighestReleases HR ON PVP.Name = HR.Name AND PVP.Version = HR.Version WHERE PVP.System = 'NPM' AND PVP.ProjectType = 'GITHUB' Incorrect: ... ON PVP.Name = HR.Name   -- misses Version, includes non-latest versions"
188,sf_bq028,db,join;order by,DEPS_DEV_V1.DEPS_DEV_V1.PROJECTS,all,all,all,"VERIFY: Final SELECT joins PVP CTE to DEPS_DEV_V1.DEPS_DEV_V1.PROJECTS on PVP.ProjectType = P.Type AND PVP.ProjectName = P.Name to retrieve StarsCount | CONTEXT: PROJECTS table identifies entries by Type and Name; using both ensures correct matching to package-version associations | WHEN_TO_CHECK: When combining package-version data with project metadata for ordering | EXAMPLE_USAGE: Correct: SELECT PVP.Name, PVP.Version FROM PVP JOIN DEPS_DEV_V1.DEPS_DEV_V1.PROJECTS P ON PVP.ProjectType = P.Type AND PVP.ProjectName = P.Name ORDER BY P.StarsCount DESC; Incorrect: ... ON PVP.ProjectName = P.Name   -- ignores ProjectType, may match wrong projects"
189,sf_bq028,generic,window;partition by;order by;aggregation,all,all,all,all,"VERIFY: Use window functions with PARTITION BY and ORDER BY to retrieve the latest row per group rather than relying solely on aggregation | PRINCIPLE: Window functions allow selecting full rows based on rank within partitions, preserving all columns | WHEN_TO_APPLY: Whenever selecting the top or latest record for each group in a table | EXAMPLE_USAGE: Correct: WITH LatestEvents AS ( SELECT *, ROW_NUMBER() OVER(PARTITION BY entity_id ORDER BY occurred_at DESC) AS rn FROM events SELECT * FROM LatestEvents WHERE rn = 1; Incorrect: SELECT entity_id, MAX(occurred_at) FROM events GROUP BY entity_id;   -- loses other event columns"
190,sf_bq028,generic,join,all,all,all,all,"VERIFY: Always include all components of composite keys in JOIN conditions to avoid unintended cross-matching | PRINCIPLE: Composite keys uniquely identify records; omitting any part leads to incorrect joins and duplicated or missing data | WHEN_TO_APPLY: Whenever joining tables that rely on multi-column keys | EXAMPLE_USAGE: Correct: SELECT * FROM Orders O JOIN OrderItems I ON O.order_id = I.order_id AND O.customer_id = I.customer_id; Incorrect: ... ON O.order_id = I.order_id;   -- misses customer_id, may mix customers"
191,sf_bq028,generic,filter;join,all,all,all,all,"VERIFY: Apply filters as early as possible (in CTEs or subqueries) to limit intermediate datasets and improve join performance and accuracy | PRINCIPLE: Early filtering reduces row counts and prevents irrelevant data from propagating through joins | WHEN_TO_APPLY: When a subset of a table is repeatedly used across joins or aggregations | EXAMPLE_USAGE: Correct: WITH ActiveUsers AS ( SELECT * FROM users WHERE status = 'ACTIVE' SELECT AU.id, O.order_total FROM ActiveUsers AU JOIN orders O ON AU.id = O.user_id; Incorrect: SELECT U.id, O.order_total FROM users U JOIN orders O ON U.id = O.user_id WHERE U.status = 'ACTIVE';   -- joins all users before filtering"
192,sf_bq028,generic,join;order by,all,all,all,all,"VERIFY: When ordering final results by a metric from a joined table, confirm the join preserves one-to-one relationships to avoid skewed rankings | PRINCIPLE: Incorrect or missing join predicates can duplicate rows, inflating metrics and misordering results | WHEN_TO_APPLY: When ranking or selecting top-N based on joined metrics | EXAMPLE_USAGE: Correct: SELECT A.id, B.score FROM A JOIN B ON A.id = B.a_id ORDER BY B.score DESC; Incorrect: SELECT A.id, B.score FROM A - missing ON clause yields CROSS JOIN JOIN B ORDER BY B.score DESC;   -- duplicates A rows for every B row"
193,sf_bq028,question,NA,NA,NA,NA,NA,"Replaced the single-table approach with two CTEs—HighestReleases to pick the true latest version per package, and PVP to link releases to projects—then joined to PROJECTS for StarsCount to produce the correct top-8 list."
194,sf_bq155,db,aggregation;avg;cast,TCGA_HG38_DATA_V0.TCGA_HG38_DATA_V0.RNASEQ_GENE_EXPRESSION,TCGA_HG38_DATA_V0.TCGA_HG38_DATA_V0.RNASEQ_GENE_EXPRESSION.HTSeq__Counts,numeric,all,"VERIFY: In snora31_expr CTE, ensure log transformation is inside the average: use AVG(LOG(10, CAST(r.""HTSeq__Counts"" AS FLOAT) + 1)) rather than LOG(10, AVG(CAST(r.""HTSeq__Counts"" AS FLOAT)) + 1) | CONTEXT: snora31_expr CTE computes average HTSeq__Counts for SNORA31 and must average log-transformed counts to reflect correct data distribution | WHEN_TO_CHECK: When aggregating HTSeq__Counts in snora31_expr CTE | EXAMPLE_USAGE: Correct: SELECT AVG(LOG(10, CAST(r.""HTSeq__Counts"" AS FLOAT) + 1)) AS avg_log_counts FROM rnaseq_data r WHERE r.symbol = 'SNORA31'; Incorrect: SELECT LOG(10, AVG(CAST(r.""HTSeq__Counts"" AS FLOAT)) + 1) AS avg_log_counts FROM rnaseq_data r WHERE r.symbol = 'SNORA31';"
195,sf_bq155,db,division;null_handling,final_result,final_result.t_statistic,numeric,all,"VERIFY: In final_result CTE, ensure t_statistic uses absolute Pearson correlation: ABS(pearson_r) * SQRT((n_samples - 2) / NULLIF(1 - pearson_r * pearson_r, 0)) rather than using pearson_r directly | CONTEXT: final_result CTE derives a two-sided t-statistic from Pearson’s r; using ABS ensures t is non-negative regardless of correlation sign | WHEN_TO_CHECK: When defining t_statistic calculation in final_result CTE | EXAMPLE_USAGE: Correct: SELECT ABS(pearson_r) SQRT((n_samples - 2) / NULLIF(1 - pearson_r * pearson_r, 0)) AS t_statistic FROM correlation_results; Incorrect: SELECT pearson_r SQRT((n_samples - 2) / NULLIF(1 - pearson_r * pearson_r, 0)) AS t_statistic FROM correlation_results;"
196,sf_bq155,db,order by,all,symbol2,str,all,"VERIFY: Final SELECT projects only the required columns and orders by symbol2: SELECT 'SNORA31' AS ""symbol1"", ""mirna_id"" AS ""symbol2"", t_statistic AS ""t"" ORDER BY ""symbol2"" | CONTEXT: Output schema must match GOLD result with three columns in the correct order and sorted by symbol2 | WHEN_TO_CHECK: In the final projection of results before output | EXAMPLE_USAGE: Correct: SELECT 'SNORA31' AS ""symbol1"", mirna_id AS ""symbol2"", t_statistic AS ""t"" FROM final_result ORDER BY ""symbol2""; Incorrect: SELECT mirna_id AS ""symbol2"", 'SNORA31' AS ""symbol1"", t_statistic AS ""t"" FROM final_result;"
197,sf_bq155,generic,aggregation;avg,all,all,all,all,"VERIFY: Mathematical transformation and aggregation order must align with analytical intent | PRINCIPLE: Applying a non-linear transformation before aggregation produces different results than transforming an aggregated summary; ensure the order matches the statistical requirement | WHEN_TO_APPLY: Whenever computing aggregate statistics (AVERAGE, SUM, etc.) on transformed data (LOG, SQRT, etc.) | EXAMPLE_USAGE: Correct: SELECT AVG(LOG(value + 1)) AS avg_log_value FROM measurements; Incorrect: SELECT LOG(AVG(value) + 1) AS avg_log_value FROM measurements;"
198,sf_bq155,generic,division;null_handling,all,all,numeric,all,VERIFY: Two-sided test statistics derived from correlation coefficients should use absolute correlation magnitude | PRINCIPLE: Two-sided t-statistics depend on the magnitude of correlation irrespective of sign to reflect test symmetry | WHEN_TO_APPLY: When calculating t-statistics or z-scores from correlation or effect size measures | EXAMPLE_USAGE: Correct: SELECT ABS(r) * SQRT((n - 2) / (1 - r * r)) AS t_statistic FROM stats; Incorrect: SELECT r * SQRT((n - 2) / (1 - r * r)) AS t_statistic FROM stats;
199,sf_bq155,generic,order by,all,all,all,all,"VERIFY: Final query output must exactly match specified columns and ordering | PRINCIPLE: Downstream consumers and validation scripts expect an exact column schema and order; discrepancies cause failures or misinterpretation | WHEN_TO_APPLY: When writing the outermost SELECT for reports, API responses, or automated grading | EXAMPLE_USAGE: Correct: SELECT colA AS ""A"", colB AS ""B"" FROM data_table ORDER BY ""B""; Incorrect: SELECT colB AS ""B"", colA AS ""A"" FROM data_table"
200,sf_bq155,question,NA,NA,NA,NA,NA,"Adjusted the log‐transform aggregation to AVG(LOG) for SNORA31, applied ABS to the correlation in the t‐statistic, and projected the three required columns in alphabetical order to align with the GOLD output."
201,sf_bq209,db,filter;cast,PATENTS.PATENTS.PUBLICATIONS,PATENTS.PATENTS.PUBLICATIONS.grant_date,int,Yes,"VERIFY: The patents_sample CTE must filter t1.""grant_date"" by converting non‐zero integer values to actual dates using TO_DATE(CASE WHEN t1.""grant_date"" != 0 THEN TO_CHAR(t1.""grant_date"") ELSE NULL END,'YYYYMMDD') BETWEEN TO_DATE('20100101','YYYYMMDD') AND TO_DATE('20101231','YYYYMMDD') | CONTEXT: The patents table stores grant_date as an integer where 0 indicates missing; without this conversion and zero check, invalid dates slip through or comparisons misuse raw integers. | WHEN_TO_CHECK: When building the initial CTE to select patents granted in 2010, ensure the grant_date filter uses the CASE WHEN → TO_CHAR → TO_DATE pattern rather than a raw numeric BETWEEN. | EXAMPLE_USAGE: Correct: WITH patents_sample AS ( SELECT * FROM patents t1 WHERE TO_DATE(CASE WHEN t1.""grant_date"" != 0 THEN TO_CHAR(t1.""grant_date"") ELSE NULL END,'YYYYMMDD') BETWEEN TO_DATE('20100101','YYYYMMDD') AND TO_DATE('20101231','YYYYMMDD') Incorrect: WHERE t1.""grant_date"" BETWEEN 20100101 AND 20101231"
202,sf_bq209,db,join;filter,PATENTS.PATENTS.PUBLICATIONS,PATENTS.PATENTS.PUBLICATIONS.citation,all,all,"VERIFY: The forward_citation CTE must join t2 (filing_date subquery) and t3 (lateral flatten subquery) separately and include the citation_date filter in the ON clause as  t3.citation_date BETWEEN t2.filing_date AND DATEADD(YEAR,10,t2.filing_date) | CONTEXT: Properly isolating the filing_date extraction (t2) and the JSON flatten (t3) prevents misaligned joins and ensures only citations within ten years of filing are counted. | WHEN_TO_CHECK: When defining forward_citation, ensure two LEFT JOINs are used—one to compute t2.filing_date and another lateral flatten to produce t3.citation_date—and that the 10-year window appears in the ON condition. | EXAMPLE_USAGE: Correct: WITH forward_citation AS ( SELECT t1.patent_id, t3.cited_patent_id FROM patents_sample t1 LEFT JOIN (SELECT patent_id, TO_DATE(...,'YYYYMMDD') AS filing_date FROM patents) t2 ON t1.patent_id = t2.patent_id LEFT JOIN LATERAL ( SELECT flatten.value:""cited_patent_id""::VARCHAR AS cited_patent_id, TO_DATE(CASE WHEN flatten.value:""date"" != '' THEN flatten.value:""date""::VARCHAR ELSE NULL END,'YYYYMMDD') AS citation_date FROM LATERAL FLATTEN(input => t1.""forward_citations"") flatten  t3 ON t1.patent_id = t3.patent_id AND t3.citation_date BETWEEN t2.filing_date AND DATEADD(YEAR,10,t2.filing_date) Incorrect: LEFT JOIN LATERAL FLATTEN(input => t1.""forward_citations"") f ON t1.patent_id = f.patent_id WHERE f.date BETWEEN t2.filing_date AND DATEADD(YEAR,10,t2.filing_date)"
203,sf_bq209,generic,filter;cast;date,all,all,all,Yes,"VERIFY: Date filters on raw integer or string date columns should wrap values in a CASE WHEN to nullify invalid placeholders before converting to DATE with TO_DATE. | PRINCIPLE: Ensuring non-date placeholders (e.g., 0 or empty strings) are turned into NULL prevents conversion errors and unintended inclusion of bad data. | WHEN_TO_APPLY: Whenever filtering on columns that store dates as integers or text and contain sentinel values for missing dates. | EXAMPLE_USAGE: Correct: WHERE TO_DATE( CASE WHEN raw_date_int != 0 THEN TO_CHAR(raw_date_int) ELSE NULL END, 'YYYYMMDD' BETWEEN DATE '2021-01-01' AND DATE '2021-12-31' Incorrect: WHERE raw_date_int BETWEEN 20210101 AND 20211231"
204,sf_bq209,generic,join;unnest,all,all,all,all,"VERIFY: Complex nested-data flattening should be split into separate lateral or CTE subqueries and joined with explicit ON conditions rather than flattening and filtering in one step. | PRINCIPLE: Decomposing JSON/array flatten operations into distinct subqueries isolates transformations and makes join filters clearer and less error-prone. | WHEN_TO_APPLY: When extracting elements from nested JSON or array columns and then filtering them based on values from the base table. | EXAMPLE_USAGE: Correct: WITH base AS (SELECT id, json_col FROM source), extracted AS ( SELECT id, elem.value AS item, TO_DATE(elem.value:""date""::VARCHAR,'YYYYMMDD') AS item_date FROM base, LATERAL FLATTEN(input => json_col) elem SELECT b.id, e.item FROM base b LEFT JOIN extracted e ON b.id = e.id AND e.item_date BETWEEN b.start_date AND DATEADD(YEAR,5,b.start_date) Incorrect: SELECT b.id, f.value AS item FROM source b LEFT JOIN LATERAL FLATTEN(input => b.json_col) f ON f.value:""date""::VARCHAR BETWEEN TO_CHAR(b.start_date,'YYYYMMDD') AND TO_CHAR(DATEADD(YEAR,5,b.start_date),'YYYYMMDD')"
205,sf_bq209,generic,join;filter,all,all,all,all,"VERIFY: Conditions on columns from a LEFT JOINed table belong in the ON clause, not in WHERE, to avoid inadvertently turning the OUTER join into an INNER join. | PRINCIPLE: Filters placed in WHERE on the right side of a LEFT JOIN remove unmatched left-table rows, effectively negating the OUTER join. | WHEN_TO_APPLY: Anytime you filter on columns from a table brought in via LEFT JOIN. | EXAMPLE_USAGE: Correct: SELECT a.*, b.status FROM orders a LEFT JOIN shipments b ON a.order_id = b.order_id AND b.ship_date BETWEEN a.order_date AND DATEADD(DAY,30,a.order_date) Incorrect: SELECT a.*, b.status FROM orders a LEFT JOIN shipments b ON a.order_id = b.order_id WHERE b.ship_date BETWEEN a.order_date AND DATEADD(DAY,30,a.order_date)"
206,sf_bq209,question,NA,NA,NA,NA,NA,"The original query filtered only US utility patents by raw grant_date integers and used a direct lateral flatten join, yielding 8. Updating the initial CTE to use TO_DATE(CASE WHEN…) for grant_date boundaries and restructuring forward citations via two LEFT JOIN subqueries (matching the GOLD SQL’s t2/t3 pattern) restored the correct 11 patents."
207,sf_bq233,db,join;filter,SAMPLE_FILES,SAMPLE_FILES.file_id,int,all,"VERIFY: extracted_modules CTE joins SAMPLE_FILES to SAMPLE_CONTENTS on file_id and filters by file_extension ('.py' or '.R') and content_line regex patterns for imports/libraries | CONTEXT: extracted_modules uses SAMPLE_FILES.file_id, SAMPLE_FILES.file_extension and SAMPLE_CONTENTS.content_line to build an array of module names; incorrect or missing join or filters will include irrelevant files or miss valid imports | WHEN_TO_CHECK: when defining the extracted_modules CTE before aggregating modules | EXAMPLE_USAGE:"
208,sf_bq233,db,unnest;aggregation,extracted_modules,extracted_modules.modules,all,all,"VERIFY: module_counts CTE uses UNNEST(modules) to flatten the modules array and groups by file_extension and module_name to count occurrences | CONTEXT: module_counts takes the modules ARRAY from extracted_modules and must explode it with UNNEST, then GROUP BY f.file_extension and module_name to get accurate counts per language | WHEN_TO_CHECK: when constructing module_counts directly after extracted_modules | EXAMPLE_USAGE:"
209,sf_bq233,db,filter,module_counts,total_count,int,all,VERIFY: python CTE selects module_name and total_count AS python_imports from module_counts WHERE language_ext = '.py' | CONTEXT: python CTE isolates only Python modules by filtering on file_extension and renaming the count column to python_imports to distinguish from R counts | WHEN_TO_CHECK: when splitting out Python data for later UNION ALL | EXAMPLE_USAGE:
210,sf_bq233,db,union;order by,all,all,all,all,"VERIFY: The final SELECT unites python and rlanguage CTEs with UNION ALL, ensuring both queries project the same number of columns with matching names and applies ORDER BY total_imports DESC | CONTEXT: combining two CTEs (python, rlanguage) requires consistent column ordering (module_name, language, import_count) to produce a single result set | WHEN_TO_CHECK: when composing the final output from separate language-specific CTEs | EXAMPLE_USAGE:"
211,sf_bq233,generic,join,all,all,all,all,"VERIFY: JOIN clauses include explicit ON conditions matching all key columns when combining tables | PRINCIPLE: to avoid cartesian products or mismatched rows, all relevant key columns must appear in the JOIN ON clause | WHEN_TO_APPLY: whenever joining two tables on a shared key (e.g., file_id) to merge metadata and content | EXAMPLE_USAGE:"
212,sf_bq233,generic,unnest;aggregation,all,all,all,all,"ENSURE: Arrays of values must be flattened with UNNEST before aggregation or filtering | PRINCIPLE: SQL engines treat arrays as single entities; to process individual elements, you must UNNEST the array into rows | WHEN_TO_APPLY: whenever you need to count or filter elements within an array column | EXAMPLE_USAGE:"
213,sf_bq233,generic,where;filter,all,all,all,all,"VERIFY: WHERE clauses mixing AND and OR conditions use parentheses to enforce intended logic | PRINCIPLE: SQL evaluates AND before OR, so parentheses are required to group conditions correctly | WHEN_TO_APPLY: whenever combining multiple filter conditions involving different columns | EXAMPLE_USAGE:"
214,sf_bq233,generic,union,all,all,all,all,ENSURE: Each branch of a UNION ALL returns the same number of columns with compatible data types and consistent aliases | PRINCIPLE: UNION ALL combines result sets vertically but demands identical column structure to avoid errors or misalignment | WHEN_TO_APPLY: when merging data from separate subqueries or CTEs into a single query output | EXAMPLE_USAGE:
215,sf_bq233,question,NA,NA,NA,NA,NA,The original one-off REGEXP_SUBSTR was replaced with the GOLD-aligned multi-CTE extraction and aggregation pipeline to correctly count Python imports and R libraries across all files.
216,sf_bq345,db,cte_definition,IDC.IDC_V17.DICOM_ALL,all,all,all,"VERIFY: The main CTE for unreferenced images must select from IDC.IDC_V17.DICOM_ALL instead of IDC.IDC_V17.DICOM_PIVOT | CONTEXT: The DICOM_ALL table contains all DICOM metadata and sequence arrays needed to identify truly unreferenced SEG and RTSTRUCT images, whereas DICOM_PIVOT lacks complete sequence information | WHEN_TO_CHECK: When defining the primary CTE to extract unreferenced segmentation and RTSTRUCT images for analysis | EXAMPLE_USAGE:"
217,sf_bq345,db,filter;where,IDC.IDC_V17.DICOM_ALL,all,all,all,"VERIFY: The WHERE clause must include ARRAY_SIZE(""ReferencedSeriesSequence"") = 0 AND ARRAY_SIZE(""ReferencedImageSequence"") = 0 AND ARRAY_SIZE(""SourceImageSequence"") = 0 | CONTEXT: The ReferencedSeriesSequence, ReferencedImageSequence, and SourceImageSequence columns in DICOM_ALL are arrays that list references to other series or images; zero-length arrays indicate no references | WHEN_TO_CHECK: When filtering for segmentation or RTSTRUCT images that have no references at all | EXAMPLE_USAGE:"
218,sf_bq345,db,join,IDC.IDC_V17.DICOM_ALL,all,all,all,ENSURE: Joins to the unreferenced_segmentations and isolated_images CTEs are removed when using direct array-size filters on DICOM_ALL | CONTEXT: Legacy queries used separate CTEs and joins to find unreferenced images; DICOM_ALL’s array columns allow combining this logic into a single CTE | WHEN_TO_CHECK: When refactoring or validating queries that shift from join-based reference checks to array-based filtering | EXAMPLE_USAGE:
219,sf_bq345,generic,all,all,all,all,all,VERIFY: The FROM clause must be updated to the correct source table or view whenever the underlying dataset origin changes | PRINCIPLE: Queries should reference the table or view that contains all required columns and relationships; failing to update can lead to missing data or incorrect results | WHEN_TO_APPLY: Whenever a new or replacement table/view is introduced to consolidate or augment the original data source | EXAMPLE_USAGE:
220,sf_bq345,generic,filter;where,all,all,all,all,VERIFY: Use array-length or size functions in WHERE clauses to filter out rows with empty nested collections instead of constructing separate join-based filters | PRINCIPLE: Leveraging built-in array functions simplifies queries by directly checking nested data absence and eliminates unnecessary CTEs or joins | WHEN_TO_APPLY: Whenever filtering records based on the absence of elements in multi-valued or array-type columns | EXAMPLE_USAGE:
221,sf_bq345,question,NA,NA,NA,NA,NA,"Switched to DICOM_ALL and used ARRAY_SIZE filters to directly identify unreferenced SEG/RTSTRUCT images, matching the GOLD SQL logic."
222,sf_bq347,db,cte_definition;where,IDC.IDC_V17.DICOM_ALL,all,all,all,"VERIFY: CTE union_sops selects both ""SOPInstanceUID"" and ""Modality"" columns from IDC.IDC_V17.DICOM_ALL for the given SeriesInstanceUID | CONTEXT: The CTE must capture MR SOP instances along with their modality from DICOM_ALL to enable modality-based counting | WHEN_TO_CHECK: When defining the MR series portion of the union_sops CTE | EXAMPLE_USAGE:"
223,sf_bq347,db,join,IDC.IDC_V17.SEGMENTATIONS,SEGMENTATIONS.SOPInstanceUID,str,all,"VERIFY: Join between SEGMENTATIONS and DICOM_ALL on s.""SOPInstanceUID"" = da.""SOPInstanceUID"" is present in union_sops CTE | CONTEXT: The join retrieves modality for segmentation SOPs by matching SOPInstanceUID in both tables | WHEN_TO_CHECK: When adding segmentation instances to the union_sops CTE | EXAMPLE_USAGE:"
224,sf_bq347,db,aggregation;count;group by;order by;limit,all,union_sops.Modality,str,all,"VERIFY: Final SELECT groups by ""Modality"" from union_sops rather than using QUALIFY on a derived table | CONTEXT: Aggregation must occur directly on the union_sops CTE to count SOPs per modality correctly | WHEN_TO_CHECK: When calculating the modality with the highest sop_count | EXAMPLE_USAGE:"
225,sf_bq347,db,where,IDC.IDC_V17.DICOM_ALL,DICOM_ALL.SeriesInstanceUID,str,all,"VERIFY: Use IDC.IDC_V17.DICOM_ALL instead of DICOM_PIVOT for sourcing MR instances and selecting Modality | CONTEXT: DICOM_ALL contains the Modality column required for both MR and segmentation instances, whereas DICOM_PIVOT does not | WHEN_TO_CHECK: When sourcing SOPInstanceUIDs for modality-based union | EXAMPLE_USAGE:"
226,sf_bq347,generic,union,all,all,all,all,"VERIFY: Use UNION ALL instead of UNION when combining result sets that include duplicate identifiers to ensure accurate aggregation counts | PRINCIPLE: UNION removes duplicate rows by default, which can undercount when counting aggregated results, whereas UNION ALL preserves all rows | WHEN_TO_APPLY: When unifying data from multiple sources prior to counting or aggregation | EXAMPLE_USAGE:"
227,sf_bq347,generic,aggregation;group by,all,all,all,all,VERIFY: Ensure all non-aggregated columns in a SELECT with aggregation appear in the GROUP BY clause | PRINCIPLE: SQL requires grouping by every column in the SELECT list that is not within an aggregate function to avoid errors or unintended results | WHEN_TO_APPLY: When writing queries that perform aggregation with GROUP BY | EXAMPLE_USAGE:
228,sf_bq347,generic,join,all,all,all,all,VERIFY: Retrieve missing attributes through explicit JOINs rather than selecting incomplete data from a single table | PRINCIPLE: Attributes not present in the primary table must be fetched via joins to ensure completeness and avoid null or placeholder values | WHEN_TO_APPLY: When a required column resides in a related table | EXAMPLE_USAGE:
229,sf_bq347,question,NA,NA,NA,NA,NA,"Original logic counted MR SOPs from DICOM_PIVOT and segmentation SOPs without modality info. The fix unified both sources via DICOM_ALL—joining SEGMENTATIONS to DICOM_ALL—and grouped by the “Modality” column, yielding the correct SEG count of 1653."
230,sf011,db,filter,census_values,census_values.MetricID,str,all,"VERIFY: The bg_pop_2021 CTE includes a WHERE v.""MetricID"" = 'B01003_001E' filter | CONTEXT: bg_pop_2021 reads block‐group census rows from the census_values table under various metrics; it must isolate the total population metric (ID B01003_001E) before any downstream join or aggregation | WHEN_TO_CHECK: When defining or validating the bg_pop_2021 CTE in population ratio queries | EXAMPLE_USAGE: Correct: WITH bg_pop_2021 AS ( SELECT v.""GEOID"", v.""CensusValue"" FROM census_values v WHERE v.""MetricID"" = 'B01003_001E' Incorrect (missing filter): WITH bg_pop_2021 AS ( SELECT v.""GEOID"", v.""CensusValue"" FROM census_values v"
231,sf011,db,aggregation;sum;group by,bg_pop_2021,bg_pop_2021.CensusValue,numeric,all,"VERIFY: The tract_pop_2021 CTE aggregates block group values using SUM(""CensusValue"") AS ""TotalTractPopulation"" | CONTEXT: tract_pop_2021 computes each tract’s total population by summing the CensusValue of its block groups; without SUM the totals will be incorrect or null | WHEN_TO_CHECK: When aggregating bg_pop_2021 into tract_pop_2021 CTE | EXAMPLE_USAGE: Correct: WITH tract_pop_2021 AS ( SELECT bg.""TRACTCE"", SUM(bg.""CensusValue"") AS ""TotalTractPopulation"" FROM bg_pop_2021 bg GROUP BY bg.""TRACTCE"" Incorrect (omitting SUM): WITH tract_pop_2021 AS ( SELECT bg.""TRACTCE"", bg.""CensusValue"" AS ""TotalTractPopulation"" FROM bg_pop_2021 bg"
232,sf011,generic,where;filter;aggregation,all,all,all,all,"VERIFY: Filtering on the correct dimension code before aggregation | PRINCIPLE: When a table holds multiple categories or metrics in one column, you must apply the specific filter to avoid mixing unwanted categories into your aggregates | WHEN_TO_APPLY: Any time you select and summarize rows from a table that stores diverse metric or category identifiers in a single column | EXAMPLE_USAGE: Situation: A sales_metrics table has a column metric_type ('units_sold', 'revenue', etc.) and a value column metric_value. Before summing revenue, verify: Correct: SELECT SUM(metric_value) FROM sales_metrics WHERE metric_type = 'revenue'; Incorrect: SELECT SUM(metric_value) FROM sales_metrics;"
233,sf011,generic,aggregation;sum;avg;count,all,all,all,all,"VERIFY: Using the appropriate aggregate function for the intended summary measure | PRINCIPLE: Choosing SUM vs AVG vs COUNT (etc.) must align with the analytical goal—cumulative vs average vs count—otherwise results misrepresent the data | WHEN_TO_APPLY: Whenever rolling up detailed data to a higher granularity or computing summary statistics | EXAMPLE_USAGE: Situation: Rolling up daily sales to monthly total revenue. Verify: Correct: SELECT month, SUM(daily_revenue) AS monthly_revenue FROM daily_sales GROUP BY month; Incorrect: SELECT month, AVG(daily_revenue) AS monthly_revenue FROM daily_sales GROUP BY month;"
234,sf011,question,NA,NA,NA,NA,NA,"Filtered to the total population metric and aggregated block‐group values with SUM to compute each tract’s total population, enabling correct ratio calculations."
235,sf_bq187,db,join,ERC20_TOKEN_TRANSFERS,ERC20_TOKEN_TRANSFERS.token_address,str,all,VERIFY: The receivedTx CTE must join ERC20_TOKEN_TRANSFERS to tokenInfo on erc.token_address = ti.address | CONTEXT: receivedTx computes total BNB received per wallet by filtering transfers for the BNB token via tokenInfo CTE | WHEN_TO_CHECK: When constructing the receivedTx CTE to isolate BNB transfers | EXAMPLE_USAGE:
236,sf_bq187,db,join,ERC20_TOKEN_TRANSFERS,ERC20_TOKEN_TRANSFERS.token_address,str,all,VERIFY: The sentTx CTE must join ERC20_TOKEN_TRANSFERS to tokenInfo on erc.token_address = ti.address | CONTEXT: sentTx computes total BNB sent per wallet by filtering transfers for the BNB token via tokenInfo CTE | WHEN_TO_CHECK: When constructing the sentTx CTE to isolate BNB transfers | EXAMPLE_USAGE:
237,sf_bq187,db,left join;coalesce;aggregation;group by,receivedTx,receivedTx.addr,str,Yes,"VERIFY: walletBalances CTE must LEFT JOIN receivedTx r to sentTx s on r.addr = s.addr and compute balance as COALESCE(r.received,0) - COALESCE(s.sent,0) | CONTEXT: walletBalances merges received and sent aggregates per address to calculate net BNB holdings | WHEN_TO_CHECK: When aggregating per-wallet balances from receivedTx and sentTx | EXAMPLE_USAGE:"
238,sf_bq187,db,aggregation;sum,walletBalances,walletBalances.balance,numeric,all,"VERIFY: The final SELECT must SUM(balance) AS circulating_supply without additional division or filters | CONTEXT: after normalization in CTEs, final aggregation should not re-scale or exclude non-positive balances | WHEN_TO_CHECK: In the final query computing total circulating supply | EXAMPLE_USAGE:"
239,sf_bq187,generic,aggregation;cast;sum,all,all,numeric,all,"VERIFY: Unit conversions should be applied at the aggregation step on raw values, not as a post-aggregation transform | PRINCIPLE: Converting units (e.g., smallest denomination to standard) during SUM ensures consistent precision and avoids errors from large-number rounding | WHEN_TO_APPLY: Whenever summing numeric values stored in base units (like Wei, cents, or bytes) that require division by a constant factor | EXAMPLE_USAGE:"
240,sf_bq187,generic,aggregation;coalesce,all,all,numeric,Yes,"VERIFY: Always use COALESCE on aggregated columns before arithmetic operations to prevent NULL propagation | PRINCIPLE: SUM returns NULL when there are no matching rows, and arithmetic with NULL yields NULL, so COALESCE guarantees numeric results | WHEN_TO_APPLY: Whenever subtracting or adding multiple aggregates that may have zero rows for some keys | EXAMPLE_USAGE:"
241,sf_bq187,generic,left join,all,all,all,all,"VERIFY: Choose LEFT JOIN when you need to preserve all keys from the primary dataset, even if the secondary has no matches | PRINCIPLE: INNER JOIN drops non-matching rows, potentially omitting entities with zero counts, whereas LEFT JOIN retains them with NULLs | WHEN_TO_APPLY: When merging a base list of entities with another set of aggregated metrics that might be missing for some entities | EXAMPLE_USAGE:"
242,sf_bq187,question,NA,NA,NA,NA,NA,"The fix introduces tokenInfo CTE and shifts the 10^18 normalization into the receivedTx/sentTx subqueries (casting to FLOAT and dividing by POWER(10,18)), replaces the bnb_transfers approach with the GOLD query structure, and removes the end-of-query division and filter, producing the correct circulating supply."
243,sf_bq236,db,group by;aggregation,hail_events,hail_events.zipcode,str,all,"VERIFY: Grouping by hail_events.zipcode and aliasing the result as hail_event_count | CONTEXT: The hail_events table stores one record per hail occurrence with a zipcode column; grouping by zipcode ensures you count events per area rather than across the whole dataset | WHEN_TO_CHECK: When computing the number of hail events for each zipcode | EXAMPLE_USAGE: Correct: ```sql SELECT zipcode, COUNT(*) AS hail_event_count FROM hail_events GROUP BY zipcode; ``` Incorrect (missing GROUP BY): ```sql SELECT zipcode, COUNT(*) AS hail_event_count FROM hail_events; ``` This incorrect approach returns one row with the total count instead of per-zipcode counts."
244,sf_bq236,db,order by;limit,all,all,int,all,"VERIFY: Applying ORDER BY hail_event_count DESC before LIMIT to retrieve the top zipcodes | CONTEXT: After grouping hail_events by zipcode and computing hail_event_count, sorting in descending order puts the zipcodes with the most events first | WHEN_TO_CHECK: When selecting the top-N zipcodes by hail_event_count | EXAMPLE_USAGE: Correct: ```sql SELECT zipcode, COUNT(*) AS hail_event_count FROM hail_events GROUP BY zipcode ORDER BY hail_event_count DESC LIMIT 5; ``` Incorrect (misordered clauses): ```sql SELECT zipcode, COUNT(*) AS hail_event_count FROM hail_events GROUP BY zipcode LIMIT 5 ORDER BY hail_event_count DESC; ``` This incorrect ordering is syntactically invalid and would not return the intended top 5 zipcodes."
245,sf_bq236,generic,order by;aggregation,all,all,all,all,"VERIFY: Use the aggregate alias in the ORDER BY clause rather than repeating the function | PRINCIPLE: Referencing the alias makes queries more readable and avoids potential mismatches if the expression changes | WHEN_TO_APPLY: Whenever ordering results by an aggregated value | EXAMPLE_USAGE: Correct: ```sql SELECT category, SUM(sales) AS total_sales FROM orders GROUP BY category ORDER BY total_sales DESC; ``` Incorrect: ```sql SELECT category, SUM(sales) AS total_sales FROM orders GROUP BY category ORDER BY SUM(sales) DESC; ``` Both return the same result, but using the alias is clearer and prevents errors if the aggregation formula is more complex."
246,sf_bq236,generic,order by;limit;group by,all,all,all,all,"VERIFY: Ensure LIMIT is applied after ORDER BY when retrieving top-N results from a grouped query | PRINCIPLE: SQL executes GROUP BY first, then ORDER BY, and finally LIMIT; reversing ORDER BY and LIMIT can lead to unexpected behavior or syntax errors | WHEN_TO_APPLY: When you need the highest or lowest N records from an aggregated result set | EXAMPLE_USAGE: Correct: ```sql SELECT item, COUNT(*) AS cnt FROM transactions GROUP BY item ORDER BY cnt DESC LIMIT 10; ``` Incorrect (placing LIMIT before ORDER BY is invalid): ```sql SELECT item, COUNT(*) AS cnt FROM transactions GROUP BY item LIMIT 10 ORDER BY cnt DESC; ```"
247,sf_bq236,question,NA,NA,NA,NA,NA,The original SQL already produced the correct top-5 hail event counts; no changes were required.
248,sf_bq260,db,filter;cast,THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.USERS,THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.USERS.created_at,date,all,"VERIFY: The WHERE clause in the date_filtered_users CTE uses CAST(DATEADD(second, ""created_at""/1000000.0, '1970-01-01') AS DATE) to correctly filter by date | CONTEXT: The created_at column stores microsecond-based epoch timestamps; integer division and missing CAST can truncate times and exclude boundary records | WHEN_TO_CHECK: When filtering user records by creation date in the date_filtered_users CTE | EXAMPLE_USAGE: Incorrect: ```sql WHERE DATEADD(second, ""created_at""/1000000, '1970-01-01') BETWEEN '2023-01-01' AND '2023-12-31'; ``` Correct: ```sql WHERE CAST(DATEADD(second, ""created_at""/1000000.0, '1970-01-01') AS DATE) BETWEEN '2023-01-01' AND '2023-12-31'; ```"
249,sf_bq260,db,division,all,all,all,all,"VERIFY: The conversion of epoch timestamps divides ""created_at"" by 1000000.0 rather than 1000000 to preserve fractional seconds | CONTEXT: Dividing by an integer literal causes SQL to perform integer division, losing fractional parts and altering the resulting timestamp | WHEN_TO_CHECK: When converting microsecond-based epoch values to datetime/date types anywhere in this database schema | EXAMPLE_USAGE: Incorrect: ```sql DATEADD(second, ""created_at""/1000000, '1970-01-01') ``` Correct: ```sql DATEADD(second, ""created_at""/1000000.0, '1970-01-01') ```"
250,sf_bq260,generic,filter;cast,all,all,all,all,"VERIFY: Date range filters on derived datetime expressions should explicitly CAST to DATE | PRINCIPLE: Functions like DATEADD return datetime with time portions; comparing directly to date literals can misinterpret or miss rows unless the time component is stripped | WHEN_TO_APPLY: Whenever applying >=, <=, or BETWEEN filters on expressions that return datetime or timestamp data | EXAMPLE_USAGE: Incorrect: ```sql WHERE DATEADD(day, 1, event_ts) <= '2024-06-30'; ``` Correct: ```sql WHERE CAST(DATEADD(day, 1, event_ts) AS DATE) <= '2024-06-30'; ```"
251,sf_bq260,generic,division,all,all,all,all,"VERIFY: Use decimal literals in arithmetic to enforce floating-point division when converting units | PRINCIPLE: Dividing two integers may result in integer division, truncating fractional parts; using a float literal ensures SQL applies floating-point arithmetic | WHEN_TO_APPLY: Whenever converting units (e.g., microseconds to seconds) via division in SQL calculations | EXAMPLE_USAGE: Incorrect: ```sql SELECT duration_us/1000 FROM logs; ``` Correct: ```sql SELECT duration_us/1000.0 FROM logs; ```"
252,sf_bq260,question,NA,NA,NA,NA,NA,Adjusted the date filter to CAST the epoch conversion to DATE (and use fractional division) to correctly include boundary dates.
253,sf_bq291,db,order by;limit,daily_weather,daily_weather.dist_m,numeric,all,"VERIFY: The query uses ORDER BY dist_m ASC LIMIT 1 when selecting the nearest grid point | CONTEXT: The daily_weather table contains lon, lat, and dist_m representing distance from a target location; ordering ensures the record with the smallest distance is chosen for that day | WHEN_TO_CHECK: When retrieving metrics for the single nearest grid point per date | EXAMPLE_USAGE: Correct: SELECT lon, lat, MAX_TEMP_F, MIN_TEMP_F, avg_temp_f FROM daily_weather WHERE date = '2019-07-16' ORDER BY dist_m ASC LIMIT 1; Incorrect: SELECT lon, lat, MAX_TEMP_F, MIN_TEMP_F, avg_temp_f FROM daily_weather WHERE date = '2019-07-16' LIMIT 1;  -- missing ORDER BY, may pick a non-nearest point"
254,sf_bq291,db,having,daily_weather,daily_weather.total_precip_mm,numeric,all,"VERIFY: total_precip_mm equals total_rain_mm + total_snow_mm on the same record | CONTEXT: The daily_weather table stores total_precip_mm, total_rain_mm, and total_snow_mm per day; ensuring precipitation components sum to the total prevents reporting mismatches | WHEN_TO_CHECK: When validating that daily precipitation metrics are internally consistent | EXAMPLE_USAGE: Correct: SELECT date, total_precip_mm, total_rain_mm, total_snow_mm FROM daily_weather HAVING total_precip_mm = total_rain_mm + total_snow_mm; Incorrect: SELECT date, total_precip_mm, total_rain_mm, total_snow_mm FROM daily_weather WHERE total_precip_mm <> total_rain_mm + total_snow_mm;  -- reveals inconsistencies"
255,sf_bq291,db,aggregation;avg;group by,temperature_readings,temperature_readings.avg_temp_f,numeric,all,"VERIFY: avg_temp_f is computed using AVG(temp_f) across all observations rather than (MAX_TEMP_F + MIN_TEMP_F)/2 | CONTEXT: The daily_weather table’s avg_temp_f should reflect the true mean of all temperature readings, not the midrange | WHEN_TO_CHECK: When calculating and validating daily average temperature values | EXAMPLE_USAGE: Correct: SELECT date, AVG(temp_f) AS avg_temp_f FROM temperature_readings WHERE date = '2019-07-16' GROUP BY date; Incorrect: SELECT date, (MAX(temp_f) + MIN(temp_f)) / 2 AS avg_temp_f FROM temperature_readings WHERE date = '2019-07-16' GROUP BY date;  -- yields midrange, not true average"
256,sf_bq291,generic,order by;limit,all,all,all,all,"VERIFY: Queries using LIMIT to select the “top” or “nearest” record must include an explicit ORDER BY clause on the ranking metric | PRINCIPLE: Without ORDER BY, LIMIT returns an arbitrary subset of rows rather than the intended highest or lowest values | WHEN_TO_APPLY: Whenever using LIMIT to fetch smallest/largest or nearest/farthest records based on a metric column | EXAMPLE_USAGE: Correct: SELECT * FROM measurements WHERE category = 'A' ORDER BY score DESC LIMIT 3; Incorrect: SELECT * FROM measurements WHERE category = 'A' LIMIT 3;  -- results are unordered and unpredictable"
257,sf_bq291,generic,having,all,all,all,all,"VERIFY: A total or aggregate column representing a whole should equal the sum of its component sub-columns | PRINCIPLE: Composite metrics must be validated by verifying that the main total equals the sum of its parts to catch missing or double-counted components | WHEN_TO_APPLY: When tables include both a total column and separate subcategory columns that partition the total | EXAMPLE_USAGE: Correct: SELECT order_id, total_amount, item_amount + shipping_amount + tax_amount AS computed_total FROM orders HAVING total_amount = computed_total; Incorrect: SELECT order_id, total_amount, item_amount + shipping_amount + tax_amount AS computed_total FROM orders WHERE total_amount <> computed_total;  -- identifies mismatches"
258,sf_bq291,generic,aggregation;avg,all,all,all,all,"VERIFY: A true average over multiple observations must use an AVG() aggregation on the raw values, not an average of extrema | PRINCIPLE: Averaging the maximum and minimum values (midrange) does not represent the mean of the full distribution of observations | WHEN_TO_APPLY: When computing average or mean metrics across multiple rows in any context | EXAMPLE_USAGE: Correct: SELECT AVG(speed) AS avg_speed FROM vehicle_logs WHERE log_date = '2024-01-01'; Incorrect: SELECT (MAX(speed) + MIN(speed)) / 2 AS avg_speed FROM vehicle_logs WHERE log_date = '2024-01-01';  -- yields midrange, not true average"
259,sf_bq291,question,NA,NA,NA,NA,NA,"The original query already returned the expected metrics for the nearest grid point on 2019-07-16, so no edits were necessary."
260,sf_bq294,db,all,all,all,all,all,(No database‐specific validation checks are necessary since there were no schema changes or issues identified in the DIFF.)
261,sf_bq294,generic,aggregation;group by,all,all,all,all,VERIFY: All non-aggregated columns in the SELECT list are included in the GROUP BY clause
262,sf_bq294,generic,window;partition by;order by,all,all,all,all,VERIFY: Window functions must include the correct PARTITION BY and ORDER BY clauses to scope calculations properly
263,sf_bq294,generic,join,all,all,all,all,VERIFY: JOIN clauses include all necessary key relationships to avoid unintended row multiplication
264,sf_bq294,generic,join;filter,all,all,all,all,"ENSURE: Conditions that filter final results rather than join eligibility should be placed in the WHERE clause, not in the ON clause"
