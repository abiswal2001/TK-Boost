mem_id,instance_id,db,scope,sql_operations,table,column,data_type,nulls,rule
0,sf_bq028,DEPS_DEV_V1,generic,window;row_number;partition by;order by;desc;filter,all,all,all,all,"VERIFY: use ROW_NUMBER() or similar window functions to identify latest or unique entries per group when tables contain history or versions | PRINCIPLE: Without window functions, queries may return duplicate or outdated records instead of the latest | WHEN_TO_APPLY: Whenever source tables record history or multiple versions, and only the latest/current is needed | EXAMPLE_USAGE: When selecting latest entries: 'SELECT *, ROW_NUMBER() OVER (PARTITION BY id ORDER BY date DESC) as rn WHERE rn=1' ensures only the newest per id; failing to use this will include outdated entries."
1,sf_bq028,DEPS_DEV_V1,generic,join,all,all,all,No,"ENSURE: JOIN conditions include all necessary keys (not just one) when tables relate on more than one column (e.g., match both name and version for package joins) | PRINCIPLE: Partial joins can incorrectly combine rows, causing mismatches or duplicates | WHEN_TO_APPLY: Whenever joining entities that need more than a single column for correct linkage | EXAMPLE_USAGE: Correct: 'ON a.id = b.id AND a.version = b.version'; Incorrect: 'ON a.id = b.id', which risks mixing two versions for the same id."
2,sf_bq028,DEPS_DEV_V1,generic,filter,all,all,all,No,"CHECK: relevant filters for system/type/source (like 'System='NPM'' or 'ProjectType='GITHUB'') are applied to restrict analysis to the target scope | PRINCIPLE: Failing to filter correctly causes blending of data from unrelated systems/contexts | WHEN_TO_APPLY: When working with datasets that store multiple system/type/source values | EXAMPLE_USAGE: Always add the correct WHERE clause (e.g., 'WHERE System='NPM''); omitting this will include packages or projects not intended for analysis."
3,sf_bq028,DEPS_DEV_V1,generic,limit,all,all,all,all,"VERIFY: query result is limited (using LIMIT or TOP) to expected row count when only top-N entities are required | PRINCIPLE: Appropriate row limiting ensures that only the most relevant/top entities are returned as per requirements | WHEN_TO_APPLY: Whenever a query requests a specific number of top items (packages, projects, etc.) based on ranking | EXAMPLE_USAGE: Use 'LIMIT 8' or 'TOP 8' to restrict output size; missing this can return entire result sets rather than the desired top entries."
4,sf_bq028,DEPS_DEV_V1,generic,order by;desc,all,all,all,No,"ENSURE: ORDER BY uses the actual popularity or ranking columns, not just name or arbitrary fields | PRINCIPLE: Sorting by the wrong column misrepresents the intended order(like popularity) | WHEN_TO_APPLY: When the goal is to return most popular/highest ranked entities | EXAMPLE_USAGE: Use 'ORDER BY popularity_column DESC'; using 'ORDER BY name' or leaving out ORDER BY will not produce ranked results."
5,sf_bq028,DEPS_DEV_V1,db,window;row_number;partition by;order by;desc;filter,PACKAGEVERSIONTOPROJECT,all,all,all,"ENSURE: when selecting latest npm package versions, use the HighestReleases CTE that applies ROW_NUMBER() OVER (PARTITION BY Name ORDER BY Ordinal DESC) and filters IsRelease=TRUE to identify the most recent released version per package | CONTEXT: PACKAGEVERSIONTOPROJECT table contains multiple versions per package; correct identification of the latest release requires using Ordinal and IsRelease | WHEN_TO_CHECK: When querying for the most up-to-date version of packages in LIBRARIES_IO.LIBRARIES_IO schema | EXAMPLE_USAGE: When filtering for the latest version, use: 'SELECT Name, Version FROM (SELECT *, ROW_NUMBER() OVER (PARTITION BY Name ORDER BY Ordinal DESC) as rn FROM PACKAGEVERSIONTOPROJECT WHERE IsRelease=TRUE) WHERE rn=1'. Omitting IsRelease=TRUE or ROW_NUMBER() may lead to outdated or non-release versions appearing as latest."
6,sf_bq028,DEPS_DEV_V1,db,join,PACKAGEVERSIONTOPROJECT,all,all,No,"VERIFY: when joining PACKAGEVERSIONTOPROJECT to HighestReleases, match on both Name and Version to ensure only genuine latest released versions are included | CONTEXT: PACKAGEVERSIONTOPROJECT has multiple entries per Name; joining just on Name without Version could mix versions improperly | WHEN_TO_CHECK: When combining package and version details to get latest release data | EXAMPLE_USAGE: Correct: 'ON PVP.Name = HR.Name AND PVP.Version = HR.Version'; Incorrect: 'ON PVP.Name = HR.Name'."
7,sf_bq028,DEPS_DEV_V1,db,join;filter,PROJECTS,all,all,No,"ENSURE: when matching projects to repositories for Github stars, join PROJECTS on both ProjectType='GITHUB' and ProjectName/Name values | CONTEXT: PROJECTS table differentiates project types and names; filtering by ProjectType avoids mixing with non-Github sources | WHEN_TO_CHECK: When querying for Github-related popularity data | EXAMPLE_USAGE: Use 'WHERE PVP.ProjectType='GITHUB'' and join with 'ON PVP.ProjectName = PROJECTS.Name AND PROJECTS.Type='GITHUB'' to fetch only Github projects."
8,sf_bq028,DEPS_DEV_V1,db,filter,PACKAGEVERSIONTOPROJECT,all,all,No,VERIFY: filter PACKAGEVERSIONTOPROJECT rows to System='NPM' to exclude non-npm packages | CONTEXT: PACKAGEVERSIONTOPROJECT may contain other package systems alongside NPM | WHEN_TO_CHECK: When a query intends to analyze only npm packages | EXAMPLE_USAGE: Ensure the WHERE clause contains 'PVP.System='NPM''. Failing to add this will include irrelevant systems.
9,sf_bq028,DEPS_DEV_V1,db,order by;desc,PROJECTS,PROJECTS.StarsCount,int,No,ENSURE: order popularity results by PROJECTS.StarsCount DESC to correctly rank by Github popularity | CONTEXT: PROJECTS.StarsCount holds the relevant popularity metric | WHEN_TO_CHECK: When the goal is to rank packages/projects by popularity | EXAMPLE_USAGE: Use 'ORDER BY PROJECTS.StarsCount DESC' in the final SELECT stage.
10,sf_bq043,TCGA,generic,select,all,all,all,all,"VERIFY: correct source tables are used when multiple similar datasets exist | PRINCIPLE: Using the wrong table (e.g., similarly named sources) can lead to mismatched, incomplete, or inaccurate results | WHEN_TO_APPLY: Whenever querying for data where more than one candidate source exists (e.g., multiple mutation or RNA expression tables) | EXAMPLE_USAGE: When building a query to retrieve mutation records, check table names precisely; if GOLD uses 'SOURCE_A', but your query uses 'SOURCE_B', your results may not match. Confirm with source documentation or previous GOLD queries."
11,sf_bq043,TCGA,generic,select,all,all,all,all,"ENSURE: output schema (number and names of SELECT columns) matches specification and expected results | PRINCIPLE: Output columns must exactly match expected structure for validation, including order and naming | WHEN_TO_APPLY: When finalizing SELECT clauses prior to result submission or validation | EXAMPLE_USAGE: Compare your SELECT column list against the GOLD/output specification. If the expected output is 'sample_id, gene_symbol, expression, vital_status', but you output only 'sample_id, gene_symbol', this is incorrect; always include all required fields as columns in both query and output."
12,sf_bq043,TCGA,generic,pivot;aggregation,all,all,all,all,"AVOID: using pivot operations when output requires long-form data | PRINCIPLE: Pivoting transforms rows into columns; some outputs require each observation (gene/sample/attribute) as a separate row | WHEN_TO_APPLY: When the question or GOLD output expects one record per key combination (e.g., per gene per sample) | EXAMPLE_USAGE: If you see the expected output has one row per gene/sample pair, using PIVOT or aggregation to combine genes as columns is incorrect; instead, SELECT each key/attribute as a column and output long-form data."
13,sf_bq043,TCGA,generic,join;select,all,all,all,all,"VERIFY: JOINs bring in all necessary attributes from related tables as explicit columns without aggregation | PRINCIPLE: Required attributes from joined tables should be selected directly; aggregating, pivoting, or omitting fields may result in lost data | WHEN_TO_APPLY: When joining reference/clinical/demographic tables for richer output | EXAMPLE_USAGE: When joining a demographics table, SELECT fields like 'gender', 'vital_status', 'days_to_death' as columns in the result set; do not GROUP BY or PIVOT these unless required."
14,sf_bq043,TCGA,generic,order by,all,all,all,all,"ORDER: output as specified in requirements to ensure predictable and valid row presentation | PRINCIPLE: ORDER BY ensures result set stability and matches expected output structure | WHEN_TO_APPLY: Whenever the requirements or GOLD output show ordered results | EXAMPLE_USAGE: If the specification says 'ORDER BY case_barcode, gene_symbol', always end your query with 'ORDER BY case_barcode, gene_symbol' to avoid row position mismatches during validation."
15,sf_bq043,TCGA,db,select;where;group by,SOMATIC_MUTATION_HG19_DCC_2017_02,all,all,all,"ENSURE: use SOMATIC_MUTATION_HG19_DCC_2017_02 as the source for mutation data, not SOMATIC_MUTATION_HG19_MC3_2017_02 | CONTEXT: The expected output is built using mutation records from SOMATIC_MUTATION_HG19_DCC_2017_02; selecting the wrong mutation source leads to missing or misaligned data | WHEN_TO_CHECK: When building mutation CTEs or querying for mutation data in this schema | EXAMPLE_USAGE: When composing a mutation CTE, confirm your FROM clause is 'FROM SOMATIC_MUTATION_HG19_DCC_2017_02' and not 'FROM SOMATIC_MUTATION_HG19_MC3_2017_02'; using the MC3 source will result in a mismatch compared to expected aggregate results."
16,sf_bq043,TCGA,db,select,RNASEQ_HG19_GDC_2017_02,all,all,all,"ENSURE: gene expression data from RNASEQ_HG19_GDC_2017_02 is selected in long-form without pivoting | CONTEXT: Long-format selects one row per gene/sample; pivoting flattens genes into columns and is incompatible with the expected output | WHEN_TO_CHECK: When selecting gene expression data for reporting on individual gene/sample combinations | EXAMPLE_USAGE: Use 'SELECT sample_barcode, aliquot_barcode, HGNC_gene_symbol, gene_id, normalized_count ... FROM RNASEQ_HG19_GDC_2017_02' to extract one row per gene per sample. Avoid using PIVOT or GROUP BY to combine genes into columns; output must remain long-form (one gene per row)."
17,sf_bq043,TCGA,db,inner join;select,clinical_info,all,all,all,"VERIFY: clinical info is joined in long form without pivoting fields | CONTEXT: Clinical fields (gender, vital status, days to death) need to be included per sample/gene without aggregating or spreading values | WHEN_TO_CHECK: When joining clinical_info table to expression/mutation data | EXAMPLE_USAGE: Structure JOIN so that for each sample/gene, clinical attributes (demo__gender, demo__vital_status, demo__days_to_death, project_short_name) appear as columns on each row. Do not aggregate or pivot clinical columns; use SELECT to list each field."
18,sf_bq043,TCGA,db,select,all,all,all,all,"ENSURE: SELECT statement includes sample_barcode, aliquot_barcode, HGNC_gene_symbol, gene_id, normalized_count, project_short_name, demo__gender, demo__vital_status, demo__days_to_death | CONTEXT: These columns are required for correct output schema | WHEN_TO_CHECK: When constructing the final SELECT clause for this question type | EXAMPLE_USAGE: Construct final output as 'SELECT sample_barcode, aliquot_barcode, HGNC_gene_symbol, gene_id, normalized_count, project_short_name, demo__gender, demo__vital_status, demo__days_to_death'. Omitting any required field results in a schema mismatch."
19,sf_bq043,TCGA,db,order by,all,all,all,all,"ORDER: results by case_barcode and HGNC_gene_symbol for consistent output | CONTEXT: Required ordering for deterministic row presentation in output | WHEN_TO_CHECK: When producing final result sets for reporting or submission | EXAMPLE_USAGE: Use 'ORDER BY case_barcode, HGNC_gene_symbol' as the last clause to ensure output rows match expected ordering; omitting ORDER BY may result in unpredictable row order and validation failures."
20,sf_bq050,NEW_YORK_CITIBIKE_1,generic,join;spatial join,all,all,all,all,"VERIFY: use appropriate spatial functions and data types (e.g., ST_POINT, ST_GEOGFROMWKB, ST_WITHIN) when joining location-based tables | PRINCIPLE: Geospatial joins require building points from latitude/longitude and using polygon geometry fields for spatial relationships; failing to do so can cause logical and inaccurate joins | WHEN_TO_APPLY: Any time linking point records (with lat/lon) to polygons (geometry) in SQL | EXAMPLE_USAGE: For a trips table with lat/lon and a zones table with geom, use 'ST_WITHIN(ST_POINT(trip_lat, trip_lon), zone.geom)' for correct spatial join. Incorrect: join using zone_id without spatial logic can misassign locations."
21,sf_bq050,NEW_YORK_CITIBIKE_1,generic,filter;where,all,all,all,all,"VERIFY: data source filtering must be applied when datasets contain multiple regions or variants (e.g., filter for NYC using 'stn' in weather data) | PRINCIPLE: Large reference tables may include data for many areas or entities; queries must restrict results to the relevant subset | WHEN_TO_APPLY: Anytime a table includes multiple possible locations/entities | EXAMPLE_USAGE: When querying weather, ensure 'WHERE stn = ""NYC_CODE""' or equivalent filter is present. If omitted, results may include other cities’ data, skewing analysis."
22,sf_bq050,NEW_YORK_CITIBIKE_1,generic,aggregation;group by;join,all,all,all,all,"ENSURE: multi-table aggregations and groupings incorporate all relevant join keys, especially after spatial and temporal joins | PRINCIPLE: Aggregating after multiple JOINs requires grouping on all contextually unique fields to avoid overcounting or blended data | WHEN_TO_APPLY: Whenever combining tables by geospatial and temporal context before aggregation | EXAMPLE_USAGE: After joining trips (with coordinates) to spatial polygons and to weather by date, group by neighborhood, borough, and month to ensure breakdown matches analytic expectations. Missing a grouping key (such as date or region) can collapse distinct entries."
23,sf_bq050,NEW_YORK_CITIBIKE_1,db,join;spatial join,NEW_YORK_CITIBIKE_1.NEW_YORK_CITIBIKE.CITIBIKE_TRIPS,NEW_YORK_CITIBIKE_1.NEW_YORK_CITIBIKE.CITIBIKE_TRIPS.start_station_longitude,numeric,all,"ENSURE: spatial joins from trips to NYC ZIP polygons use ST_POINT for trip lat/lon and ST_GEOGFROMWKB for zip_code_geom, with the join made via ST_WITHIN(ST_POINT(trip_lat, trip_lon), ST_GEOGFROMWKB(zip_code_geom)) | CONTEXT: The trips table contains latitude/longitude; NYC ZIP polygons use zip_code_geom (WKB). Correct spatial association is needed to link trips to physical neighborhoods | WHEN_TO_CHECK: When linking trips to neighborhoods or zip codes using location columns | EXAMPLE_USAGE: Validate that the JOIN condition uses ST_WITHIN(ST_POINT(trip_lat, trip_lon), ST_GEOGFROMWKB(zip_code_geom)). Incorrect: simply matching zip_code or ignoring geometry leads to misaligned location mapping."
24,sf_bq050,NEW_YORK_CITIBIKE_1,db,filter;where,NEW_YORK_CITIBIKE_1.NOAA_GSOD.GSOD2014,NEW_YORK_CITIBIKE_1.NOAA_GSOD.GSOD2014.stn,str,No,"ENSURE: weather data from GSOD2014 is filtered to use stn='141060' to select NYC-specific weather readings | CONTEXT: GSOD2014 contains weather data for multiple stations; '141060' is NYC's code, ensuring proper local weather context for trip analyses | WHEN_TO_CHECK: Whenever incorporating weather data into trip or location-based queries | EXAMPLE_USAGE: Check for WHERE weather.stn = '141060' or join conditions restricting to stn='141060'. If absent, the query may mix in irrelevant weather readings from other regions."
25,sf_bq050,NEW_YORK_CITIBIKE_1,db,join;where;date,NEW_YORK_CITIBIKE_1.NEW_YORK_CITIBIKE.CITIBIKE_TRIPS,all,date,all,"VERIFY: date-based joins between trips and weather use matching dates, aligning trip date to weather date (typically via a join on trip_date = weather.date) | CONTEXT: Correctly associating temporal context to each trip by synchronizing with the appropriate day's weather info | WHEN_TO_CHECK: When joining trips to weather data | EXAMPLE_USAGE: Confirm a JOIN or WHERE clause aligns trips.date = weather.date; missing this results in trip-weather mismatches."
26,sf_bq091,PATENTS,generic,flatten;group by;aggregation,all,all,all,all,"VERIFY: array or nested field flattening uses the correct, standardized version of a field for analysis | PRINCIPLE: Many schemas have both raw and harmonized/standardized fields for the same data entity (e.g., assignee vs assignee_harmonized); analytic operations should target the harmonized fields for consistency across records | WHEN_TO_APPLY: Whenever flattening or extracting array/nested data during group-by or aggregation queries | EXAMPLE_USAGE: When you see a table with both ""raw_entity"" and ""entity_harmonized"" columns (e.g., for assignee names), check that FLATTEN, JOIN, or GROUP BY clauses use ""entity_harmonized"". Using the raw field can lead to fragmented grouping and incorrect aggregates; e.g., 'FLATTEN(input => t.entity_harmonized)' is correct, while 'FLATTEN(input => t.raw_entity)' may cause duplicates or mismatches."
27,sf_bq091,PATENTS,db,flatten;aggregation;group by,a61_filings,a61_filings.assignee_harmonized,str,all,"ENSURE: when flattening assignee data in the a61_filings CTE, use ""assignee_harmonized"" instead of ""assignee"" to avoid grouping and matching issues | CONTEXT: The a61_filings CTE has both ""assignee"" and ""assignee_harmonized"" fields. ""assignee_harmonized"" is the curated version intended for analyses and aggregations; errors occur when flattening the unharmonized ""assignee"" | WHEN_TO_CHECK: When performing aggregations or groupings by assignee, or flattening assignee-related arrays in the a61_filings CTE | EXAMPLE_USAGE: In a query needing to group filings by assignee, verify the FLATTEN clause uses ""assignee_harmonized"" (e.g., 'LATERAL FLATTEN(input => a61_filings.assignee_harmonized)') — using 'assignee' instead will incorrectly split or duplicate entities, leading to wrong counts."
28,sf_bq091,PATENTS,db,all,all,all,all,all,"ENSURE: use LATERAL FLATTEN(input => ""assignee_harmonized"") to extract individual assignee names from the array | PRINCIPLE: The ""assignee_harmonized"" column contains an array of assignee objects, each with a ""name"" field; flattening guarantees all assignee entries are considered | WHEN_TO_APPLY: When extracting assignee names from ""assignee_harmonized"" in PATENTS tables | EXAMPLE_USAGE: Correct: 'SELECT a.value:""name""::STRING AS assignee_name FROM PATENTS.PATENTS.PUBLICATIONS, LATERAL FLATTEN(input => ""assignee_harmonized"") a'; Incorrect: Using 'assignee_harmonized[0]' or direct array indexing misses all but the first assignee."
29,sf_bq091,PATENTS,db,all,all,all,all,all,"AVOID: hard-coding assignee names in WHERE IN clauses when selecting top N assignees; use dynamic aggregation instead | PRINCIPLE: Top assignees should be determined by data-driven counts (ORDER BY COUNT(*) DESC LIMIT N), not static lists | WHEN_TO_APPLY: When identifying the most frequent assignees or top N entities in patent queries | EXAMPLE_USAGE: Correct: 'SELECT assignee_name, COUNT(*) as app_count FROM ... GROUP BY assignee_name ORDER BY app_count DESC LIMIT 3'; Incorrect: 'WHERE assignee_name IN (''LELY'', ''DEERE'', ...)' introduces bias and cannot adapt to data changes."
28,sf_bq121,STACKOVERFLOW,generic,aggregation;avg;sum;count;group by;where;cast;date;datediff,all,all,date,all,"VERIFY: Date-dependent calculations use the required fixed reference date, not dynamic system dates | PRINCIPLE: When queries require analysis relative to a historical or reporting cutoff date, using system functions like CURRENT_DATE() can produce changing results—fixed reference dates are necessary for reproducibility | WHEN_TO_APPLY: Whenever aggregating, bucketing, or calculating metrics based on elapsed time and a specific reporting period is required | EXAMPLE_USAGE: Instead of 'DATEDIFF(CURRENT_DATE(), event_date)', check for 'DATEDIFF(TO_DATE('YYYY-MM-DD'), event_date)' where 'YYYY-MM-DD' matches the reporting cutoff; this ensures results are not affected by when the query runs."
29,sf_bq121,STACKOVERFLOW,db,aggregation;avg;sum;count;group by;where;order by;limit;left join;cast;date;datediff,all,all,date,all,"ENSURE: membership_years calculation uses TO_DATE('2021-10-01') as the reference date instead of CURRENT_DATE() | CONTEXT: membership_years is computed as the integer difference between a user's join_date and a fixed cutoff date to produce accurate tenure data for this database | WHEN_TO_CHECK: When calculating user tenure for reporting or analysis tasks that are time-bounded, such as grouping users by membership duration | EXAMPLE_USAGE: In SELECT statements, verify membership_years is calculated as 'FLOOR(DATEDIFF(TO_DATE('2021-10-01'), join_date) / 365)' rather than 'FLOOR(DATEDIFF(CURRENT_DATE(), join_date) / 365)', to ensure consistent historical cutoffs matching GOLD."
30,sf_bq153,PANCANCER_ATLAS_1,generic,order by;case,all,all,all,all,"VERIFY: ORDER BY clauses produce exact output row order required by specifications or GOLD standards, using explicit CASE logic when needed | PRINCIPLE: Default column sorting may not align with required business or test result order; explicit CASE-based ordering ensures precise alignment | WHEN_TO_APPLY: Whenever row sequence is mandated to follow a non-standard or mapped order, not raw column values | EXAMPLE_USAGE: When result order matters (e.g., specific category sequence), check that 'ORDER BY CASE WHEN category = 'X' THEN 1 WHEN category = 'Y' THEN 2 ELSE N END' is used instead of 'ORDER BY category', preventing mismatched row order and ensuring test pass."
31,sf_bq153,PANCANCER_ATLAS_1,generic,order by;case,all,all,all,all,"VERIFY: Custom CASE statements are used in ORDER BY when result row order must match a specific pattern, not just column value sorting | PRINCIPLE: A CASE-based ORDER BY allows precise control over output ordering according to business or domain rules, avoiding surprises from default alphabetical, numerical, or chronological order | WHEN_TO_APPLY: Whenever the GOLD output specifies a particular order of rows based on values, rather than standard SQL sort | EXAMPLE_USAGE: If you need rows with value A, then B, then C (regardless of their sort order), use ORDER BY CASE WHEN col = 'A' THEN 1 WHEN col = 'B' THEN 2 WHEN col = 'C' THEN 3 ELSE 4 END. Using ORDER BY col may produce a different, undesirable sequence."
32,sf_bq153,PANCANCER_ATLAS_1,db,order by;case,CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED,CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED.icd_o_3_histology,str,all,"ENSURE: ORDER BY clauses use explicit CASE statements rather than relying on default column sorting for custom output order | CONTEXT: Queries involving the ""icd_o_3_histology"" column require explicit sequencing to match required row order; relying on natural column value order can misalign results with GOLD standards | WHEN_TO_CHECK: When output order must follow a custom logic, such as specific histology groupings or business requirements, not simple alphabetical/numeric column order | EXAMPLE_USAGE: When ordering by ""icd_o_3_histology"", verify you include: 'ORDER BY CASE WHEN ""icd_o_3_histology"" = 'A' THEN 1 WHEN ... ELSE N END' rather than just 'ORDER BY ""icd_o_3_histology""', ensuring the explicit ordering matches GOLD output expectations."
33,sf_bq153,PANCANCER_ATLAS_1,db,order by;case,PANCANCER_ATLAS_1.PANCANCER_ATLAS_FILTERED.CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED,PANCANCER_ATLAS_1.PANCANCER_ATLAS_FILTERED.CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED.icd_o_3_histology,str,all,"ENSURE: Use a CASE statement in the ORDER BY clause when a specific, non-alphabetical order of ""icd_o_3_histology"" values is required to match GOLD outputs | CONTEXT: ""icd_o_3_histology"" column is present in the histology dataset, and a CASE-based ORDER BY arranges rows in a custom priority that differs from simple alphanumeric sorting | WHEN_TO_CHECK: When presenting or comparing results where ""icd_o_3_histology"" rows need to appear in a designated order (not relying on default sort) | EXAMPLE_USAGE: If GOLD expects '9450/3' before '9401/3', use ORDER BY CASE ""icd_o_3_histology"" WHEN '9450/3' THEN 1 WHEN '9401/3' THEN 2 ELSE N END, rather than ORDER BY ""icd_o_3_histology"", or rows will appear in the wrong sequence."
34,sf_bq155,TCGA_HG38_DATA_V0,generic,aggregation;avg;log,all,all,all,all,"VERIFY: Mathematical transformations are applied at the correct step in aggregation | PRINCIPLE: For operations like log, square root, or normalization, apply the transformation to each row before aggregating to prevent incorrect results caused by transforming aggregated data | WHEN_TO_APPLY: Whenever a transformation must be applied to per-row data but aggregation (e.g., AVG, SUM) is needed afterwards | EXAMPLE_USAGE: To compute a mean of log-transformed values, use 'AVG(LOG(value))' for per-row transformation, not 'LOG(AVG(value))' which transforms post-aggregation and distorts the expected calculation."
35,sf_bq155,TCGA_HG38_DATA_V0,db,aggregation;avg;log;cast,TCGA_HG38_DATA_V0.TCGA_HG38_DATA_V0.RNASEQ_GENE_EXPRESSION,RNASEQ_GENE_EXPRESSION.HTSeq__Counts,numeric,all,"ENSURE: When computing SNORA31 log-transformed expression values, apply LOG(10, CAST(""HTSeq__Counts"" AS FLOAT) + 1) per row before averaging | CONTEXT: ""HTSeq__Counts"" column from relevant table must use log10(count+1) transformation per sample, then average the result to produce SNORA31 expression | WHEN_TO_CHECK: When calculating SNORA31 expression averages for comparative or statistical analysis | EXAMPLE_USAGE: When computing mean SNORA31 expression, use 'AVG(LOG(10, CAST(r.""HTSeq__Counts"" AS FLOAT) + 1))' instead of 'LOG(10, AVG(CAST(r.""HTSeq__Counts"" AS FLOAT)) + 1)' to ensure log transformation is done per sample before aggregation."
36,sf_bq159,PANCANCER_ATLAS_1,generic,cross join;group by;having;aggregation;where,all,all,all,No,"ENSURE: when building contingency grids or cross-joins for statistical analysis, first filter valid row/column sets per marginal threshold, and base all subsequent calculations (tables, marginals, expected values) ONLY on filtered grid cells | PRINCIPLE: Proper statistical analysis requires calculations (counts, expected values) using only eligible data meeting validity criteria; using unfiltered or global counts causes mismatches and incorrect results | WHEN_TO_APPLY: Whenever constructing cross-tabulations, contingency tables, or performing grouped calculations with data filtering | EXAMPLE_USAGE: After applying ""HAVING COUNT(*) > X"" on both row and column groupings, create a cross-join or grid only of the row/column pairs represented by those filtered sets, then proceed with ""SELECT ... FROM filtered_cross_grid ..."", ensuring subsequent aggregations only reference counts/marginals from these included cells, not the entire dataset."
37,sf_bq159,PANCANCER_ATLAS_1,generic,group by;aggregation;where,all,all,all,No,"VERIFY: variable naming and value mapping in output and calculations match the expected standards used in reference/gold code; misaligned names (e.g., 'mutated' instead of 'YES') can cause grouping mismatches and comparison errors | PRINCIPLE: Consistent variable naming and value mapping are critical for correct grouping, joining, and aggregation; mismatches can lead to incorrect counts or output misalignment | WHEN_TO_APPLY: When designing queries that need to align to a reference standard or produce output for comparison/testing | EXAMPLE_USAGE: When grouping or aggregating by categorical variables, check mapping (""mutation_status"" as 'YES'/'NO') matches gold code—e.g., ""CASE WHEN status = 'mutated' THEN 'YES' ELSE 'NO' END AS mutation_status""—and avoid using alternate names unless explicitly required."
38,sf_bq159,PANCANCER_ATLAS_1,db,where;group by;aggregation,all,mutation_status,str,No,"ENSURE: when computing contingency tables for mutation status analysis, use 'YES'/'NO' mutation status naming for compatibility with expected logic and results | CONTEXT: The mutation status field should be labeled 'YES' or 'NO' rather than 'mutated'/'wildtype' to match gold standard expectations and avoid mismatches in grouping/aggregation | WHEN_TO_CHECK: When constructing or grouping data by mutation status for statistical calculations or table outputs | EXAMPLE_USAGE: When filtering or aggregating rows, verify you use ""WHERE mutation_status IN ('YES','NO')"" and not ""IN ('mutated','wildtype')"" to ensure correct subset and result alignment."
39,sf_bq159,PANCANCER_ATLAS_1,db,group by;having;aggregation;where,all,all,all,No,"VERIFY: contingency cell, row, and column marginals are calculated only for rows and columns with more than 10 cases included, based on filtered contingency cells | CONTEXT: Statistical tests (like chi-square) require sufficient marginal counts (>10) for validity, so row/column sets must be restricted to groups meeting this threshold per Gold standards | WHEN_TO_CHECK: When creating contingency or cross-tabulation grids for statistical analysis | EXAMPLE_USAGE: When generating contingency tables, filter initial groups with ""HAVING COUNT(*) > 10"" and apply this filter not just to rows/columns individually, but to the set of contingency cells actually present in the filtered data (e.g., SELECT row_var, col_var FROM ... GROUP BY ... HAVING COUNT(*) > 10)."
40,sf_bq159,PANCANCER_ATLAS_1,db,aggregation;group by;where,all,all,all,No,"ENSURE: expected values for chi-square or similar tests are computed using only the filtered marginals for included contingency cells, not total global patient counts | CONTEXT: Valid expected cell computation requires marginals derived from the subset passing marginal thresholds (>10 per group), not the full dataset; otherwise, expected counts and test statistics are incorrect | WHEN_TO_CHECK: When performing chi-square or similar calculations on contingency tables | EXAMPLE_USAGE: After filtering in eligible rows/columns, compute expected cell as: ""expected_ij = row_i_count * col_j_count / total_filtered_n"" (where counts are from filtered groups), not ""expected_ij = row_i_full * col_j_full / total_n"" (which would include excluded patients)."
41,sf_bq166,TCGA_MITELMAN,generic,left join;join;inner join,all,all,all,all,"VERIFY: LEFT JOIN is used when it is necessary to retain all records from the left table, even if no match exists in the right table | PRINCIPLE: LEFT JOIN retains unmatched rows from the left side, whereas INNER JOIN removes them, which may exclude relevant data | WHEN_TO_APPLY: Whenever combining datasets and want to preserve all entries from one side regardless of matches in the other | EXAMPLE_USAGE: If querying across a mapping table and a reference dimension (e.g., mapping segments to regions), use 'LEFT JOIN' when some segments may not match any region and you want to keep those; 'INNER JOIN' would drop those unmatched segments, leading to incomplete results."
42,sf_bq166,TCGA_MITELMAN,generic,aggregation;group by,all,all,all,all,"ENSURE: Aggregation GROUP BY clauses include all columns that identify the grouping scope needed for the analysis | PRINCIPLE: Omitting necessary fields in GROUP BY can lead to incorrect aggregations and duplicate/missing counts | WHEN_TO_APPLY: When summarizing or counting data across multiple fields, especially in frequency tables or statistics per distinct entity | EXAMPLE_USAGE: If aggregating max or count per entity in a complex report, verify 'GROUP BY' includes every identifying column—such as (field1, field2, field3). If only 'GROUP BY field1', values for field2/3 may be combined erroneously, distorting the analysis."
43,sf_bq166,TCGA_MITELMAN,generic,cte_definition;filter;join;group by;aggregation,all,all,all,all,"CHECK: All CTEs required for the logic are present and used with correct join/filter conditions | PRINCIPLE: Necessary CTEs encapsulate intermediate computations and enable correct aggregation or filtering for final results | WHEN_TO_APPLY: When analysis relies on several layered transformations (e.g., filtering by subset, joining detailed entities, calculating group statistics) | EXAMPLE_USAGE: If GOLD SQL includes CTEs like cytob or joined, ensure that these are included and referenced with appropriate join conditions and filters; omitting or misnaming CTEs leads to logic gaps and mismatched results."
44,sf_bq166,TCGA_MITELMAN,db,join;left join;filter,TCGA_MITELMAN.TCGA_VERSIONED.COPY_NUMBER_SEGMENT_ALLELIC_HG38_GDC_R23,TCGA_MITELMAN.TCGA_VERSIONED.COPY_NUMBER_SEGMENT_ALLELIC_HG38_GDC_R23.chromosome,str,all,"ENSURE: when joining segments to cytobands, use a LEFT JOIN with precise overlap conditions on chromosome, hg38_start, and hg38_stop fields | CONTEXT: The segments table and cytoband table are joined to identify which segments overlap which cytobands. Using the correct JOIN and overlap logic prevents missing segments without a matching cytoband and avoids false matches | WHEN_TO_CHECK: When correlating segments to cytobands to assign segment data (e.g., copy_number) to cytoband regions | EXAMPLE_USAGE: When joining segments and cytobands, verify the SQL uses 'LEFT JOIN cytoband ON segments.chromosome = cytoband.chromosome AND segments.hg38_start <= cytoband.hg38_stop AND segments.hg38_stop >= cytoband.hg38_start', not just INNER JOIN or only chromosome equality. Missing the LEFT JOIN or overlap conditions (i.e., only joining on chromosome) omits segments not matching any cytoband and can cause inaccurate aggregation."
45,sf_bq166,TCGA_MITELMAN,db,aggregation;group by;max,joined,joined.chromosome,str,all,"ENSURE: cytoband-related aggregation uses GROUP BY on chromosome, cytoband_name, hg38_start, hg38_stop, and case_barcode | CONTEXT: To accurately compute the maximum copy number or frequency per cytoband for each case, grouping on all these fields is necessary | WHEN_TO_CHECK: When aggregating segment/variant data at the cytoband level for reporting statistics | EXAMPLE_USAGE: When building a CTE to aggregate values, use 'GROUP BY chromosome, cytoband_name, hg38_start, hg38_stop, case_barcode'. Omitting any of these fields groups data incorrectly and skews counts or max values; for example, 'GROUP BY chromosome, cytoband_name' would collapse distinct cytoband locations together and distort output."
46,sf_bq167,META_KAGGLE,generic,aggregation;count;count distinct,all,all,all,all,"CHECK: the aggregation column in COUNT(DISTINCT ...) matches the actual entity being counted, not just a related or grouping field | PRINCIPLE: Aggregations should operate on the true unique identifier of the records of interest, rather than on group-level or foreign keys that may mask additional distinct records | WHEN_TO_APPLY: Whenever using COUNT(DISTINCT ...) to deduplicate or count records in any table, especially when tables have both unique primary keys and foreign/group keys | EXAMPLE_USAGE: If counting votes, verify 'COUNT(DISTINCT vote_id)' counts individual vote records. Counting 'COUNT(DISTINCT message_id)' only gives the unique messages, not vote records, so if multiple votes exist per message, results will be incorrect. Correct: 'SELECT COUNT(DISTINCT vote_id) FROM votes_table'; Incorrect: 'SELECT COUNT(DISTINCT message_id) FROM votes_table'."
47,sf_bq167,META_KAGGLE,db,aggregation;count;count distinct;group by,FORUMMESSAGEVOTES,FORUMMESSAGEVOTES.Id,int,No,"ENSURE: when counting unique votes in the FORUMMESSAGEVOTES table, use COUNT(DISTINCT ""Id"") instead of COUNT(DISTINCT ""ForumMessageId"") | CONTEXT: The ""Id"" column in FORUMMESSAGEVOTES represents each vote record, while ""ForumMessageId"" groups votes by message. Counting distinct ""Id"" ensures the correct total number of votes, avoiding undercounting if multiple votes exist per message. | WHEN_TO_CHECK: When aggregating total votes or deduplicating vote records in queries involving FORUMMESSAGEVOTES | EXAMPLE_USAGE: For capturing the total number of votes: 'SELECT COUNT(DISTINCT ""Id"") FROM FORUMMESSAGEVOTES' is correct. Using 'SELECT COUNT(DISTINCT ""ForumMessageId"") FROM FORUMMESSAGEVOTES' only counts the number of messages that received votes, not the total vote records, leading to an inaccurate count."
48,sf_bq167,all,generic,distinct;select;limit;order by,all,all,all,all,"CHECK: When the question explicitly asks for ""the top-ranked [singular entity]"" (e.g., ""the top-ranked city"", ""the highest-rated term"", ""the most popular item""), use DISTINCT to ensure only one result is returned, even if multiple rows exist with the same ranking value | PRINCIPLE: Questions phrased in singular form (""the city"" not ""cities"") expect a unique result; without DISTINCT, queries may return duplicate entities if the underlying data has multiple rows with the same top value across different grouping dimensions (e.g., same city appearing in multiple DMAs or time periods) | WHEN_TO_APPLY: When the question uses singular phrasing for top N queries (especially when N=1), and the source data may contain duplicates of the same entity across different dimensions | EXAMPLE_USAGE: For ""What is the top-ranked rising term?"", use 'SELECT DISTINCT term FROM table ORDER BY rank LIMIT 1'; without DISTINCT, if ""bitcoin"" is the top term in 3 different DMAs, it would return 3 rows of ""bitcoin"". Correct: 'SELECT DISTINCT term FROM ... ORDER BY score DESC LIMIT 1'; Incorrect: 'SELECT term FROM ... ORDER BY score DESC LIMIT 1' (may return duplicates)"
49,sf_bq176,TCGA_MITELMAN,generic,select,all,all,all,all,"VERIFY: the SELECT clause returns exactly and only the columns required by the expected output | PRINCIPLE: Result set column count and order must match the specification or GOLD result; extra columns (even if valid) lead to mismatched outputs | WHEN_TO_APPLY: When writing or validating queries against expected outputs, especially in competitive or testing environments | EXAMPLE_USAGE: If the expected output is one column SELECT field1 FROM ..., including additional fields (e.g., SELECT field1, field2 FROM ...) is incorrect; final SELECT must only include field1 to align with requirements."
50,sf_bq176,TCGA_MITELMAN,db,select,all,case_barcode,str,all,"ENSURE: only case_barcode is included in the SELECT clause when output must match GOLD | CONTEXT: The relevant table or query produces both case_barcode and weighted_avg_segment_mean, but GOLD only requires case_barcode. Including extra columns leads to output mismatch. | WHEN_TO_CHECK: When selecting columns for final output, especially when GOLD result specifies only a subset of columns | EXAMPLE_USAGE: If the intermediate results include both SELECT case_barcode, weighted_avg_segment_mean FROM ..., verify that the final output uses SELECT case_barcode FROM ...; removing weighted_avg_segment_mean ensures correct output."
51,sf_bq182,GITHUB_REPOS_DATE,generic,from;where;partition,all,all,all,all,"VERIFY: selected data source (table/schema/partition) matches the query's required time granularity | PRINCIPLE: When databases have multiple partitioning schemes (e.g., monthly and daily tables), using the wrong partition can include excess data or miss required rows; match table selection to the intended time range | WHEN_TO_APPLY: When queries involve time-specific event data and multiple partitioned tables exist | EXAMPLE_USAGE: If analyzing events for a specific day, use the daily partitioned table rather than the monthly partition plus WHERE date = X; e.g., 'FROM Db.Day._YYYYMMDD' is correct, while 'FROM Db.Month._YYYYMM WHERE event_date = YYYY-MM-DD' may be inefficient or subtly incorrect."
52,sf_bq182,GITHUB_REPOS_DATE,generic,where;count;filter,all,all,all,all,"CHECK: filtered event count thresholds in WHERE clauses reflect the question logic and expected output | PRINCIPLE: Hard-coded numeric thresholds in filters (e.g., event_count >= X) directly control which results appear; mismatched thresholds produce unexpected results | WHEN_TO_APPLY: Whenever a query requires at least/minimum N events or items per group | EXAMPLE_USAGE: When a question asks for entities with at least N instances (e.g., presentations, releases, PRs), verify the WHERE clause uses 'X >= N' with the correct N specified; e.g., 'WHERE event_count >= 5' for a ""min 5"" requirement, not 'WHERE event_count >= 100', which can filter out most of the expected results."
53,sf_bq182,GITHUB_REPOS_DATE,db,from,GITHUB_REPOS_DATE.DAY._20230118,all,all,all,"ENSURE: use GITHUB_REPOS_DATE.DAY._20230118 as the data source for PR events targeting January 18, 2023 | CONTEXT: The database contains event data partitioned both by month and by day in the GITHUB_REPOS_DATE schema; for single-day PR event queries, the correct table is GITHUB_REPOS_DATE.DAY._20230118 | WHEN_TO_CHECK: When querying PR events for only January 18, 2023 | EXAMPLE_USAGE: When counting PR events for 2023-01-18, verify the FROM clause is 'GITHUB_REPOS_DATE.DAY._20230118' rather than 'GITHUB_REPOS_DATE.MONTH._202301' with an added date filter; using the latter risks including data outside the intended day and requires extra filtering."
54,sf_bq182,GITHUB_REPOS_DATE,db,where;count;filter,all,all,all,all,"ENSURE: update event count thresholds in WHERE clauses to match question requirements; for this query, the correct PR event count threshold is >= 5 | CONTEXT: The results depend on the event count threshold in the WHERE clause; using a threshold of 100 omits valid results, while a threshold of 5 matches the GOLD standard | WHEN_TO_CHECK: When specifying minimum PR event counts in filtering statements | EXAMPLE_USAGE: When filtering repositories with at least 5 PR events, ensure the condition is 'WHERE pr_event_count >= 5' rather than 'WHERE pr_event_count >= 100', which would incorrectly reduce the result set."
55,sf_bq213,PATENTS,generic,select,all,all,all,all,"VERIFY: The number of columns in the SELECT clause exactly matches the expected output structure | PRINCIPLE: Output should not contain extra columns beyond what is required in the final result set | WHEN_TO_APPLY: Whenever constructing the final SELECT statement, especially after intermediate calculations or aggregations | EXAMPLE_USAGE: If expected output has one column (e.g., only 'category'), verify that the final SELECT clause is like 'SELECT category FROM ...' not 'SELECT category, count FROM ...', which would produce an incorrect column count."
56,sf_bq213,PATENTS,db,where;group by;order by;limit;select;substr;count,top_ipc4,top_ipc4.ipc4,str,all,"ENSURE: Only include the ipc4 column in the final SELECT when output requirements specify single-column results | CONTEXT: The top_ipc4 table was selected with both ipc4 and n_pubs columns, but only ipc4 was needed for the correct output | WHEN_TO_CHECK: When the question requires only ipc4 in the result, after any ranking/filtering is applied | EXAMPLE_USAGE: If you have 'SELECT ipc4, n_pubs FROM top_ipc4 WHERE rn = 1', verify that you rewrite this as 'SELECT ipc4 FROM top_ipc4 WHERE rn = 1' to match single-column output requirements."
57,sf_bq246,PATENTSVIEW,generic,aggregation;filter,all,all,all,all,"VERIFY: CTE logic matches expected citation direction and filtering semantics | PRINCIPLE: CTE definitions for aggregations or filtering (such as forward/backward links) must mirror the business logic, especially when directionality or temporal windows matter | WHEN_TO_APPLY: Whenever creating CTEs for directional relationships, aggregation, or time-sensitive filtering | EXAMPLE_USAGE: When defining CTEs for forward/backward relations, ensure the logic aligns with the required temporal precedence (e.g., a forwards CTE for citations should have cited_date > citing_date), rather than applying a generic filter or using only one date."
58,sf_bq246,PATENTSVIEW,generic,join,all,all,all,all,"ENSURE: Final query joins outputs from CTEs on all key identifiers required to restrict to intersection of interest | PRINCIPLE: When multiple CTEs yield subsets that should be intersected (e.g., patents with both forward and backward citations), join on all relevant keys to obtain only records present in both subsets | WHEN_TO_APPLY: Whenever combining results from distinct filtered subsets | EXAMPLE_USAGE: When joining results from forward and backward citation CTEs, use 'ON a.key = b.key' to require presence in both; simply selecting from one CTE or failing to join can yield superfluous or irrelevant records."
59,sf_bq246,PATENTSVIEW,generic,order by;limit;aggregation;desc,all,all,all,all,"CHECK: Ranking and LIMIT logic matches reporting requirements (e.g., top N or most cited entity) | PRINCIPLE: The output should reflect the reporting spec (such as 'most cited', 'latest', 'top N'), requiring explicit ORDER BY and LIMIT clauses on the correct aggregation metric | WHEN_TO_APPLY: Whenever the result should be limited to most, newest, or top entries | EXAMPLE_USAGE: When expected to show the most cited entity, verify that 'ORDER BY citation_count DESC LIMIT 1' (or the required N) is present; omitting the ORDER BY or using the wrong column will select a random result rather than the intended entry."
60,sf_bq246,PATENTSVIEW,db,join;where;filter,USPATENTCITATION,all,all,all,"ENSURE: citation direction (forward vs backward) is determined using USPATENTCITATION and APPLICATION tables with correct date windows and country filters | CONTEXT: Correct identification of forward and backward patent citations relies on matching APPLICATION.country to 'US' and USPATENTCITATION.date to the appropriate time window for each citation direction | WHEN_TO_CHECK: When constructing CTEs for forward or backward patent citations | EXAMPLE_USAGE: For backward citations, filter USPATENTCITATION where citing patent’s application date is after cited patent’s application date and country is 'US'; for forward citations, reverse the date logic. Incorrectly applying date windows or omitting the country filter leads to wrong citation counts."
61,sf_bq246,PATENTSVIEW,db,join,all,patent_id,int,all,ENSURE: final SELECT only joins patents present in BOTH forward and backward citation CTEs on patent_id | CONTEXT: Only patents with both types of citations should be reported; joining on patent_id ensures the correct intersection | WHEN_TO_CHECK: When aggregating or ranking patents by citation counts and reporting results combining both forward and backward citation metrics | EXAMPLE_USAGE: Use 'FROM bkwd JOIN fwrd ON bkwd.patent_id = fwrd.patent_id' to ensure only patents with both citation types are included; missing this join would allow patents with only one citation direction to appear incorrectly.
62,sf_bq246,PATENTSVIEW,db,order by;aggregation;limit;desc,all,bkwdCitations_3,int,all,"REMEMBER: Sort by backward citation count descending for reporting highly cited patents, limiting to top result(s) | CONTEXT: Ranking patents by number of backward citations (bkwdCitations_3) is needed to find the most influential patents for a query | WHEN_TO_CHECK: When reporting top-cited patents or summarizing citation influence | EXAMPLE_USAGE: Use 'ORDER BY bkwd.bkwdCitations_3 DESC LIMIT 1' for correct ranking; omitting the ORDER BY or using the wrong column would select incorrect patents."
63,sf_bq246,PATENTSVIEW,db,join;group by;distinct;aggregation;left join,PATENT,patent_id,int,No,"ENSURE: Include a GROUP BY clause to eliminate duplicate patent rows when joining to multi-row tables like CPC_CURRENT | CONTEXT: The patent_id may appear multiple times due to one-to-many relationships with tables such as CPC_CURRENT. Without proper grouping, the result contains duplicate rows for each patent. | WHEN_TO_CHECK: When producing queries that join patents to classification/taxonomy tables (e.g., CPC_CURRENT), and the output should be unique per patent_id (and columns like title, abstract, pub_date, backward_citations, forward_citations_5y) | EXAMPLE_USAGE: After performing JOINs that may expand patent_id due to multiple classification records, use 'GROUP BY patent_id, title, abstract, pub_date, backward_citations, forward_citations_5y' in the final SELECT. Omitting the GROUP BY (just using SELECT ...) leads to duplicates; adding GROUP BY ensures one row per patent."
64,sf_bq252,GITHUB_REPOS,generic,join,all,all,all,all,"VERIFY: that JOIN clauses use the correct key columns from both tables, especially when tables have distinct primary keys | PRINCIPLE: Accurate joining relies on matching the actual key fields that link records; incorrect columns or missing keys result in misaligned or incomplete data | WHEN_TO_APPLY: Whenever joining two tables representing linked but distinct entities (e.g., metadata and content) | EXAMPLE_USAGE: If Table A has 'a.id' and Table B has 'b.id', the JOIN should use 'ON a.id = b.id'. Using other columns like 'a.name = b.name' or an ambiguous key can cause erroneous joins."
65,sf_bq252,GITHUB_REPOS,generic,filter;where;like,all,all,all,all,"ENSURE: that filtering conditions reference the correct columns from the table holding the filtered attribute, especially after JOINs | PRINCIPLE: Filters must be applied to the column that actually contains the relevant attribute, not a similarly named column from another table | WHEN_TO_APPLY: Whenever applying WHERE clauses in queries involving multiple tables | EXAMPLE_USAGE: If filtering by a file path extension, use the file metadata table's ""path"" column ('WHERE f.path LIKE '%.swift''), rather than a possibly mismatched or duplicated column in another table ('WHERE c.sample_path LIKE '%.swift'')."
66,sf_bq252,GITHUB_REPOS,generic,join;select,all,all,all,all,"CHECK: output columns in the SELECT clause reference the correct source table and column, especially after renaming/joining | PRINCIPLE: The final output should pull the intended data from the authoritative table, using correct aliases after table merges | WHEN_TO_APPLY: When mapping output column names after joins or table renames | EXAMPLE_USAGE: If the expected output is repository name, ensure 'SELECT f.repo_name AS output' draws from the correct joined table, not 'SELECT c.sample_repo_name', which may not contain the canonical data."
67,sf_bq252,GITHUB_REPOS,db,join;where;filter;order by;limit,GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS,GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS.id,int,all,"ENSURE: when joining GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS and GITHUB_REPOS.GITHUB_REPOS.SAMPLE_FILES, join on the ""id"" column and select ""repo_name"" and ""path"" from SAMPLE_FILES for accurate identification | CONTEXT: The SAMPLE_CONTENTS and SAMPLE_FILES tables are linked by the ""id"" key, and selecting the correct columns (especially ""repo_name"" and ""path"" from SAMPLE_FILES) ensures the retrieved data reflects actual repository and file details | WHEN_TO_CHECK: When constructing queries that relate file content to repository/file metadata, especially when the file path or repo name is used for filtering or output | EXAMPLE_USAGE: When joining SAMPLE_CONTENTS c to SAMPLE_FILES f, verify the join uses 'ON c.id = f.id' and the SELECT uses 'f.repo_name, f.path'. A wrong join (e.g., 'ON c.sample_id = f.sample_id') or selecting c.sample_repo_name/c.sample_path will produce incorrect mappings and output."
68,sf_bq252,GITHUB_REPOS,db,filter;where;like,GITHUB_REPOS.GITHUB_REPOS.SAMPLE_FILES,GITHUB_REPOS.GITHUB_REPOS.SAMPLE_FILES.path,str,all,"ENSURE: when filtering for Swift files, apply the WHERE clause to the ""path"" column in SAMPLE_FILES (i.e., f.""path"" LIKE '%.swift') | CONTEXT: The file type can only be correctly identified by inspecting the actual path name in SAMPLE_FILES, as ""sample_path"" in SAMPLE_CONTENTS may not reflect the real file extension | WHEN_TO_CHECK: When filtering queries to return only files of a certain type/extension like '.swift' | EXAMPLE_USAGE: Use 'WHERE f.""path"" LIKE '%.swift'' to filter Swift files, not 'WHERE c.""sample_path"" LIKE '%.swift'' which may miss or error in the filtering."
69,sf_bq252,all,generic,aggregation;array_agg;array_sort;array_to_string;cte_definition,all,all,all,all,"ENSURE: When aggregating values into arrays for final output, perform the aggregation (e.g., ARRAY_AGG) in a CTE first, then apply sorting/formatting functions (e.g., ARRAY_SORT, ARRAY_TO_STRING) in the final SELECT that references the CTE | PRINCIPLE: Attempting to perform ARRAY_AGG with inline ORDER BY or DISTINCT inside ARRAY_TO_STRING can cause syntax errors or incorrect results; separating aggregation (in CTE) from transformation (in final SELECT) ensures correct execution and allows reuse of aggregated data | WHEN_TO_APPLY: When building queries that aggregate multiple values per entity into arrays and need to sort or format them as strings | EXAMPLE_USAGE: Instead of 'SELECT ARRAY_TO_STRING(ARRAY_AGG(DISTINCT language ORDER BY language), ',') FROM ...', use a CTE pattern: 'WITH aggregated AS (SELECT entity_id, ARRAY_AGG(DISTINCT language) as languages FROM ... GROUP BY entity_id) SELECT entity_id, ARRAY_TO_STRING(ARRAY_SORT(languages), ', ') FROM aggregated'. The CTE handles aggregation, the final SELECT handles sorting and formatting. Correct: Use CTE for ARRAY_AGG, then ARRAY_SORT in final SELECT; Incorrect: Inline ARRAY_AGG with ORDER BY inside ARRAY_TO_STRING."
70,sf_bq264,THELOOK_ECOMMERCE,generic,where;filter;to_timestamp;extract;date_cast;timestamp,all,all,date,all,"VERIFY: timestamp conversions accurately reflect source units (seconds/milliseconds/microseconds) | PRINCIPLE: Many databases store timestamps in non-standard units (e.g., microseconds, milliseconds). Converting to correct units before using date functions ensures correct time filtering and avoids record misalignment | WHEN_TO_APPLY: Whenever using date/time functions (e.g., TO_TIMESTAMP, EXTRACT) with columns whose units are not standard seconds | EXAMPLE_USAGE: When a column represents epoch time in microseconds, always divide by 1,000,000 before passing to TO_TIMESTAMP. Correct: 'TO_TIMESTAMP(column / 1000000.0)'; Incorrect: 'TO_TIMESTAMP(column)' (if column is microseconds, this will produce wildly incorrect timestamps and filtering)."
71,sf_bq264,THELOOK_ECOMMERCE,generic,where;filter;between;to_timestamp;date_cast,all,all,date,all,"ENSURE: BETWEEN logic in date filters matches timestamp values exactly without rounding errors | PRINCIPLE: Filtering rows using BETWEEN for time ranges requires ensuring values used for comparison are correctly normalized, especially after conversions | WHEN_TO_APPLY: When filtering on timestamp ranges with BETWEEN | EXAMPLE_USAGE: After converting the timestamp value to the proper unit, use 'BETWEEN TO_TIMESTAMP(start) AND TO_TIMESTAMP(end)' to ensure only the records in that range are returned; skipping conversion or using mismatched units may miss or mistakenly include records outside the intended range."
72,sf_bq264,THELOOK_ECOMMERCE,db,where;filter;between;to_timestamp;date_cast,THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.USERS,THELOOK_ECOMMERCE.THELOOK_ECOMMERCE.USERS.created_at,date,all,"ENSURE: when filtering by ""created_at"" timestamp, convert microseconds to seconds by dividing ""created_at"" by 1,000,000.0 before passing to TO_TIMESTAMP | CONTEXT: The ""created_at"" values in this database are stored in microseconds; direct use with TO_TIMESTAMP without this conversion results in incorrect datetime filtering and record counts | WHEN_TO_CHECK: Whenever applying date range filters on the ""created_at"" column | EXAMPLE_USAGE: To retrieve rows created in a date range, use 'TO_TIMESTAMP(""created_at"" / 1000000.0) BETWEEN TO_TIMESTAMP('start') AND TO_TIMESTAMP('end')' instead of 'TO_TIMESTAMP(""created_at"") BETWEEN ...', which would give wrong times and counts."
73,sf_bq273,THELOOK_ECOMMERCE,generic,join;aggregation,all,all,all,all,"ENSURE: cost value sources match the product/item relationship in business logic | PRINCIPLE: Profit or cost calculations should use cost fields from the product table referenced by order/item lines, not from unrelated inventory tables | WHEN_TO_APPLY: When calculating financial metrics involving products, items, or inventory | EXAMPLE_USAGE: If an order line references ""product_id"", verify cost comes from PRODUCTS.""cost"" via 'JOIN PRODUCTS ON order_line.""product_id"" = PRODUCTS.""id""'. Using inventory cost without confirming this relationship risks miscalculating profits."
74,sf_bq273,THELOOK_ECOMMERCE,generic,filter;date_cast,all,all,all,all,"VERIFY: date range filters are compatible with the datetime formats of source columns | PRINCIPLE: Date filters must convert timestamps appropriately to match desired date ranges; using raw timestamp fields may cause misaligned results | WHEN_TO_APPLY: Whenever filtering between dates on timestamped data | EXAMPLE_USAGE: If source dates are in Unix timestamp format, convert using functions like TO_TIMESTAMP_NTZ before comparing to date strings. For example, 'WHERE TO_TIMESTAMP_NTZ(source.""created_at"" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('start_date') AND TO_TIMESTAMP_NTZ('end_date')' is correct; direct comparison without conversion is incorrect."
75,sf_bq273,THELOOK_ECOMMERCE,generic,left join;aggregation;date_cast,all,all,all,all,"VERIFY: when comparing aggregates month over month, match current month value to exactly one prior month using date arithmetic | PRINCIPLE: MoM comparisons require accurate alignment of current and previous time windows, typically using date adjustment functions | WHEN_TO_APPLY: When creating month-over-month metrics | EXAMPLE_USAGE: Use a LEFT JOIN with 'ON current.month = DATEADD(MONTH, -1, prior.month)' to ensure each current month compares only to its immediate predecessor. Avoid joining on mismatched or unrelated date values."
76,sf_bq273,THELOOK_ECOMMERCE,generic,aggregation;group by,all,all,all,all,"CHECK: aggregate grouping keys include only relevant dimensions when a single filter applies | PRINCIPLE: If the analysis is limited to one dimension (e.g., only one traffic source), grouping by additional keys is unnecessary and can create miscounted results | WHEN_TO_APPLY: Whenever grouping query results by time, category, or dimension | EXAMPLE_USAGE: For metrics on Facebook traffic only, use 'GROUP BY month' instead of 'GROUP BY month, traffic_source'. The latter can introduce duplicate or meaningless groups when only one source exists."
77,sf_bq273,THELOOK_ECOMMERCE,generic,aggregation;coalesce,all,all,all,Yes,"ENSURE: use COALESCE (or other default-value functions) when calculating differences between aggregates to handle NULLs gracefully | PRINCIPLE: Subtraction involving NULLs returns NULL, which can obscure results; COALESCE sets a default value where needed | WHEN_TO_APPLY: When calculating change metrics, especially first or partial periods | EXAMPLE_USAGE: For 'profit_difference = COALESCE(curr.profit - prev.profit, 0)', the use of COALESCE ensures a valid numeric output even when no previous value exists. Omitting it results in NULLs that disrupt analysis."
78,sf_bq273,THELOOK_ECOMMERCE,db,join;aggregation,PRODUCTS,PRODUCTS.cost,numeric,all,"ENSURE: profit calculations use PRODUCTS.""cost"" joined through ORDER_ITEMS.""product_id"" and PRODUCTS.""id"" rather than INVENTORY_ITEMS.""cost"" or ORDER_ITEMS.""inventory_item_id"" | CONTEXT: ORDER_ITEMS links to PRODUCTS via ""product_id"", and PRODUCTS contains the correct ""cost"" for profit calculations; using INVENTORY_ITEMS can result in inaccurate profit figures | WHEN_TO_CHECK: When calculating order profit using cost values | EXAMPLE_USAGE: When calculating profit per order, verify that you use 'JOIN PRODUCTS ON ORDER_ITEMS.""product_id"" = PRODUCTS.""id""' and 'PRODUCTS.""cost""' in your profit formula. Using 'JOIN INVENTORY_ITEMS ON ORDER_ITEMS.""inventory_item_id"" = INVENTORY_ITEMS.""id""' and 'INVENTORY_ITEMS.""cost""' is incorrect, as this doesn't match the appropriate product cost."
79,sf_bq273,THELOOK_ECOMMERCE,db,filter;date_cast,ORDERS,ORDERS.created_at,date,all,"ENSURE: date filters on orders use TO_TIMESTAMP_NTZ for proper timestamp conversion and range definitions | CONTEXT: Orders' ""created_at"" values are Unix timestamps, requiring division and conversion to match date filters accurately | WHEN_TO_CHECK: When selecting orders within a specific date range | EXAMPLE_USAGE: To filter for July–November 2022 orders, use 'TO_TIMESTAMP_NTZ(orders.""created_at"" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2022-07-01') AND TO_TIMESTAMP_NTZ('2023-11-30')'. Filtering without conversion, such as 'orders.""created_at"" BETWEEN ...', will not match expected dates due to format mismatch."
80,sf_bq273,THELOOK_ECOMMERCE,db,left join;aggregation;date_cast,monthly_sales,monthly_sales.delivery_month,date,all,"REMEMBER: month-over-month comparisons should use LEFT JOIN with DATEADD(MONTH, -1, prev.""delivery_month"") to align current and prior months | CONTEXT: Comparing monthly aggregates requires matching derived current month with the exact prior month | WHEN_TO_CHECK: When joining monthly aggregates for MoM comparison | EXAMPLE_USAGE: To compare August profits to July, use 'LEFT JOIN monthly_profits prev ON curr.""delivery_month"" = DATEADD(MONTH, -1, prev.""delivery_month"")'. Do not join on mismatched or absolute month numbers."
81,sf_bq273,THELOOK_ECOMMERCE,db,aggregation;group by,monthly_sales,monthly_sales.delivery_month,date,all,"ENSURE: monthly profit aggregation excludes GROUP BY on traffic_source when analyzing a single source | CONTEXT: Including traffic_source in grouping for Facebook-only results creates redundant or incorrect groupings | WHEN_TO_CHECK: When aggregating profits by month for a specific traffic source | EXAMPLE_USAGE: Use 'GROUP BY delivery_month' when the traffic_source is fixed (e.g., only Facebook). Grouping by both 'delivery_month, traffic_source' can produce duplicate or unintended results."
82,sf_bq273,THELOOK_ECOMMERCE,db,aggregation;coalesce,monthly_sales,monthly_sales.total_profit,numeric,Yes,"VERIFY: COALESCE is applied to MoM profit difference computation to handle NULLs for initial or missing prior months | CONTEXT: Profit difference may be NULL when a previous month does not exist; COALESCE ensures a default value of 0 | WHEN_TO_CHECK: When calculating month-over-month profit changes | EXAMPLE_USAGE: Use 'COALESCE(curr.""profit"" - prev.""profit"", 0)' in SELECT for MoM difference. Omitting COALESCE ('curr.""profit"" - prev.""profit""') leaves initial month results as NULL, which leads to unclear output."
83,sf_bq273,THELOOK_ECOMMERCE,db,date_trunc;to_date;to_timestamp;to_char,all,all,all,all,"VERIFY: use DATE_TRUNC('MONTH', TO_DATE(TO_TIMESTAMP_NTZ(""created_at""/1000000))) for monthly grouping of order activity from ""created_at"" epoch in order_details | CONTEXT: To consistently report or group by month using the order_details ""created_at"" timestamp, proper transformation and truncation functions are required to align with expected time reporting granularity | WHEN_TO_CHECK: When extracting or grouping by month from ""created_at"" in order_details | EXAMPLE_USAGE: Correct: 'SELECT DATE_TRUNC('MONTH', TO_DATE(TO_TIMESTAMP_NTZ(""created_at""/1000000))) AS reporting_month FROM order_details'; Incorrect: 'SELECT TO_CHAR(TO_TIMESTAMP_NTZ(""created_at""/1000000), 'YYYY-MM') AS order_month' creates a string which may not consistently match across downstream processing or grouping."
84,sf_bq273,all,generic,aggregation;sum;subtraction,all,all,all,all,"ENSURE: separate SUM aggregations before performing arithmetic operations in aggregate queries | PRINCIPLE: Arithmetic operations should be done after aggregation when calculating total metrics, rather than aggregating after row-wise calculations | WHEN_TO_APPLY: When designing queries for aggregate totals (e.g., profits, net balances) | EXAMPLE_USAGE: When calculating overall profit, use 'SUM(price) - SUM(cost)' rather than 'SUM(price - cost)'; the former aggregates totals accurately across all rows, while the latter may produce incorrect results if individual (price - cost) per row is not representative."
85,sf_bq273,all,generic,date_trunc;to_date;to_timestamp;to_char,all,all,all,all,"VERIFY: timestamp conversion and truncation functions match target reporting granularity for date grouping | PRINCIPLE: To ensure correct date-based grouping, verify that all timestamp conversions produce consistent date formats and use proper granularity (e.g., months, days) | WHEN_TO_APPLY: When grouping results by date/time periods | EXAMPLE_USAGE: If grouping by month, use 'DATE_TRUNC('MONTH', TO_DATE(timestamp_column))' rather than casting to string formats like 'TO_CHAR(timestamp_column, 'YYYY-MM')', as the latter can cause inconsistencies and unexpected results in groupings and further calculations."
86,sf_bq291,NOAA_GLOBAL_FORECAST_SYSTEM,generic,filter;order by;limit;cte_definition,all,all,all,all,"ENSURE: when performing spatial selection, use nearest-point queries (ORDER BY distance LIMIT 1) rather than fixed-distance filtering unless exclusion is desired | PRINCIPLE: Arbitrary cutoff filters can unintentionally exclude all relevant data points if no point falls within the threshold; nearest-point selection always returns a result | WHEN_TO_APPLY: Any time you're finding the closest object/location in spatial databases | EXAMPLE_USAGE: Use 'ORDER BY ST_DISTANCE(geom, req_geom) ASC LIMIT 1' in a CTE or subquery to always pick the closest record; avoid 'WHERE ST_DISTANCE(geom, req_geom) < X' unless you want to exclude far points—even then, combine with ORDER BY and LIMIT for robustness."
87,sf_bq291,NOAA_GLOBAL_FORECAST_SYSTEM,generic,select;group by;aggregation,all,all,all,all,"VERIFY: include all necessary contextual metadata columns in the SELECT statement, not necessarily in GROUP BY, for clearer debugging and interpretation | PRINCIPLE: Columns like coordinates or distances helpful for context should be in result output, but only group by relevant aggregation keys | WHEN_TO_APPLY: When building result tables with explanatory context or metadata | EXAMPLE_USAGE: SELECT relevant grouping keys and add metadata columns (e.g., coordinates, distances); avoid unnecessary GROUP BY on metadata: 'SELECT time, date, lon, lat, dist_m GROUP BY time, date' is correct, while 'GROUP BY time, date, lon, lat, dist_m' causes over-aggregation and unwanted row splitting."
88,sf_bq291,NOAA_GLOBAL_FORECAST_SYSTEM,generic,cte_definition;join;filter;aggregation;case,all,all,all,all,"ENSURE: CTEs are used to organize complex queries, separating logic like nearest-point selection, data flattening, date calculations, and precipitation classification into distinct stages | PRINCIPLE: CTEs improve clarity and maintainability, making each transformation explicit and easier to validate | WHEN_TO_APPLY: When queries combine multiple filtering, calculation, and classification steps | EXAMPLE_USAGE: Build CTEs like nearest_point (select closest record), forecast_flat (flattened forecast data), next_day (fetch next day's results), and daily_temp (compute averages), referencing output from previous CTEs to enforce proper sequencing and validation."
89,sf_bq291,NOAA_GLOBAL_FORECAST_SYSTEM,generic,aggregation;group by,all,all,all,all,"VERIFY: aggregation keys in GROUP BY match the intended reporting period, especially when tracking multiple time series (e.g., creation_time plus forecast_date) | PRINCIPLE: Failing to group by all required keys can produce incorrect aggregations, missing intended data separation | WHEN_TO_APPLY: Whenever aggregating or reporting over composite temporal keys | EXAMPLE_USAGE: Group on both creation_time and forecast_date for time series with multiple snapshots, not just one or the other: 'GROUP BY creation_time, forecast_date' is correct; 'GROUP BY forecast_date' alone merges distinct forecast runs."
90,sf_bq291,NOAA_GLOBAL_FORECAST_SYSTEM,generic,case,all,all,all,all,"CHECK: CASE WHEN logic for classification uses correct calculated variables, not raw source columns when derived versions are present | PRINCIPLE: Using the intended calculated field (e.g., daily average temperature) prevents misclassification due to using per-interval data rather than summary statistics | WHEN_TO_APPLY: When CASE WHEN is used for conditional output based on computed metrics | EXAMPLE_USAGE: In a query determining snow/rain, use 'CASE WHEN daily_temp < 1 ...' instead of raw temperature values, ensuring that aggregation occurs before logic application for reliable classification."
91,sf_bq291,NOAA_GLOBAL_FORECAST_SYSTEM,db,filter;order by;limit;cte_definition,NOAA_GLOBAL_FORECAST_SYSTEM.NOAA_GLOBAL_FORECAST_SYSTEM.NOAA_GFS0P25,all,all,all,"ENSURE: select the single nearest grid point to requested coordinates using ST_DISTANCE and LIMIT 1, removing any fixed spatial distance filters | CONTEXT: Queries on grid-based forecast tables should use ST_DISTANCE to measure proximity and LIMIT 1 to ensure selection of the closest grid cell, rather than a hard cutoff (e.g., 5km) which can exclude all data | WHEN_TO_CHECK: When finding the relevant grid point for spatial weather forecasts | EXAMPLE_USAGE: Instead of 'WHERE ST_DISTANCE(grid_geom, req_geom) < 5000', use 'ORDER BY ST_DISTANCE(grid_geom, req_geom) ASC LIMIT 1' in the nearest_point CTE to reliably select the closest cell, ensuring data inclusion even if no point falls within an arbitrary distance."
92,sf_bq291,NOAA_GLOBAL_FORECAST_SYSTEM,db,select;aggregation;group by,NOAA_GLOBAL_FORECAST_SYSTEM.NOAA_GLOBAL_FORECAST_SYSTEM.NOAA_GFS0P25,lon,numeric,all,"REMEMBER: include lon, lat, and dist_m columns explicitly in SELECT output, not GROUP BY, to provide contextual information about chosen grid points | CONTEXT: These columns reflect metadata about the spatial selection and should be presented in result rows, but grouping by them is unnecessary when reporting per forecast date and creation time | WHEN_TO_CHECK: When reporting forecast results per grid cell and forecast date | EXAMPLE_USAGE: In final SELECT, add lon, lat, dist_m columns, but GROUP BY only on creation_time and forecast_date: 'SELECT creation_time, forecast_date, lon, lat, dist_m, ... GROUP BY creation_time, forecast_date'."
93,sf_bq291,NOAA_GLOBAL_FORECAST_SYSTEM,db,aggregation;group by,NOAA_GLOBAL_FORECAST_SYSTEM.NOAA_GLOBAL_FORECAST_SYSTEM.NOAA_GFS0P25,creation_time,date,all,"VERIFY: group results by creation_time and forecast_date to support multiple daily forecasts | CONTEXT: If the schema allows multiple forecasts/updates per day, grouping by both creation time and forecast_date ensures accurate aggregation and reporting | WHEN_TO_CHECK: When aggregating or reporting forecast statistics per time period | EXAMPLE_USAGE: Use 'GROUP BY creation_time, forecast_date' and not just one column so that if forecasts are issued multiple times per day, each gets properly represented."
94,sf_bq291,NOAA_GLOBAL_FORECAST_SYSTEM,db,aggregation;join;filter;cte_definition;cast,NOAA_GLOBAL_FORECAST_SYSTEM.NOAA_GLOBAL_FORECAST_SYSTEM.NOAA_GFS0P25,forecast_date,date,all,"ENSURE: daily average temperature calculations are based only on the next calendar day after creation_time, not other intervals | CONTEXT: To accurately classify precipitation type using next day temperature, only use data from the immediate next day's forecast | WHEN_TO_CHECK: When joining or calculating daily_temp for precipitation classification | EXAMPLE_USAGE: In CTE daily_temp, restrict rows to 'forecast_date = DATE(creation_time) + INTERVAL '1 day'', ensuring JOINs use the correct forecast period rather than multiple days or offsets."
95,sf_bq291,NOAA_GLOBAL_FORECAST_SYSTEM,db,aggregation;case;cte_definition,NOAA_GLOBAL_FORECAST_SYSTEM.NOAA_GLOBAL_FORECAST_SYSTEM.NOAA_GFS0P25,daily_temp,numeric,all,"VERIFY: use computed daily_temp exclusively in precipitation CASE WHEN logic to separate snow vs rain events | CONTEXT: For accurate classification, the daily_avg temperature should be used as the decision variable for weather type | WHEN_TO_CHECK: Whenever output requires separating snow and rain in forecast results | EXAMPLE_USAGE: Implement 'CASE WHEN daily_temp < 1 THEN snow = precip ELSE rain = precip END' logic in SELECT statement to ensure correct meteorological classification."
96,sf_bq321,IDC,generic,aggregation;count;count distinct,all,all,all,all,"VERIFY: The correct table or data source is used for the intended aggregation or analysis | PRINCIPLE: When multiple similar tables exist in a database, each may contain different subsets, formats, or levels of completeness; using the wrong table can lead to incorrect results | WHEN_TO_APPLY: Whenever there is a choice between tables that appear similar or overlapping for a query | EXAMPLE_USAGE: If tasked with counting unique entities (e.g., StudyInstanceUIDs, user_ids, product_ids), first ensure that the table queried contains all relevant records. For example, querying a limited or summary table (e.g., 'SELECT COUNT(DISTINCT user_id) FROM USER_SUMMARY') instead of the complete table ('SELECT COUNT(DISTINCT user_id) FROM USERS') may lead to underreported figures. Always validate which source is canonical for the required data."
97,sf_bq321,IDC,db,aggregation;count;count distinct,all,all,all,"ENSURE: When counting unique StudyInstanceUIDs related to DICOM studies, use IDC.IDC_V17.DICOM_ALL instead of IDC.IDC_V17.DICOM_PIVOT | CONTEXT: The DICOM_ALL table contains the complete set of StudyInstanceUIDs, whereas DICOM_PIVOT may contain a different subset or structure, leading to incorrect counts | WHEN_TO_CHECK: When calculating statistics or aggregations based on unique StudyInstanceUIDs for the IDC database | EXAMPLE_USAGE: For correct unique study counts, use 'SELECT COUNT(DISTINCT StudyInstanceUID) FROM IDC.IDC_V17.DICOM_ALL'. Using 'FROM IDC.IDC_V17.DICOM_PIVOT' can result in mismatched and incomplete study counts.",
98,sf_bq321,IDC,db,all,all,all,all,all,"AVOID: using IDC.IDC_V17.DICOM_PIVOT for queries unless explicitly instructed; use IDC.IDC_V17.DICOM_ALL as the default source | PRINCIPLE: DICOM_ALL is the comprehensive canonical source for DICOM metadata; DICOM_PIVOT is a specialized view with different structure and may lack completeness | WHEN_TO_APPLY: For any query on IDC database requiring DICOM metadata, use DICOM_ALL by default | EXAMPLE_USAGE: Default to 'FROM IDC.IDC_V17.DICOM_ALL' for all DICOM queries. Only use 'FROM IDC.IDC_V17.DICOM_PIVOT' if the question explicitly asks for pivot structure or mentions pivot table."
99,sf_bq321,IDC,db,join;from,all,all,all,all,"ENSURE: When querying segmentation metadata (SegmentedPropertyCategory, SegmentLabel, etc.) or needing to reference SOPInstanceUID for segmentations, join DICOM_ALL with IDC.IDC_V17.SEGMENTATIONS on seg_SOPInstanceUID | CONTEXT: Segmentation-specific metadata like SegmentedPropertyCategory.CodeMeaning is stored in the SEGMENTATIONS table; DICOM_ALL contains the base SOPInstanceUID that references segmentations | WHEN_TO_CHECK: When the query involves segmentation categories, segment labels, or needs to link DICOM instances to their segmentation details | EXAMPLE_USAGE: For segmentation queries, use 'FROM IDC.IDC_V17.DICOM_ALL d JOIN IDC.IDC_V17.SEGMENTATIONS s ON d.SOPInstanceUID = s.seg_SOPInstanceUID'. This join enables access to segmentation-specific fields while maintaining the complete DICOM metadata."
98,sf_bq341,CRYPTO,generic,select,all,address,str,all,"VERIFY: The SELECT clause contains exactly the columns required by the specification/output | PRINCIPLE: Output should match the required structure for column count and names; including extra columns leads to mismatches | WHEN_TO_APPLY: Whenever writing a SELECT statement where the expected result has a specific number of columns or specific names | EXAMPLE_USAGE: If the specification says ""output address,"" use 'SELECT address' only. Do not include additional columns such as 'SELECT address, balance', as this causes column count errors and mismatches against expected outputs."
99,sf_bq341,CRYPTO,db,select;group by;having;order by;limit,all,address,str,all,"ENSURE: Only include the 'address' column in the final SELECT output when the question requires only addresses, excluding 'balance' or other columns | CONTEXT: The relevant table has both 'address' and 'balance' columns, but sometimes only 'address' is required in output; including extra columns results in incorrect results | WHEN_TO_CHECK: When writing a SELECT query for outputs that specify addresses only | EXAMPLE_USAGE: If the table columns are address and balance and the expected result is just a list of addresses, use 'SELECT address FROM table_name'. Avoid 'SELECT address, balance FROM table_name', as this will output an extra column not expected in results."
100,sf_bq349,GEO_OPENSTREETMAP,generic,join;inner join;left join;aggregation;count;group by,all,all,all,Yes,"VERIFY: The JOIN type matches the analytical intent—use INNER JOIN when excluding entities with no matches and LEFT JOIN when including all entities regardless of match | PRINCIPLE: The choice between INNER and LEFT JOIN determines whether unmatched rows are included; using LEFT JOIN during aggregation can inflate counts by including zeros or NULLs | WHEN_TO_APPLY: Any time aggregate functions (COUNT, SUM, etc.) are used after a JOIN, ensure the JOIN type reflects whether you want to count all entities or only those with matches | EXAMPLE_USAGE: If you want to count only groups/entities that have associated records (e.g., boundaries with POIs, customers with orders), use INNER JOIN: 'SELECT b.id, COUNT(*) FROM boundaries b INNER JOIN pois p ON ...'. Using LEFT JOIN instead ('SELECT b.id, COUNT(*) FROM boundaries b LEFT JOIN pois p ON ...') counts all boundaries, even those with no matching POIs, leading to misleading results."
101,sf_bq349,GEO_OPENSTREETMAP,db,join;inner join;left join;aggregation;count;group by,boundary_poi_counts,boundary_poi_counts.poi_count,int,Yes,"ENSURE: Use INNER JOIN instead of LEFT JOIN when counting POIs within boundaries to avoid including boundaries with zero POIs | CONTEXT: In the boundary_poi_counts CTE, boundaries are joined to POIs using ST_CONTAINS; using LEFT JOIN counts boundaries regardless of whether they contain POIs, while INNER JOIN restricts the count to only boundaries that actually contain at least one POI | WHEN_TO_CHECK: When aggregating or counting POIs per boundary in spatial queries involving boundary and POI tables | EXAMPLE_USAGE: When counting boundaries with POIs, verify the JOIN uses INNER JOIN on the spatial predicate: 'FROM boundaries b INNER JOIN pois p ON ST_CONTAINS(b.geom, p.geom)' is correct, as it excludes boundaries with no POIs. 'FROM boundaries b LEFT JOIN pois p ON ST_CONTAINS(b.geom, p.geom)' is incorrect, as it includes boundaries with zero POIs leading to inaccurate counts."
102,sf_bq359,GITHUB_REPOS,generic,aggregation;count,all,all,all,Yes,"ENSURE: aggregation functions specify the correct column and output alias to match expected result schema | PRINCIPLE: In SQL, COUNT(*) counts all rows, whereas COUNT(column) counts only non-NULL entries; also, output column names in SELECT must match expected results for clarity and validation purposes | WHEN_TO_APPLY: Whenever performing aggregations and output formatting for reporting queries | EXAMPLE_USAGE: If expectations are for 'num_commits', use 'COUNT(commit) AS num_commits' in SELECT. Using 'COUNT(*) AS commit_count' can cause both data accuracy and result-format mismatches. Correct: 'SELECT COUNT(commit) AS num_commits'; Incorrect: 'SELECT COUNT(*) AS commit_count'."
103,sf_bq359,GITHUB_REPOS,db,aggregation;count;group by;order by;limit;inner join,stats,stats.commit,all,Yes,"ENSURE: when counting the number of commits in the 'stats' table, use COUNT(s.""commit"") and name the column 'num_commits' to match schema conventions | CONTEXT: The 'stats' table contains a ""commit"" column representing individual commits. Using COUNT(s.""commit"") ensures only non-NULL commit entries are counted, and using 'num_commits' matches output expectations | WHEN_TO_CHECK: When aggregating commit counts from the 'stats' table for reporting or analytics | EXAMPLE_USAGE: When writing 'SELECT COUNT(s.""commit"") AS num_commits FROM stats s', verify the count is over 's.""commit""' and not just 'COUNT(*)'. If you use 'COUNT(*) AS commit_count', it may count all rows regardless of commit field and produce a column name mismatch with expected results."
104,sf_bq421,IDC,generic,from;distinct;group by;count,all,all,all,all,"VERIFY: correct data source/table is used when multiple similar choices exist | PRINCIPLE: When more than one table contains related or overlapping information, always check which is the GOLD (canonical) source to ensure results match expected aggregates and contents | WHEN_TO_APPLY: Whenever a schema presents similarly named tables or versions (e.g., *_ALL vs *_METADATA) | EXAMPLE_USAGE: If a database has both DATA_ALL and DATA_METADATA tables, verify which source table GOLD expects for analysis; using DATA_METADATA might yield incomplete or outdated results, whereas DATA_ALL aggregates the necessary dataset for proper counting and matching."
105,sf_bq421,IDC,db,from,IDC.IDC_V17.DICOM_ALL,all,all,all,"ENSURE: all queries sourcing imaging metadata use IDC.IDC_V17.DICOM_ALL as the FROM table, not IDC.IDC_V17.DICOM_METADATA | CONTEXT: DICOM_ALL contains the comprehensive dataset required to match the expected GOLD output, while DICOM_METADATA may be incomplete or differently structured | WHEN_TO_CHECK: When querying for DICOM-related metadata or performing analysis requiring complete imaging records in IDC.IDC_V17 schema | EXAMPLE_USAGE: When writing a query to pull data on 'embeddingMedium_CodeMeaning', verify that FROM IDC.IDC_V17.DICOM_ALL is used:"
106,sf_bq421,IDC,db,from;select,IDC.IDC_V17.DICOM_ALL,embeddingMedium_CodeMeaning,str,all,Correct: 'SELECT embeddingMedium_CodeMeaning FROM IDC.IDC_V17.DICOM_ALL...'
107,sf_bq421,IDC,db,from;select,IDC.IDC_V17.DICOM_METADATA,embeddingMedium_CodeMeaning,str,all,Incorrect: 'SELECT embeddingMedium_CodeMeaning FROM IDC.IDC_V17.DICOM_METADATA...'
108,sf_bq421,IDC,db,all,all,all,all,all,Using the wrong source table can lead to missing or mismatched values in results.
109,sf_bq429,CENSUS_BUREAU_ACS_2,generic,join,all,all,all,all,"VERIFY: All relevant join keys are included in JOIN conditions, especially when tables have composite, non-unique keys | PRINCIPLE: When joining tables, omitting part of a composite key can cause duplicate or mismatched rows due to ambiguous join logic | WHEN_TO_APPLY: Whenever joining tables where multiple columns together form a unique identifier | EXAMPLE_USAGE: When two tables both have (id1, id2), joining only on 'ON a.id1 = b.id1' can cause duplicates; correct approach is 'ON a.id1 = b.id1 AND a.id2 = b.id2' to ensure one-to-one matching."
110,sf_bq429,CENSUS_BUREAU_ACS_2,generic,distinct;aggregation;group by,all,all,all,all,"CHECK: Use DISTINCT or aggregation to suppress unwanted duplicate rows after joins | PRINCIPLE: Joins can multiply rows if keys are not unique, so DISTINCT (or GROUP BY) should be used in final output to ensure unique results per entity | WHEN_TO_APPLY: After performing joins, when the output shows duplicate rows for the same entity | EXAMPLE_USAGE: If the output contains multiple identical rows for each state, add 'SELECT DISTINCT ...' or GROUP BY to ensure uniqueness."
111,sf_bq429,CENSUS_BUREAU_ACS_2,generic,filter;select,all,all,all,all,"ENSURE: Final SELECT clause matches required output column list and ordering exactly | PRINCIPLE: Output column number, names, and order must match the expected results; extra columns or mismatches lead to incorrect results | WHEN_TO_APPLY: When preparing the SELECT clause for queries designed to match a specific result format | EXAMPLE_USAGE: Do not output extra columns that are not required (e.g., don't include internal keys); ensure only required ones are present in the results."
112,sf_bq429,CENSUS_BUREAU_ACS_2,db,join;left join;on,state_avg_income_diff,state_avg_income_diff.state_code,str,all,"ENSURE: when joining state_avg_income_diff with state_vulnerable_avg, JOIN on both state_code and state_name, not just one of these columns | CONTEXT: Both state_avg_income_diff and state_vulnerable_avg contain state_code and state_name fields and represent state-level aggregates; joining only on state_code can lead to ambiguous matches and duplicate rows | WHEN_TO_CHECK: When joining state-level aggregate tables that both have state_code and state_name | EXAMPLE_USAGE: When writing 'LEFT JOIN state_vulnerable_avg ON s.state_code = v.state_code AND s.state_name = v.state_name', verify both columns are used in the ON clause. Using just 'ON s.state_code = v.state_code' risks joining unrelated state_name values, creating extra rows per state."
113,sf_bq429,CENSUS_BUREAU_ACS_2,db,aggregation;distinct;group by,state_avg_income_diff,all,all,all,"REMEMBER: Use SELECT DISTINCT on state_code, state_name, and avg_income_diff when aggregating state-level results to suppress duplicate state rows in final output | CONTEXT: Duplicates occur when a join creates multiple rows for the same state due to ambiguous key matches; DISTINCT will return only one row per unique set of these columns | WHEN_TO_CHECK: When presenting final output for state-level aggregates, especially after joins with non-unique keys | EXAMPLE_USAGE: When the query's SELECT clause is 'SELECT DISTINCT s.state_code, s.state_name, s.avg_income_diff', verify that no state appears more than once in results. Omitting DISTINCT, as in 'SELECT s.state_code, s.state_name, s.avg_income_diff', may cause multiple identical rows."
114,sf_bq429,CENSUS_BUREAU_ACS_2,db,filter;select,state_avg_income_diff,state_avg_income_diff.state_name,str,all,"ENSURE: Output only the required columns – state_name, avg_income_diff, avg_vulnerable_employees_2017 – in final SELECT, matching target specification | CONTEXT: The GOLD output specifies only these three columns, so extra columns like state_code or unnecessary values must be excluded | WHEN_TO_CHECK: When defining the SELECT clause for queries expected to match a specific output specification | EXAMPLE_USAGE: Final query should be 'SELECT s.state_name, s.avg_income_diff, v.avg_vulnerable_employees_2017' rather than 'SELECT s.state_code, s.state_name, s.avg_income_diff, ...'."
115,sf_bq444,CRYPTO,generic,union all,all,all,all,all,"ENSURE: when retrieving multiple event types, split the queries and combine them with UNION ALL instead of a single filter | PRINCIPLE: Multi-event queries may require distinct criteria that cannot be covered by a single WHERE clause, so combining result sets ensures completeness | WHEN_TO_APPLY: When aggregating distinct entities or event types in any logs/audit table | EXAMPLE_USAGE: For events 'A' and 'B', write two queries—one with WHERE for 'A', one with WHERE for 'B'—and use 'UNION ALL' to combine; relying on 'WHERE type IN ('A', 'B')' may not work if filtering logic differs or hashes must be exact."
116,sf_bq444,CRYPTO,generic,filter;where,all,all,all,all,"VERIFY: that comparison values in WHERE clauses are data type-appropriate (e.g., quoted if strings/hashes) | PRINCIPLE: SQL comparisons must match types (strings in quotes, numbers unquoted) to work as intended and avoid mis-matches | WHEN_TO_APPLY: Whenever filtering by hashes, IDs, or any field that can be interpreted differently by SQL | EXAMPLE_USAGE: When filtering a column for '0xABC', use WHERE col = '0xABC', not WHERE col = 0xABC; missing quotes makes logic fail."
117,sf_bq444,CRYPTO,generic,select,all,all,all,all,"ENSURE: result sets include only the requested columns in correct order | PRINCIPLE: Output format should match requirements exactly (column count, names, order) to avoid unintended errors or misinterpretations | WHEN_TO_APPLY: When finalizing SELECT statements for reporting, API, or downstream use | EXAMPLE_USAGE: If requirements ask for columns (timestamp, id), include only those: 'SELECT timestamp, id', not 'SELECT *' or 'SELECT timestamp, id, extra_column'."
118,sf_bq444,CRYPTO,generic,order by;asc,all,all,all,all,"ENSURE: result sets are ordered as specified by requirements (e.g., ascending timestamp) | PRINCIPLE: Data presentation needs explicit ordering to guarantee predictability, especially for time-based or sequential data | WHEN_TO_APPLY: Whenever returning sorted lists, logs, or time-series data | EXAMPLE_USAGE: Use 'ORDER BY timestamp ASC' for chronological order; missing ordering or incorrect ordering direction leads to out-of-sequence results."
119,sf_bq444,CRYPTO,db,cte_definition;filter;union all,CRYPTO.CRYPTO_ETHEREUM.LOGS,all,all,all,"ENSURE: when querying for mint and burn events, split the events into separate CTEs and combine them with UNION ALL | CONTEXT: The relevant database stores event logs (including mint and burn events) in a single table; to accurately retrieve both event types, separate logic is needed before combining results | WHEN_TO_CHECK: When filtering for multiple distinct event types within logs/events tables | EXAMPLE_USAGE: If needing both mint and burn events, create two CTEs (one for mint, one for burn) filtering by distinct topic hash (e.g., ""topic[0]"" = 'mint_hash' for mint and ""topic[0]"" = 'burn_hash' for burn), then combine with 'UNION ALL' to deliver a unified result set. Using only one filter or not combining will miss one event type."
120,sf_bq444,CRYPTO,db,filter;where,CRYPTO.CRYPTO_ETHEREUM.LOGS,CRYPTO.CRYPTO_ETHEREUM.LOGS.topics,str,all,"VERIFY: ""topics""[0] values are quoted as strings in WHERE clause comparisons | CONTEXT: The ""topics"" array holds hashed string values identifying event types, and these must be matched exactly using quoted literals | WHEN_TO_CHECK: Whenever filtering by event type in the ""topics""[0] field in log tables | EXAMPLE_USAGE: When filtering for events, ensure your WHERE clause matches exact strings: 'WHERE ""topics""[0] = '0x123...'' is correct. Omitting quotes or using unquoted hashes (e.g., WHERE ""topics""[0] = 0x123...) fails to match correctly."
121,sf_bq444,CRYPTO,db,select,CRYPTO.CRYPTO_ETHEREUM.LOGS,all,all,all,"ENSURE: SELECT only the requested output columns, specifically block_timestamp, block_number, transaction_hash | CONTEXT: The output should strictly align with requirements (no extra or missing columns), particularly for event retrieval from logs | WHEN_TO_CHECK: When preparing final SELECT statements for event log queries | EXAMPLE_USAGE: Use 'SELECT block_timestamp, block_number, transaction_hash' in your final statement; including additional columns (e.g., topics, address) deviates from requirements."
122,sf_bq444,CRYPTO,db,order by;asc,CRYPTO.CRYPTO_ETHEREUM.LOGS,CRYPTO.CRYPTO_ETHEREUM.LOGS.block_timestamp,date,all,"ENSURE: the final result is ORDERED BY block_timestamp ascending | CONTEXT: Time-based ordering is required for event log queries to reflect chronological progression | WHEN_TO_CHECK: When presenting result sets that contain timestamps/events | EXAMPLE_USAGE: At the end of your query, verify inclusion of 'ORDER BY block_timestamp ASC'; omitting ordering or using DESC will show events out of chronological order."
123,sf_bq444,CRYPTO,db,all,all,all,all,all,"ENSURE: when querying transaction data with nested VARIANT arrays (inputs/outputs), use LATERAL FLATTEN to decompose arrays before aggregation | PRINCIPLE: TRANSACTIONS tables in CRYPTO databases often store inputs and outputs as VARIANT arrays; these must be flattened with LATERAL FLATTEN before per-item operations | WHEN_TO_APPLY: When calculating address-level balances, transaction values, or any per-input/output aggregations from TRANSACTIONS tables | EXAMPLE_USAGE: For Bitcoin Cash, Dash, or similar cryptocurrencies with nested transaction data, use 'FROM CRYPTO.CRYPTO_X.TRANSACTIONS t, LATERAL FLATTEN(input => t.""inputs"") inp, LATERAL FLATTEN(input => t.""outputs"") out' to access individual input/output items. Then extract fields using 'inp.value[""address""]::string', 'out.value[""value""]::float'. Do NOT use separate INPUTS/OUTPUTS tables unless they are explicitly the correct flat structure for the schema."
123,sf_bq264,all,generic,date;to_date;to_timestamp;to_timestamp_ltz;date_cast;cast,all,all,date,all,"VERIFY: output date columns use correct conversion and formatting, not raw epoch or timezone-mismatched functions | PRINCIPLE: Displayed date fields should be presented using proper date extraction/conversion (e.g., DATE(TO_TIMESTAMP_LTZ(...))) to ensure expected format and timezone | WHEN_TO_APPLY: When displaying or filtering date columns derived from integer epoch fields | EXAMPLE_USAGE: 'SELECT DATE(TO_TIMESTAMP_LTZ(start_date / 1000000)) AS start_date' produces correct date; using 'TO_TIMESTAMP_NTZ(...)' or no conversion results in inconsistent or incorrect date output."
124,sf_bq166,all,generic,join;left join;inner join;filter,all,all,all,Yes,"CHECK: After using LEFT JOIN to preserve all left-side records, apply appropriate NULL filters in WHERE clause to exclude unmatched records if needed | PRINCIPLE: LEFT JOIN includes NULLs for unmatched right-side records; without filtering, these NULLs may cause incorrect aggregations or analytics | WHEN_TO_APPLY: When using LEFT JOIN but analysis requires only records with valid matches | EXAMPLE_USAGE: After 'LEFT JOIN stations s ON t.station_id = s.station_id', add 'WHERE s.station_id IS NOT NULL' to exclude transactions without valid station mappings; omitting this filter includes incomplete records in results."
130,sf_bq450,ETHEREUM_BLOCKCHAIN,db,filter;where;null_handling,TRACES,call_type,str,Yes,"CAUTION: When filtering the call_type column in TRACES table, use an exclusion list with NULL handling instead of a simple equality filter | CONTEXT: The call_type column contains various transaction types (call, delegatecall, callcode, staticcall, etc.) and may have NULL values. To correctly include all standard calls while excluding special call types, use NOT IN with an OR IS NULL clause | WHEN_TO_CHECK: When filtering transactions by call_type to exclude delegatecall, callcode, and staticcall | EXAMPLE_USAGE: Correct: 'WHERE (""call_type"" NOT IN ('delegatecall','callcode','staticcall') OR ""call_type"" IS NULL)'; this includes standard calls and NULL entries. Incorrect: 'WHERE ""call_type"" = 'call''; this excludes NULL values and potentially other valid call types. The exclusion approach ensures all non-special-call transactions are included."
