mem_id,instance_id,db,scope,sql_operations,table,column,data_type,nulls,rule
0,bq008,ga360,db,group by;aggregation,all,all,all,all,"ENSURE: group hits by fullVisitorId, visitId, page.pagePath, and type in the all_hits CTE, selecting MIN(hitNumber) AS hitNumber and MIN(time) AS time to capture each session’s first hit per page | CONTEXT: The hits table records multiple hits for the same pagePath and type per session; without grouping by all relevant keys and taking the earliest hit, later duplicates inflate duration calculations | WHEN_TO_CHECK: When defining the all_hits CTE for session-level page hit aggregation | EXAMPLE_USAGE: Correct: WITH all_hits AS ( SELECT s.fullVisitorId, s.visitId, h.page.pagePath AS home_page, h.type, MIN(h.hitNumber) AS hitNumber, MIN(h.time) AS time FROM sessions s JOIN hits h ON s.fullVisitorId = h.fullVisitorId AND s.visitId = h.visitId GROUP BY s.fullVisitorId, s.visitId, h.page.pagePath, h.type Incorrect (missing pagePath and type in GROUP BY, causing aggregated times across pages): … GROUP BY s.fullVisitorId, s.visitId"
1,bq008,ga360,db,window;filter,all,all,all,all,"VERIFY: filter out self‐transitions in next_page_stats by adding WHERE next_page <> home_page after computing LEAD/LAG | CONTEXT: Including transitions where next_page equals home_page produces zero-duration loops that skew max duration metrics | WHEN_TO_CHECK: When calculating next_page_stats for page-to-page duration analysis | EXAMPLE_USAGE: Correct: WITH next_page_stats AS ( SELECT home_page, next_page, next_time, next_time - time AS duration FROM ( SELECT home_page, LEAD(home_page) OVER (PARTITION BY fullVisitorId, visitId ORDER BY time) AS next_page, LEAD(time) OVER (PARTITION BY fullVisitorId, visitId ORDER BY time) AS next_time, time FROM all_hits t WHERE next_page <> home_page Incorrect (omitting the WHERE, so rows like home_page='/home' and next_page='/home' remain, yielding zero durations): …"
2,bq008,all,generic,group by;aggregation,events,events.event_time,date,all,"VERIFY: when summarizing events to derive first-occurrence metrics, use MIN on timestamp or sequence columns and group by all key dimensions to avoid later duplicates skewing time-based analyses | PRINCIPLE: Aggregation functions return extreme values; MIN yields the earliest event, MAX yields the latest. Using the wrong aggregation distorts subsequent duration calculations. | WHEN_TO_APPLY: Whenever grouping timestamped or ordered events before computing time differences | EXAMPLE_USAGE: Correct: SELECT session_id, page, MIN(event_time) AS first_event_time FROM events GROUP BY session_id, page; Incorrect (using MAX and then calculating next_event_time - event_time yields negative or zero values when events occur only once per page): SELECT session_id, page, MAX(event_time) AS first_event_time FROM events GROUP BY session_id, page;"
3,bq008,all,generic,window;filter,events,all,all,Yes,"ENSURE: apply filters on window-function outputs (LEAD, LAG) in an outer SELECT or wrapped subquery so the window calculations aren’t preemptively dropped by the WHERE clause | PRINCIPLE: The WHERE clause is applied after window functions are evaluated in the query lifecycle. Filtering on window results inside the same SELECT without nesting removes rows before window frames are computed. | WHEN_TO_APPLY: Whenever you compute comparisons or differences using LEAD, LAG, or other window functions and need to exclude certain results (e.g., self-transitions) | EXAMPLE_USAGE: Correct: WITH sequenced AS ( SELECT page, time, LEAD(page) OVER (PARTITION BY session_id ORDER BY time) AS next_page, LEAD(time) OVER (PARTITION BY session_id ORDER BY time) AS next_time FROM events SELECT * FROM sequenced WHERE next_page IS NOT NULL AND next_page <> page; Incorrect (trying to apply next_page <> page in the same SELECT that defines the window, which doesn’t filter correctly): SELECT page, time, LEAD(page) OVER (PARTITION BY session_id ORDER BY time) AS next_page, LEAD(time) OVER (PARTITION BY session_id ORDER BY time) AS next_time FROM events WHERE next_page <> page;"
4,bq008,all,generic,filter;where;date;wildcard,all,all,date;timestamp,all,"ENSURE: When filtering, selecting, or aggregating dates on databases with date-partitioned wildcard tables (e.g., events_*, ga_sessions_*, gsod*), use wildcard table selection with _TABLE_SUFFIX for date filtering instead of manually filtering on potentially unclean column data | PRINCIPLE: _TABLE_SUFFIX filtering is evaluated before query execution, making it more efficient and reliable than filtering on date columns which may have NULL, malformed, or inconsistent values; it also leverages BigQuery's table pruning for better performance | WHEN_TO_APPLY: When querying tables with naming patterns like table_YYYYMMDD, table_YYYY, or table_* where dates are encoded in table names | EXAMPLE_USAGE: Correct: FROM `dataset.events_*` WHERE _TABLE_SUFFIX BETWEEN '20201101' AND '20201130'; Less efficient/reliable: FROM `dataset.events_*` WHERE DATE(event_date) BETWEEN '2020-11-01' AND '2020-11-30'. Use _TABLE_SUFFIX to constrain the table scan first, then apply additional date filters on columns if needed."
5,bq008,ga360,question,NA,NA,NA,NA,NA,Grouping hits to the first occurrence of each page per session and filtering out transitions back to the same page corrected the maximum time calculation to 2848.473 seconds.
6,bq022,chicago,db,filter;where;between,filtered_trips,filtered_trips.trip_seconds,int,all,"ENSURE: Use trip_seconds BETWEEN 0 AND 3600 in the filtered_trips WHERE clause | CONTEXT: filtered_trips CTE filters taxi trips by duration using the trip_seconds column; previous logic using ROUND(trip_seconds/60.0) < 60 excluded trips at boundary and added complexity | WHEN_TO_CHECK: When filtering trips for durations up to one hour in filtered_trips CTE | EXAMPLE_USAGE: Correct: WITH filtered_trips AS ( SELECT trip_seconds, unique_key FROM trips WHERE trip_seconds BETWEEN 0 AND 3600 Incorrect: WITH filtered_trips AS ( SELECT trip_seconds, unique_key FROM trips WHERE trip_seconds > 0 AND ROUND(trip_seconds/60.0) < 60"
7,bq022,chicago,db,window;ntile;over;order by,trips_sextile,all,all,all,"ENSURE: NTILE(6) window function orders by trip_seconds and unique_key for deterministic sextile assignment | CONTEXT: trips_sextile CTE computes sextiles on filtered_trips; ordering by only duration_minutes leads to grouping imprecision and nondeterministic bins when durations tie | WHEN_TO_CHECK: When computing NTILE or other quantile-based window functions in trips_sextile CTE | EXAMPLE_USAGE: Correct: SELECT NTILE(6) OVER (ORDER BY trip_seconds, unique_key) AS sextile FROM filtered_trips; Incorrect: SELECT NTILE(6) OVER (ORDER BY duration_minutes) AS sextile FROM filtered_trips;"
8,bq022,all,generic,filter;where;between,all,all,numeric,all,VERIFY: Filtering numeric ranges should use raw column values with BETWEEN rather than rounded or derived values | PRINCIPLE: Direct range filters on raw numeric columns avoid boundary errors and unintended exclusions caused by rounding or casting functions | WHEN_TO_APPLY: Whenever filtering rows by numeric thresholds | EXAMPLE_USAGE: Incorrect: WHERE ROUND(duration_ms/1000.0) < 60 Correct:   WHERE duration_ms BETWEEN 0 AND 60000
9,bq022,all,generic,window;over;order by,all,all,all,all,"ENSURE: Include a unique tie-breaker column in window function ORDER BY clauses to guarantee deterministic results | PRINCIPLE: Window functions like NTILE, ROW_NUMBER, and RANK require fully deterministic ordering; identical sort keys must be disambiguated by a unique identifier to avoid inconsistent assignments | WHEN_TO_APPLY: Whenever using ORDER BY in window functions for ranking, quantiles, or pagination | EXAMPLE_USAGE: Incorrect: NTILE(4) OVER (ORDER BY score) Correct:   NTILE(4) OVER (ORDER BY score, player_id)"
10,bq022,all,generic,aggregation;window;quantile;transformation,all,all,numeric,all,"ENSURE: Perform all computations (aggregations, quantiles, window functions) on raw values, then apply unit conversions or transformations only in the final SELECT | PRINCIPLE: Computing aggregates or quantiles on transformed values (e.g., ROUND(seconds/60), CAST(value AS type)) can cause boundary errors, binning inconsistencies, and incorrect statistical results; raw values preserve precision and correct ordering | WHEN_TO_APPLY: When calculating MIN, MAX, AVG, NTILE, PERCENTILE, or any aggregate/window function that depends on numeric ordering or grouping | EXAMPLE_USAGE: Incorrect: WITH bins AS (SELECT NTILE(4) OVER (ORDER BY ROUND(seconds/60)) AS quartile FROM data) SELECT MIN(ROUND(seconds/60)) FROM bins GROUP BY quartile; Correct: WITH bins AS (SELECT NTILE(4) OVER (ORDER BY seconds) AS quartile, seconds FROM data) SELECT ROUND(MIN(seconds)/60) AS min_minutes FROM bins GROUP BY quartile; Exception: If the question explicitly asks to compute on transformed values (e.g., 'group by rounded minutes'), follow the question's intent."
11,bq022,chicago,question,NA,NA,NA,NA,NA,"The fix was to base quantile bins on raw trip_seconds (with unique_key tie‐breaker) and allow trips rounding to 0 minutes by simplifying the WHERE clause, aligning the sextile boundaries and aggregate values with the GOLD result."
12,bq039,new_york_plus,db,where;date;filter,valid_trips,valid_trips.pickup_datetime,date,all,"ENSURE: filter valid_trips rows using DATE(pickup_datetime) and DATE(dropoff_datetime) for date-based range selections | CONTEXT: valid_trips contains pickup_datetime and dropoff_datetime columns; filtering by DATE instead of TIMESTAMP ensures trips are correctly included by date, regardless of timestamp part | WHEN_TO_CHECK: When filtering trips for specific date ranges from valid_trips | EXAMPLE_USAGE: For selecting trips on a date range, use ""WHERE DATE(pickup_datetime) BETWEEN '2016-07-01' AND '2016-07-07'"" and avoid comparing full timestamps like ""WHERE pickup_datetime BETWEEN ..."", which can exclude intended rows."
13,bq039,new_york_plus,db,round;division;cast,valid_trips,valid_trips.driving_speed_miles_per_hour,numeric,all,"ENSURE: ROUND the calculation of driving_speed_miles_per_hour for reporting results | CONTEXT: valid_trips contains calculation for driving_speed_miles_per_hour; rounding aligns output with reporting requirements and GOLD matches | WHEN_TO_CHECK: When calculating and selecting driving_speed_miles_per_hour | EXAMPLE_USAGE: Use ""ROUND((miles / seconds) * 3600, 2)"" instead of just ""(miles / seconds) * 3600"" to ensure output values match expectations."
14,bq039,new_york_plus,db,case when;division;cast,valid_trips,valid_trips.tip_rate,numeric,Yes,"ENSURE: calculate tip_rate using CASE WHEN vt.total_amount = 0 THEN 0 ELSE ... to prevent division by zero or misleading rates | CONTEXT: valid_trips has total_amount and tip_amount; if total_amount is zero, tip_rate should be zero, not NULL or error | WHEN_TO_CHECK: When deriving tip_rate, especially when total_amount can be zero | EXAMPLE_USAGE: Use ""CASE WHEN vt.total_amount = 0 THEN 0 ELSE vt.tip_amount / vt.total_amount END"" rather than only ""vt.tip_amount / vt.total_amount""."
15,bq039,new_york_plus,db,inner join;join,valid_trips,all,all,all,"ENSURE: use INNER JOIN instead of LEFT JOIN for pickup_zone and dropoff_zone lookups to exclude rows missing zone data | CONTEXT: pickup_zone and dropoff_zone tables must be matched to valid_trips records for zone information; only trips with matching zones should be included | WHEN_TO_CHECK: When joining valid_trips with pickup_zone and dropoff_zone to get zone details | EXAMPLE_USAGE: Use ""INNER JOIN pickup_zone ... INNER JOIN dropoff_zone ..."" instead of ""LEFT JOIN ..."", so that trips missing zone information are not included in the final set."
16,bq039,all,generic,where;date;filter,all,all,date,all,"VERIFY: date-based filters use DATE() extraction from datetime columns for range selection | PRINCIPLE: Filtering on DATE(datetime_column) ensures all rows for a specific day are included regardless of time portion | WHEN_TO_APPLY: Whenever querying rows for date ranges using datetime columns | EXAMPLE_USAGE: Using ""WHERE DATE(start_time) BETWEEN 'YYYY-MM-DD' AND 'YYYY-MM-DD'"" includes all times on those dates; ""WHERE start_time BETWEEN ..."" with timestamps may miss some rows."
17,bq039,all,generic,round;division;cast,all,all,numeric,all,"ENSURE: numeric computed columns for reporting are rounded as needed to match specification or sample output | PRINCIPLE: Rounding computed metrics avoids mismatches due to floating point precision | WHEN_TO_APPLY: When selecting or calculating metrics for reporting or comparison | EXAMPLE_USAGE: ""SELECT ROUND(distance / duration, 2)"" produces results aligned with expectations, while leaving unrounded numbers introduces small variance."
18,bq039,all,generic,case when;division;cast;filter,all,all,numeric,Yes,"CHECK: derived metrics involving division by a field that could be zero should use CASE WHEN to set safe fallback values | PRINCIPLE: Prevents division by zero errors or misleading NA/NULL results in calculations | WHEN_TO_APPLY: When any division could have denominator of zero due to data | EXAMPLE_USAGE: ""CASE WHEN total = 0 THEN 0 ELSE part / total END"" ensures safe, meaningful output; ""part / total"" alone can raise errors or misinformation."
19,bq039,all,generic,inner join;join,all,all,all,all,"VERIFY: INNER JOIN should be used when you need to exclude records lacking related data in the joined table | PRINCIPLE: INNER JOIN ensures only records with matching entries in both tables appear in results; LEFT JOIN retains unmatched rows which may not be desired | WHEN_TO_APPLY: When you only want rows with fully matched reference data (e.g., zones, categories) | EXAMPLE_USAGE: ""SELECT ... FROM trips INNER JOIN zone ON ..."", returns only trips with valid zone mapping; ""LEFT JOIN"" would keep trips without zones, resulting in extra or incomplete rows."
20,bq039,all,generic,filter;where;date;timestamp;between,all,all,all,all,"ENSURE: When filtering datetime/timestamp columns at day granularity using BETWEEN, use clean date literals (YYYY-MM-DD) without adding time components like ""23:59:59"" to the end date | PRINCIPLE: BigQuery's BETWEEN is inclusive on both ends, and when comparing a timestamp column to a date literal, it automatically treats the date as the start of that day (00:00:00); adding ""23:59:59"" is unnecessary and can cause subtle bugs (e.g., missing records with timestamps after 23:59:59) | WHEN_TO_APPLY: When filtering on timestamp/datetime columns for date ranges at day granularity (e.g., ""all records from Jan 1 to Jan 7"") | EXAMPLE_USAGE: Correct: WHERE pickup_datetime BETWEEN '2016-01-01' AND '2016-01-07'; Incorrect: WHERE pickup_datetime BETWEEN '2016-01-01' AND '2016-01-07 23:59:59' (unnecessarily complex and could miss records). If you need inclusive end-of-day behavior, use DATE(column) for comparison or simply rely on BETWEEN with date literals."
21,bq039,new_york_plus,question,NA,NA,NA,NA,NA,"Using DATE() for datetime filters, rounding driving speed, handling zero total fare in tip_rate, and using INNER JOIN for zones were necessary to exactly match GOLD output rows and calculations."
22,bq059,san_francisco_plus,db,filter;subquery;cast;join,trips,all,int,all,"ENSURE: When restricting trips to those starting and ending in a specific region, filter by station_id via a region_id lookup instead of using station_name patterns | CONTEXT: trips table has numeric start_station_id and end_station_id, bikeshare_station_info has station_id (STRING) and region_id, and bikeshare_regions maps region_id to region names. Using station_name LIKE '%berkeley%' can miss stations or include non-Berkeley ones, whereas filtering by station_id via region_id ensures completeness. | WHEN_TO_CHECK: When querying trips for a geographic region (e.g., Berkeley) in the san_francisco_bikeshare dataset | EXAMPLE_USAGE: Incorrect: SELECT MAX(velocity) FROM trips JOIN `…bikeshare_station_info` si ON CAST(trips.start_station_id AS STRING)=si.station_id WHERE si.station_name LIKE '%berkeley%' AND …; Correct: SELECT MAX(velocity) FROM trips WHERE CAST(trips.start_station_id AS STRING) IN ( SELECT station_id FROM `…bikeshare_station_info` WHERE region_id = (SELECT region_id FROM `…bikeshare_regions` WHERE name='Berkeley') AND CAST(trips.end_station_id AS STRING) IN ( SELECT station_id FROM `…bikeshare_station_info` WHERE region_id = (SELECT region_id FROM `…bikeshare_regions` WHERE name='Berkeley') );"
23,bq059,san_francisco_plus,db,cast;filter;join,all,all,all,all,"VERIFY: CAST trips.start_station_id and trips.end_station_id to STRING before comparing to station_info.station_id | CONTEXT: trips.start_station_id and end_station_id are stored as INT64, while bikeshare_station_info.station_id is STRING, so comparisons or IN-subqueries fail unless types match. | WHEN_TO_CHECK: Whenever joining or filtering trips by station_id against bikeshare_station_info | EXAMPLE_USAGE: Incorrect: … WHERE trips.start_station_id IN (SELECT station_id FROM bikeshare_station_info …) Correct: … WHERE CAST(trips.start_station_id AS STRING) IN (SELECT station_id FROM bikeshare_station_info …)"
24,bq059,all,generic,all,all,all,all,all,"ENSURE: Always use BigQuery's ST_DISTANCE function to calculate distances between geographic points (including radian distances, great circle distances, etc.) rather than attempting manual calculations | PRINCIPLE: ST_DISTANCE is optimized for geographic calculations, handles edge cases correctly (dateline crossing, pole proximity), and provides accurate results in meters; manual haversine or other distance formulas are error-prone and may produce incorrect results | WHEN_TO_APPLY: Whenever calculating distance between two points with latitude/longitude coordinates or GEOGRAPHY/GEOMETRY types | EXAMPLE_USAGE: Use ST_DISTANCE(point1, point2) or ST_DISTANCE(ST_GEOGPOINT(lon1, lat1), ST_GEOGPOINT(lon2, lat2)) instead of manual haversine formulas. The function returns distance in meters by default. For filtering by distance threshold, use ST_DWITHIN for better performance."
25,bq059,all,generic,filter;subquery,all,all,all,all,"VERIFY: Prefer ID-based filters over text-pattern filters for categorical grouping | PRINCIPLE: Using explicit key or ID lookups ensures you capture all relevant records without relying on potentially inconsistent name patterns | WHEN_TO_APPLY: When filtering records by a category or region that is represented by an ID in a lookup table | EXAMPLE_USAGE: When selecting orders from the “Europe” region, avoid WHERE country_name LIKE '%Europe%'. Instead: Incorrect: SELECT * FROM orders WHERE country_name LIKE '%France%'; Correct: SELECT * FROM orders WHERE country_id IN (SELECT id FROM countries WHERE region='Europe');"
26,bq059,all,generic,cast;join,all,all,all,all,"ENSURE: Data types match in comparisons and joins, using explicit casting when necessary | PRINCIPLE: Implicit type conversion can lead to errors or inefficiencies; explicit casting makes intent clear and prevents mismatches | WHEN_TO_APPLY: Whenever comparing or joining columns of different SQL data types (e.g., INT vs STRING) | EXAMPLE_USAGE: Incorrect: SELECT * FROM sales s JOIN stores st ON s.store_id = st.store_id_string; Correct: SELECT * FROM sales s JOIN stores st ON CAST(s.store_id AS STRING) = st.store_id_string;"
27,bq059,san_francisco_plus,question,NA,NA,NA,NA,NA,"Replaced station_name LIKE '%berkeley%' filters with region-based station_id filters to include all Berkeley trips, yielding the correct max_velocity of 8.2."
28,bq059,san_francisco_plus,generic,join;cast,all,all,all,all,"ENSURE: When joining STRING and INT64 columns, use them directly without conversion; BigQuery handles implicit type coercion | PRINCIPLE: BigQuery automatically converts between STRING and INT64 during joins (e.g., STRING '25025' matches INT64 25025); manual conversion with LPAD or CAST is unnecessary and can cause mismatches for larger values | WHEN_TO_APPLY: When joining columns of different types (STRING vs INT64), use them directly in join condition; avoid LPAD, CAST, or other conversions unless explicitly required | EXAMPLE_USAGE: For joining STRING station_id with INT64 start_station_id, use 'station_id = start_station_id' directly; incorrect: using 'CAST(start_station_id AS STRING) = station_id' is unnecessary and adds complexity. BigQuery's implicit conversion handles this correctly."
29,bq061,census_bureau_acs_1,db,substring,census_data,census_data.tract_code,str,all,"ENSURE: extract the last six characters of tract_code using RIGHT(tract_code, 6) in the final SELECT | CONTEXT: The tract_code column stores full-length geographic identifiers but the expected output is a six-digit tract code, so selecting the raw column returns mismatched values | WHEN_TO_CHECK: When constructing the final SELECT clause that returns tract_code | EXAMPLE_USAGE: Incorrect: SELECT tract_code FROM census_data; – returns ‘140000US060372001’ Correct: SELECT RIGHT(tract_code, 6) AS tract_code FROM census_data; – returns ‘72001’"
30,bq061,all,generic,substring,all,all,str,all,"VERIFY: apply substring functions to conform stored strings to required output lengths | PRINCIPLE: When stored data includes prefixes or extra characters but reports demand fixed-length codes, using string functions ensures the output matches specification | WHEN_TO_APPLY: Whenever an output specification requires a specific segment or fixed length of a string column different from how it’s stored | EXAMPLE_USAGE: Scenario: A table has product_code 'SKU-00012345' but the dashboard needs just '00012345'. Incorrect: SELECT product_code FROM products; – returns 'SKU-00012345' Correct: SELECT RIGHT(product_code, 8) AS product_code FROM products; – returns '00012345'"
31,bq061,census_bureau_acs_1,question,NA,NA,NA,NA,NA,The fix extracts the last six digits of the full tract_code so the output matches the expected 6-digit tract code.
32,bq064,census_bureau_acs_1,db,all,bigquery-public-data.geo_census_tracts.us_census_tracts_national,tract_geom,numeric,all,"ENSURE: When computing the land‐area of census tracts, use ST_AREA on the tract_geom column rather than a stored area field | CONTEXT: The zip_tract_allocation CTE joins zip_codes with tracts and needs an accurate area measurement; tracts table provides a geometry column tract_geom | WHEN_TO_CHECK: Whenever selecting or aliasing area_land_meters in a query involving tract_geom | EXAMPLE_USAGE:"
33,bq064,census_bureau_acs_1,db,join;filter,bigquery-public-data.geo_us_boundaries.zip_codes,zip_code_centroid,all,all,"VERIFY: Use the zip_code_centroid column for point‐based spatial operations instead of internal_point_geom | CONTEXT: zip_codes table contains both internal_point_geom (an internal reference) and zip_code_centroid (the true geographic centroid) | WHEN_TO_CHECK: When performing spatial joins, distance calculations, or any centroid‐based logic on zip_codes | EXAMPLE_USAGE:"
34,bq064,all,generic,aggregation;division,all,all,all,all,"VERIFY: Weighted averages must be computed as SUM(value * weight) / SUM(weight), not as a plain AVG(value) | PRINCIPLE: A true weighted average multiplies each item’s value by its weight, sums those products, and divides by the total weight | WHEN_TO_APPLY: Whenever summarizing metrics where observations contribute unequally (e.g., income per population, score per count) | EXAMPLE_USAGE:"
35,bq064,all,generic,all,all,all,all,all,"ENSURE: Spatial measurements on geometry columns always invoke the appropriate spatial function (e.g., ST_AREA, ST_Length) rather than relying on stored attributes | PRINCIPLE: Geometry properties must be derived with spatial functions to guarantee consistency and accuracy | WHEN_TO_APPLY: When calculating area, perimeter, length, or other geometry‐based metrics in any spatial query | EXAMPLE_USAGE:"
36,bq064,census_bureau_acs_1,question,NA,NA,NA,NA,NA,"The original query already produced the correct spatial allocation and weighted-income results, so no edits were necessary."
37,bq066,sdoh,db,order by,statistics,statistics.data_year,date,all,"ENSURE: when ordering query results by data_year, include DESC in the ORDER BY clause | CONTEXT: The data_year column represents chronological years and the expected output requires the most recent years first | WHEN_TO_CHECK: When writing or reviewing ORDER BY clauses that involve the data_year column | EXAMPLE_USAGE: Incorrect: SELECT region, data_year, value FROM statistics ORDER BY data_year; Correct: SELECT region, data_year, value FROM statistics ORDER BY data_year DESC;"
38,bq066,sdoh,db,all,all,all,all,all,"AVOID: Beware, do not compute derived values (e.g. rates, percentages) unless the question specifically mentions those words. Interpret metrics ending in ""rate"" (e.g., poverty rate, unemployment rate) as ratios or percentages, whereas metrics without ""rate"" in the name should be treated as raw counts or absolute numbers | PRINCIPLE: SDOH datasets use ""rate"" suffix consistently to distinguish between percentage-based metrics and absolute counts; mixing these interpretations leads to incorrect analysis | WHEN_TO_APPLY: When selecting, filtering, or comparing socioeconomic metrics in SDOH-related queries | EXAMPLE_USAGE: Correct interpretation: ""poverty_rate"" = percentage of population in poverty (compare as 15.2 vs 12.8); ""poverty"" or ""people_in_poverty"" = absolute number of people (compare as 1,520 vs 1,280). When calculating changes or comparisons, ensure rate metrics are compared as percentages and count metrics as raw numbers."
39,bq066,all,generic,order by,all,all,all,all,"VERIFY: the ORDER BY clause explicitly specifies DESC when descending sort is required | PRINCIPLE: SQL defaults to ascending order if no direction is specified, which can lead to results that don’t match descending expectations | WHEN_TO_APPLY: Whenever query results must be in descending order of a column’s values | EXAMPLE_USAGE: Situation: You need the largest totals first. Incorrect: SELECT customer_id, total_sales FROM sales_summary ORDER BY total_sales; Correct: SELECT customer_id, total_sales FROM sales_summary ORDER BY total_sales DESC;"
40,bq066,all,generic,extract;date;week;year;ISO,all,all,all,all,"AVOID: Do not use ISOWEEK or ISOYEAR for date extraction unless explicitly requested in the question | PRINCIPLE: ISOWEEK and ISOYEAR follow ISO 8601 standards where weeks start on Monday and the first week must contain January 4th, which can cause week 1 to start in the previous December or week 53 to extend into the next January; this often produces unexpected results when the question simply asks for ""week"" or ""year"" without specifying ISO standards | WHEN_TO_APPLY: When extracting week or year components from dates; default to EXTRACT(WEEK FROM date) and EXTRACT(YEAR FROM date) unless the question explicitly mentions ""ISO week"" or ""ISO year"" | EXAMPLE_USAGE: Correct: EXTRACT(YEAR FROM start_date), EXTRACT(WEEK FROM event_date); Incorrect (unless specifically requested): EXTRACT(ISOYEAR FROM start_date), EXTRACT(ISOWEEK FROM event_date). ISO variants should only be used when the question specifically requires ISO 8601 compliance."
41,bq066,sdoh,question,NA,NA,NA,NA,NA,The only change needed was to reverse the sort order by adding DESC to the ORDER BY clause so the row order matches the expected output.
42,bq085,covid19_jhu_world_bank,db,filter;aggregation;sum;group by,indicators_data,indicators_data.value,numeric,all,"ENSURE: when calculating population metrics, use `bigquery-public-data.world_bank_wdi.indicators_data` filtered for `indicator_code = 'SP.POP.TOTL'` and do NOT multiply `value` by 1000 | CONTEXT: The `SP.POP.TOTL` indicator represents total population in raw numbers in `indicators_data`, so scaling is unnecessary and incorrect | WHEN_TO_CHECK: When aggregating or reporting population totals for countries from the World Bank indicators dataset | EXAMPLE_USAGE: For population counts: 'SELECT value FROM indicators_data WHERE indicator_code = 'SP.POP.TOTL'' is correct; 'SELECT value * 1000 FROM indicators_data WHERE indicator_code = 'SP.POP.TOTL'' would incorrectly inflate population figures."
43,bq085,covid19_jhu_world_bank,db,join;case;alias;filter,summary,summary.country_region,str,all,"VERIFY: country matching between `covid19_jhu_csse.summary` and World Bank population sources uses standardized names, using CASE statements or aliases for exceptions like 'US' and 'Iran' | CONTEXT: `summary.country_region` may use different naming conventions compared to population tables, causing mismatches for certain countries | WHEN_TO_CHECK: When joining COVID data (`summary.country_region`) with population data targeting specific countries | EXAMPLE_USAGE: Correct country mapping: 'CASE WHEN summary.country_region = ""US"" THEN ""United States"" WHEN summary.country_region = ""Iran"" THEN ""Iran, Islamic Rep."" ELSE summary.country_region END', ensuring both sources align; using raw country names without mapping may result in missing or incorrect data, e.g., 'US' != 'United States'."
44,bq085,all,generic,aggregation;cast;filter,all,all,all,all,"VERIFY: indicator source tables provide metrics in expected units; always check documentation before applying multipliers or scaling factors | PRINCIPLE: Different datasets may store values already in the correct unit (e.g., population counts not in thousands); blindly applying scaling can distort results | WHEN_TO_APPLY: When pulling quantitative measures (e.g., population, GDP) from indicator tables and preparing output | EXAMPLE_USAGE: Before applying 'value * 1000' for an indicator, confirm the unit: if documentation says value is raw count, use 'value' as-is; multiplying by 1000 would return inflated and incorrect results."
45,bq085,all,generic,join;case;alias,all,all,str,all,"ENSURE: country and region names are normalized between datasets using CASE statements or mapping tables whenever conventions differ | PRINCIPLE: Direct joins on disparate naming conventions (e.g., 'US' vs 'United States') will fail for edge cases unless handled | WHEN_TO_APPLY: When joining two tables where one or both contain country/region names that may not match exactly | EXAMPLE_USAGE: When joining on country name, use 'ON CASE WHEN x.country = ""US"" THEN ""United States"" ... ELSE x.country END = y.country_name' to ensure correct mapping; joining directly on 'US' = 'United States' will exclude actual US data from the result."
46,bq085,covid19_jhu_world_bank,question,NA,NA,NA,NA,NA,The core issue was an incorrect population source and unit scaling; switching to the correct World Bank total population indicator and raw counts (not thousands) resolved the discrepancy.
47,bq086,covid19_open_world_bank,db,all,covid,covid.country_code,str,all,"REMEMBER: Use covid.country_code for two-letter country codes instead of covid.iso_3166_1_alpha_3 | CONTEXT: The covid table contains both country_code (two-letter) and iso_3166_1_alpha_3 (three-letter) fields; reports expect two-letter codes | WHEN_TO_CHECK: When selecting country identifiers for output from the covid table | EXAMPLE_USAGE: Correct: SELECT covid.country_code AS country_code, ROUND(SAFE_DIVIDE(100.0 * covid.cumulative_confirmed, pop.year_2018),2) AS case_percent FROM covid JOIN pop ON covid.country_code = pop.country_code; This returns codes like “US”, “FR”. Incorrect: SELECT covid.iso_3166_1_alpha_3 AS country_code, … This returns “USA”, “FRA” and mismatches expected two-letter codes."
48,bq086,covid19_open_world_bank,db,round;division;percent,all,all,numeric,all,"ENSURE: Wrap percentage calculations in ROUND(...,2) to enforce two decimal places | CONTEXT: case_percent is derived via SAFE_DIVIDE(100.0 * covid.cumulative_confirmed, pop.year_2018) and must be formatted to two decimals for presentation consistency | WHEN_TO_CHECK: When computing case_percent from cumulative_confirmed and population | EXAMPLE_USAGE: Correct: SELECT ROUND(SAFE_DIVIDE(100.0 * covid.cumulative_confirmed, pop.year_2018),2) AS case_percent … Returns values like 12.34, 0.75. Incorrect: SELECT SAFE_DIVIDE(100.0 * covid.cumulative_confirmed, pop.year_2018) AS case_percent … Returns unrounded values like 12.345678, 0.752341."
49,bq086,covid19_open_world_bank,db,order by;desc,all,case_percent,numeric,all,"VERIFY: Order results by the case_percent alias in descending order instead of by country_code | CONTEXT: The final output must rank countries by their computed case_percent, not alphabetically by code | WHEN_TO_CHECK: When applying ORDER BY to the country-level percentage results | EXAMPLE_USAGE: Correct: SELECT covid.country_code, ROUND(SAFE_DIVIDE(100.0 * covid.cumulative_confirmed, pop.year_2018),2) AS case_percent FROM covid JOIN pop … ORDER BY case_percent DESC; This lists highest percentages first. Incorrect: … ORDER BY country_code; This sorts alphabetically (“AD”, “AE”, “AF”), not by percentage ranking."
50,bq086,all,generic,all,all,all,all,all,"VERIFY: SELECT clauses must reference the specific source column that matches the required output representation | PRINCIPLE: Aliasing the wrong column can produce data in an unintended format (e.g., three-letter codes instead of two-letter) | WHEN_TO_APPLY: Whenever a table contains multiple representations of the same concept (like different code lengths) and one is required for reports | EXAMPLE_USAGE: Given a table codes(code_short, code_long): Correct: SELECT code_short AS code FROM codes; Incorrect: SELECT code_long AS code FROM codes; The former yields the expected short codes, the latter the wrong format."
51,bq086,all,generic,round;division;percent,all,all,numeric,all,"ENSURE: Numeric calculations for ratios or percentages are wrapped in ROUND to enforce a fixed decimal precision | PRINCIPLE: Floating-point results can have variable decimal lengths; rounding ensures consistent, readable output | WHEN_TO_APPLY: Whenever computing derived metrics (percentages, ratios) for display or comparison | EXAMPLE_USAGE: Correct: SELECT ROUND(sales / total_sales * 100,2) AS pct FROM sales_summary; Returns 23.45. Incorrect: SELECT sales / total_sales * 100 AS pct FROM sales_summary; Returns 23.456789 with too many decimals."
52,bq086,all,generic,order by,all,all,all,all,"CHECK: ORDER BY should reference the alias of a computed column when sorting by a derived metric | PRINCIPLE: Sorting needs to target the exact expression or its alias; using unrelated columns will misorder results | WHEN_TO_APPLY: When ordering by values that are calculated in the SELECT list | EXAMPLE_USAGE: After computing total_revenue as price * quantity: Correct: SELECT price * quantity AS total_revenue FROM sales ORDER BY total_revenue DESC; Incorrect: ORDER BY price; The correct sort ranks by revenue, not by individual price."
53,bq086,all,generic,aggregation;window;sum;average;computation,all,all,all,all,"CHECK: If a question mentions ""cumulative"" while performing sums, averages, or computing differences, pay careful attention to the scope and ordering of the computations | PRINCIPLE: Cumulative calculations require proper ordering (usually by date/time) and running totals via window functions (SUM OVER, AVG OVER) rather than simple GROUP BY aggregations; the term ""cumulative"" signals that each row should include all prior values | WHEN_TO_APPLY: When the question explicitly mentions cumulative totals, cumulative sums, cumulative averages, running totals, or ""by [date]"" with accumulation over time | EXAMPLE_USAGE: Incorrect: SELECT country, SUM(cases) FROM data GROUP BY country; Correct for cumulative: SELECT country, date, SUM(cases) OVER (PARTITION BY country ORDER BY date) AS cumulative_cases FROM data. The window function ensures each row contains the sum of all cases up to that date."
54,bq086,covid19_open_world_bank,question,NA,NA,NA,NA,NA,"The original query used three‐letter ISO codes, left percentages unrounded, and ordered by country code; switching to two‐letter codes, rounding percentages to two decimals, and ordering by descending case_percent resolves all discrepancies."
55,bq096,gbif,db,cte_definition;filter;aggregation;group by;having,tenplus,all,all,all,"ENSURE: Use a CTE to filter Sterna paradisaea observations north of latitude 40, in months after January, where sightings exceed 10 per day | CONTEXT: The tenplus CTE aggregates observations by year and eventdate and applies filters on species, latitude, and day-of-year, critical for selecting qualifying records | WHEN_TO_CHECK: When determining the earliest year with notable Sterna paradisaea presence based on filtered and aggregated sighting records | EXAMPLE_USAGE: Construct a CTE such as 'WITH tenplus AS (SELECT year, eventdate FROM sightings WHERE species = 'Sterna paradisaea' AND latitude > 40 AND EXTRACT(MONTH FROM eventdate) > 1 GROUP BY year, eventdate HAVING COUNT(*) > 10)' — omitting the CTE or failing to apply HAVING COUNT(*) > 10 would admit incorrect events."
56,bq096,gbif,db,where;order by;limit;min;filter,tenplus,year,int,all,"ENSURE: When filtering for years, apply the correct year restriction in the WHERE clause to match recent observations | CONTEXT: Limiting results to years greater than 2020 ensures relevance and consistency with current data trends | WHEN_TO_CHECK: When the logic requires selecting modern or post-2020 event years for analysis | EXAMPLE_USAGE: In a query such as 'SELECT year FROM tenplus WHERE year > 2020 ORDER BY MIN(dayofyear) LIMIT 1', verify the WHERE clause restricts years appropriately; neglecting this may produce outdated results."
57,bq096,all,generic,aggregation;group by;having,all,all,all,all,"VERIFY: Use aggregation and HAVING clauses for event frequency filters | PRINCIPLE: When filtering based on counts (such as sightings per day or event), aggregate records and apply HAVING to restrict qualifying groups | WHEN_TO_APPLY: Any time a query needs to filter groups (by date, user, region, etc.) according to count thresholds | EXAMPLE_USAGE: 'SELECT group_col FROM table GROUP BY group_col HAVING COUNT(*) > N' — omitting the HAVING clause or filtering pre-aggregation with WHERE on counts will not achieve the correct result."
58,bq096,all,generic,cte_definition;filter,all,all,all,all,"ENSURE: When deriving summary statistics across filtered records, use CTEs or subqueries to encapsulate filtering before aggregation | PRINCIPLE: Segregating filtering and aggregation logic improves readability and avoids mixing event-level and global aggregations | WHEN_TO_APPLY: When the query involves multiple filtering steps prior to summary or limiting operations | EXAMPLE_USAGE: 'WITH filtered_events AS (...) SELECT agg_func() FROM filtered_events'; not using a CTE or subquery may require duplicating filter logic or compromise clarity."
59,bq096,all,generic,order by;limit;aggregation;min,all,all,all,all,"CHECK: Use ORDER BY with LIMIT to select extremal values after aggregation | PRINCIPLE: To find minimum/maximum values (e.g., earliest date, highest count), aggregate and then use ORDER BY + LIMIT on the summary column | WHEN_TO_APPLY: Whenever a single extremal group (e.g., the first year, latest event) is desired after aggregation | EXAMPLE_USAGE: After aggregating, 'SELECT year FROM grouped_events ORDER BY MIN(eventdate) LIMIT 1'; omitting ORDER BY or LIMIT may yield nondeterministic results."
60,bq096,gbif,question,NA,NA,NA,NA,NA,"The ISSUE was using a static text response; FIX was replacing it with CTE filtering Sterna paradisaea observations after January, north of 40°, requiring >10 daily sightings, and restricting to years >2020 to match the GOLD year."
61,bq103,gnomAD,db,aggregation;unnest,region_variants,region_variants.region_id,int,all,"ENSURE: When aggregating variant counts in the counts_summary CTE, use COUNT(1) AS num_variants and SUM((SELECT alt.AC FROM UNNEST(alternate_bases) AS alt)) AS sum_AC | CONTEXT: counts_summary aggregates metrics directly from region_variants’s region_id and alternate_bases columns to compute total variants and allele counts | WHEN_TO_CHECK: When defining or validating the counts_summary CTE | EXAMPLE_USAGE:"
62,bq103,gnomAD,db,all,region_length,region_length.region_length,int,all,VERIFY: region_length CTE must calculate 55064852 - 55039447 (without +1) to match expected region span | CONTEXT: region_length defines region_length from fixed start_position and end_position values in a simple subtraction CTE | WHEN_TO_CHECK: When computing region_length in the region_length CTE | EXAMPLE_USAGE:
63,bq103,gnomAD,db,division;round,all,burden_of_mutation,numeric,all,"ENSURE: In final SELECT, wrap SAFE_DIVIDE(region_length.region_length, cs.num_variants) in ROUND(..., 3) to produce burden_of_mutation with three decimal places | CONTEXT: The final query calculates burden_of_mutation as a density metric requiring fixed precision | WHEN_TO_CHECK: When deriving ratio or density columns in the final SELECT | EXAMPLE_USAGE:"
64,bq103,gnomAD,db,aggregation;order by,all,genes,str,all,"ENSURE: Use STRING_AGG(gene_symbol, ', ' ORDER BY gene_symbol) for the genes column to produce a sorted, comma-separated string | CONTEXT: The final SELECT combines multiple gene_symbol values into one string field | WHEN_TO_CHECK: When concatenating gene_symbol values into a single output column | EXAMPLE_USAGE:"
65,bq103,all,generic,aggregation;unnest,all,all,all,all,"VERIFY: Include explicit UNNEST clauses when aggregating over array or repeated fields | PRINCIPLE: Aggregation functions cannot directly operate on arrays—UNNEST must expand elements first | WHEN_TO_APPLY: Whenever summing, counting, or averaging values stored in array or repeated columns | EXAMPLE_USAGE:"
66,bq103,all,generic,all,all,all,all,all,"ENSURE: Check off-by-one logic in range or length calculations—decide clearly whether endpoints are inclusive or exclusive | PRINCIPLE: Misplacing +1 leads to incorrect spans or counts | WHEN_TO_APPLY: When computing lengths, durations, or distances from start and end values | EXAMPLE_USAGE:"
67,bq103,all,generic,division;round,all,all,numeric,all,VERIFY: Wrap division operations in a rounding function when output demands fixed decimal precision | PRINCIPLE: Unrounded division yields floats with unpredictable decimal lengths | WHEN_TO_APPLY: When presenting numeric ratios or densities in reports or output tables | EXAMPLE_USAGE:
68,bq103,all,generic,aggregation;order by,all,all,str,all,"CHECK: Use string aggregation functions with explicit delimiters and ORDER BY clauses for consistent, reproducible lists | PRINCIPLE: Specifying ORDER and delimiter ensures predictable output and formatting | WHEN_TO_APPLY: When concatenating multiple text values into a single string field | EXAMPLE_USAGE:"
69,bq103,gnomAD,question,NA,NA,NA,NA,NA,"Fixed variant count and allele count aggregation by sourcing counts_summary from region_variants, corrected region_length to match GOLD’s formula, applied rounding to density, and formatted gene list as a comma-separated string."
70,bq112,bls,db,aggregation;avg;group by,bigquery-public-data.bls.cpi_u,bigquery-public-data.bls.cpi_u.value,numeric,all,"ENSURE: Annual CPI in the cpi_1998_2017 CTE is calculated using AVG(value) with GROUP BY year rather than selecting a single period | CONTEXT: bigquery-public-data.bls.cpi_u stores monthly CPI values (columns: year, period, value, area_code); using period='M13' returns a synthetic national index and omits area-specific monthly data | WHEN_TO_CHECK: When defining or reviewing the cpi_1998_2017 CTE for annual CPI metrics of a specific area | EXAMPLE_USAGE:"
71,bq112,bls,db,filter;subquery,bigquery-public-data.bls.cpi_u,bigquery-public-data.bls.cpi_u.area_code,int,all,ENSURE: Filter for Pittsburgh’s CPI series uses a subquery on area_name to select area_code instead of hard-coding '0' | CONTEXT: area_code='0' corresponds to the national CPI; Pittsburgh has its own area_code in cpi_u and must be looked up to avoid using the wrong series | WHEN_TO_CHECK: When filtering the CPI CTE or any query for Pittsburgh-specific data | EXAMPLE_USAGE:
72,bq112,all,generic,aggregation;avg;sum;count;group by,all,all,all,all,"VERIFY: Aggregate functions must be accompanied by a matching GROUP BY clause when summarizing by key fields | PRINCIPLE: Using AVG, SUM, COUNT etc. without grouping columns causes unintended results or reliance on a single row’s value instead of full-group aggregation | WHEN_TO_APPLY: Whenever you compute summary metrics across partitions (e.g., monthly→annual, item-level→order-level totals) | EXAMPLE_USAGE:"
73,bq112,all,generic,filter;subquery,all,all,all,all,"ENSURE: Avoid hard-coding identifier values; derive them via subqueries using descriptive fields | PRINCIPLE: Hard-coded IDs (area codes, category IDs, status codes) are brittle and may change; dynamic lookups based on human-readable names maintain query robustness | WHEN_TO_APPLY: Whenever filtering by coded identifiers that have an associated descriptive column | EXAMPLE_USAGE:"
74,bq112,bls,question,NA,NA,NA,NA,NA,"The CPI calculation was corrected from using the national M13 index to averaging all monthly CPI values for Pittsburgh, changing both the aggregation (AVG(value) with GROUP BY year) and the area_code filter to select the Pittsburgh series, which yields the matching 57.07% CPI growth."
75,bq112,bls,generic,aggregation;group by;time;granularity,all,all,date;timestamp,all,"CHECK: Verify the temporal granularity of source data before applying time-based GROUP BY operations; avoid unnecessary aggregation if data is already at the target granularity | PRINCIPLE: Tables with temporal aggregations in their schema (e.g., weekly_*, monthly_*, annual_*, or columns like 'week', 'month', 'year', 'avg_wkly_', 'monthly_total') already contain pre-aggregated data at that time unit; further grouping by the same unit is redundant and may produce incorrect results | WHEN_TO_APPLY: Before writing GROUP BY with temporal units (WEEK, MONTH, YEAR), examine table names and column names for temporal indicators (daily_, weekly_, monthly_, yearly_, annual_); check if columns already represent aggregated values (avg_wkly_, monthly_total, annual_sum) | EXAMPLE_USAGE: Incorrect: SELECT AVG(avg_wkly_wage) FROM weekly_wages GROUP BY week - the data is already weekly averages; Correct: SELECT avg_wkly_wage FROM weekly_wages WHERE week = '2023-01'. Similarly, if a table is named 'monthly_sales' or has 'monthly_revenue' column, don't GROUP BY month."
76,bq185,new_york_plus,db,filter,bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2016,all,date,all,ENSURE: the target_week_trips CTE filters both pickup_datetime and dropoff_datetime within the same date bounds using BETWEEN | CONTEXT: target_week_trips CTE selects from trips table and must exclude trips that start or end outside the specified week to avoid skewed aggregates | WHEN_TO_CHECK: when defining the date window for weekly trip subsets | EXAMPLE_USAGE: Correct: WITH target_week_trips AS ( SELECT * FROM trips WHERE pickup_datetime BETWEEN '2016-02-01' AND '2016-02-07' AND dropoff_datetime BETWEEN '2016-02-01' AND '2016-02-07' Incorrect: WHERE pickup_datetime >= '2016-02-01' AND pickup_datetime < '2016-02-08'  -- missing dropoff filter
77,bq185,new_york_plus,db,division,bigquery-public-data.new_york_taxi_trips.tlc_yellow_trips_2016,all,numeric,all,"ENSURE: duration_minutes in trips_with_duration CTE uses seconds‐based diff divided by 60.0 to capture fractional minutes | CONTEXT: trips_with_duration CTE calculates ride durations and fractional minutes are needed for accurate average calculations | WHEN_TO_CHECK: when computing duration between dropoff_datetime and pickup_datetime | EXAMPLE_USAGE: Correct: SELECT TIMESTAMP_DIFF(dropoff_datetime, pickup_datetime, SECOND) / 60.0 AS duration_minutes FROM target_week_trips Incorrect: SELECT TIMESTAMP_DIFF(dropoff_datetime, pickup_datetime, MINUTE) AS duration_minutes  -- truncates fractions"
78,bq185,all,generic,filter,all,all,date,all,"ENSURE: filters on both start and end timestamps when selecting a date‐bounded subset | PRINCIPLE: Omitting the end‐time filter allows records that start inside but end outside the window, distorting aggregates | WHEN_TO_APPLY: any query that defines a record’s inclusion by a start‐and‐end timestamp range | EXAMPLE_USAGE: Correct pattern: WHERE start_ts BETWEEN @start_date AND @end_date AND end_ts BETWEEN @start_date AND @end_date Incorrect pattern: WHERE start_ts >= @start_date AND start_ts < DATE_ADD(@end_date, INTERVAL 1 DAY)  -- no end_ts condition"
79,bq185,all,generic,division,all,all,numeric,all,"ENSURE: selecting the appropriate unit and precision for timestamp differences to avoid unintended truncation | PRINCIPLE: Using higher‐unit diffs (e.g., MINUTE) drops fractional parts; computing in smaller units (e.g., SECOND) and scaling preserves precision | WHEN_TO_APPLY: when calculating durations where partial units matter for accuracy | EXAMPLE_USAGE: Correct pattern: SELECT TIMESTAMP_DIFF(end_ts, start_ts, SECOND) / 60.0 AS duration Incorrect pattern: SELECT TIMESTAMP_DIFF(end_ts, start_ts, MINUTE) AS duration  -- loses seconds fraction"
80,bq185,new_york_plus,question,NA,NA,NA,NA,NA,"The query originally truncated durations to whole minutes and only filtered by pickup_datetime; switching to seconds/60.0 for fractional minutes and adding a dropoff_datetime BETWEEN filter aligned the date range and fractional calculation, producing the correct average."
81,bq198,ncaa_basketball,db,filter;where;null_handling,filtered_seasons,filtered_seasons.wins,int,Yes,"ENSURE: when defining the filtered_seasons CTE, only apply “WHERE wins IS NOT NULL” and do not filter on fs.market or fs.name | CONTEXT: filtered_seasons contains season, market, name, wins; filtering on market or name here can prematurely exclude seasons with valid wins data | WHEN_TO_CHECK: When constructing the filtered_seasons CTE to capture all seasons with a wins value | EXAMPLE_USAGE: Incorrect: WITH filtered_seasons AS ( SELECT season, market, name, wins FROM seasons WHERE wins IS NOT NULL AND market IS NOT NULL AND market <> '' AND name IS NOT NULL Correct: WITH filtered_seasons AS ( SELECT season, market, name, wins FROM seasons WHERE wins IS NOT NULL ;"
82,bq198,ncaa_basketball,db,filter;where;concat;null_handling,season_leaders,season_leaders.team_name,str,Yes,"ENSURE: in the season_leaders CTE, select fs.market AS team_name and include “WHERE fs.market IS NOT NULL AND fs.market <> ''” instead of concatenating market and name | CONTEXT: season_leaders should present a clean team_name based solely on market; concatenation with name and missing market filtering led to mismatches with the gold output | WHEN_TO_CHECK: When building the season_leaders CTE for team performance | EXAMPLE_USAGE: Incorrect: SELECT season, CONCAT(fs.market, ' ', fs.name) AS team_name, wins FROM filtered_seasons fs; Correct: SELECT season, fs.market AS team_name, wins FROM filtered_seasons fs WHERE fs.market IS NOT NULL AND fs.market <> '';"
83,bq198,ncaa_basketball,db,aggregation;count distinct;group by,team_season_counts,team_season_counts.season,int,all,"ENSURE: in the team_season_counts CTE, use COUNT(DISTINCT season) instead of COUNT(*) to calculate the number of unique seasons per team_name | CONTEXT: team_season_counts aggregates season_leaders by team_name; counting all rows overcounts when a team appears multiple times in a season | WHEN_TO_CHECK: When aggregating season counts per team in team_season_counts | EXAMPLE_USAGE: Incorrect: SELECT team_name, COUNT(*) AS season_count FROM season_leaders GROUP BY team_name; Correct: SELECT team_name, COUNT(DISTINCT season) AS season_count FROM season_leaders GROUP BY team_name;"
84,bq198,all,generic,filter;where;null_handling,all,all,str,Yes,"VERIFY: exclude missing string values by applying both IS NOT NULL and <> '' filters | PRINCIPLE: NULL is distinct from empty string; to fully remove blank text entries you must filter out both | WHEN_TO_APPLY: Whenever filtering on text/varchar columns to drop missing or blank records | EXAMPLE_USAGE: Incorrect: SELECT user_id, username FROM users WHERE username IS NOT NULL; (returns rows where username = '') Correct: SELECT user_id, username FROM users WHERE username IS NOT NULL AND username <> '';"
85,bq198,all,generic,aggregation;count distinct,all,all,all,all,"ENSURE: use COUNT(DISTINCT column) when you need the number of unique values instead of COUNT(*) | PRINCIPLE: COUNT(*) counts all rows—including duplicates—whereas COUNT(DISTINCT x) counts only unique occurrences of x | WHEN_TO_APPLY: When the goal is to compute distinct-item counts rather than total record counts | EXAMPLE_USAGE: Incorrect: SELECT country, COUNT(*) AS num_countries FROM visits GROUP BY country; (This counts every visit row) Correct: SELECT country, COUNT(DISTINCT visitor_id) AS unique_visitors FROM visits GROUP BY country;"
86,bq198,all,generic,concat,all,all,all,all,"CHECK: avoid concatenating multiple fields for identifiers when a single field suffices and simplifies filtering | PRINCIPLE: Unnecessary concatenation can introduce blanks, complicate WHERE clauses, and cause mismatches; prefer using the single most appropriate column | WHEN_TO_APPLY: When forming labels or identifiers in SELECT clauses for reporting | EXAMPLE_USAGE: Incorrect: SELECT CONCAT(region, ' ', subregion) AS region_label, sales FROM sales_data; Correct: SELECT region AS region_label, sales FROM sales_data;"
87,bq198,ncaa_basketball,question,NA,NA,NA,NA,NA,"The core issue was concatenating nicknames and filtering out blanks too early; switching to only `market` as `team_name`, moving the market filter into season_leaders, and counting distinct seasons aligned the output with GOLD."
88,bq203,new_york_plus,db,aggregation;group by,stations,stations.station_name,str,all,"ENSURE: station_ada_entry CTE selects and groups by station_name instead of station_id | CONTEXT: The station_ada_entry CTE joins entrances_2017 to stations to count ADA entrances per station. Using station_id groups raw IDs which can misalign with display names and inflate counts when multiple IDs map to a single name | WHEN_TO_CHECK: When defining or reviewing the station_ada_entry CTE’s SELECT and GROUP BY clauses | EXAMPLE_USAGE: Correct: WITH station_ada_entry AS ( SELECT s.station_name, COUNT(*) AS ada_entrances FROM entrances_2017 e JOIN stations s ON e.station_id = s.station_id GROUP BY s.station_name Incorrect: WITH station_ada_entry AS ( SELECT e.station_id, COUNT(*) AS ada_entrances FROM entrances_2017 e JOIN stations s ON e.station_id = s.station_id GROUP BY e.station_id ;"
89,bq203,new_york_plus,db,join;left join,all,all,all,Yes,"ENSURE: station_ada_entry CTE uses an inner JOIN (JOIN) not a LEFT JOIN between entrances_2017 and stations | CONTEXT: A LEFT JOIN includes stations with zero ADA entrances as NULLs, inflating the borough-level station count when aggregated further | WHEN_TO_CHECK: When joining entrances_2017 to stations in station_ada_entry CTE | EXAMPLE_USAGE: Correct: FROM entrances_2017 e JOIN stations s ON e.station_id = s.station_id Incorrect: FROM entrances_2017 e LEFT JOIN stations s ON e.station_id = s.station_id"
90,bq203,new_york_plus,db,aggregation;group by;count distinct,stations,stations.station_name,str,all,"ENSURE: per_borough CTE counts distinct station_name rather than station_id | CONTEXT: At the borough level, station_name uniquely identifies each station for summary counts. Counting station_id can double-count if the same name appears under multiple IDs or if IDs appear multiple times | WHEN_TO_CHECK: When computing COUNT(DISTINCT…) in per_borough CTE | EXAMPLE_USAGE: Correct: SELECT s.borough, COUNT(DISTINCT s.station_name) AS ada_station_count FROM station_ada_entry sae JOIN stations s ON sae.station_name = s.station_name GROUP BY s.borough Incorrect: SELECT s.borough, COUNT(DISTINCT sae.station_id) AS ada_station_count FROM station_ada_entry sae JOIN stations s ON sae.station_id = s.station_id GROUP BY s.borough"
91,bq203,all,generic,join;inner join;left join,all,all,all,all,"VERIFY: Use INNER JOIN when you intend to exclude unmatched rows rather than include them with NULLs | PRINCIPLE: INNER JOIN returns only rows with matches in both tables; LEFT JOIN returns all rows from the left table and NULLs for non-matches, which can inflate or distort aggregates if unmatched rows are not intended | WHEN_TO_APPLY: Anytime filtering or counting only records that have related entries in a joined table | EXAMPLE_USAGE: Correct: SELECT u.user_id, COUNT(o.order_id) FROM users u JOIN orders o ON u.user_id = o.user_id GROUP BY u.user_id; Incorrect: SELECT u.user_id, COUNT(o.order_id) FROM users u LEFT JOIN orders o ON u.user_id = o.user_id GROUP BY u.user_id;  -- includes users with zero orders if not filtered out"
92,bq203,all,generic,group by,all,all,all,all,"VERIFY: GROUP BY and SELECT must reference the same display-level column to avoid splitting or misaligning aggregates | PRINCIPLE: The columns listed in SELECT and GROUP BY define the aggregation buckets; mixing an internal key in GROUP BY with a display name in SELECT can lead to SQL errors or unintended grouping | WHEN_TO_APPLY: Whenever you aggregate data and want to display human-readable columns instead of surrogate keys | EXAMPLE_USAGE: Correct: SELECT department_name, SUM(salary) FROM employees GROUP BY department_name; Incorrect: SELECT department_name, SUM(salary) FROM employees GROUP BY department_id;  -- groups by ID but displays name, may error or misaggregate"
93,bq203,all,generic,aggregation;count distinct,all,all,all,all,"VERIFY: COUNT(DISTINCT field) should target the true unique identifier of the entity being counted, not an event or transaction key | PRINCIPLE: COUNT(DISTINCT) counts unique values of the specified column; using an event-level key counts events, not entities, which misrepresents distinct entity counts | WHEN_TO_APPLY: When counting unique entities (e.g., users, products, stations) in aggregated results involving multiple rows per entity | EXAMPLE_USAGE: Correct: SELECT region, COUNT(DISTINCT product_id) FROM sales GROUP BY region; Incorrect: SELECT region, COUNT(DISTINCT sale_id) FROM sales GROUP BY region;  -- counts individual sales instead of unique products sold"
94,bq203,new_york_plus,question,NA,NA,NA,NA,NA,"The query originally counted all station_ids (including those with no entrances) via a LEFT JOIN, inflating totals. Switching to an inner JOIN on station_name and aggregating by station_name aligns with the GOLD logic, producing correct per-borough station counts and percentages."
95,bq234,all,db,aggregation,bigquery-public-data.cms_medicare.part_d_prescriber_2014,bigquery-public-data.cms_medicare.part_d_prescriber_2014.generic_name,str,all,"ENSURE: in the state_med_counts CTE, select generic_name AS drug_name and GROUP BY generic_name instead of drug_name | CONTEXT: state_med_counts CTE aggregates total_claim_count by drug; grouping by the brand-level drug_name can split counts across brand variants, while generic_name consolidates all variants correctly | WHEN_TO_CHECK: When defining the state_med_counts CTE for per-state prescription aggregation | EXAMPLE_USAGE: - Incorrect: WITH state_med_counts AS ( SELECT state, drug_name, SUM(total_claim_count) AS total_claims FROM prescriptions GROUP BY state, drug_name … - Correct: WITH state_med_counts AS ( SELECT state, generic_name AS drug_name, SUM(total_claim_count) AS total_claim_count FROM prescriptions GROUP BY state, generic_name …"
96,bq234,all,db,aggregation;join,state_med_counts,state_med_counts.total_claim_count,int,all,"ENSURE: alias SUM(total_claim_count) AS total_claim_count in state_med_counts CTE to match downstream joins | CONTEXT: max_per_state CTE and final join reference total_claim_count; misnaming the alias causes join failures or NULL results | WHEN_TO_CHECK: When aggregating total_claim_count in state_med_counts for use by subsequent CTEs or joins | EXAMPLE_USAGE: - Incorrect: SELECT state, generic_name AS drug_name, SUM(total_claim_count) AS total_claims … JOIN max_per_state USING (state, total_claim_count)  -- fails because total_claim_count doesn’t exist - Correct: SELECT state, generic_name AS drug_name, SUM(total_claim_count) AS total_claim_count … JOIN max_per_state USING (state, total_claim_count)"
97,bq234,all,db,join,all,all,all,all,"ENSURE: join max_per_state to state_med_counts on both state and total_claim_count to correctly identify each state’s top drug | CONTEXT: max_per_state CTE returns state and MAX(total_claim_count) (aliased e.g. max_total_claim_count); joining on state alone can match multiple drugs or incorrect counts | WHEN_TO_CHECK: When performing the final SELECT to pull each state’s most prescribed medication | EXAMPLE_USAGE: - Incorrect: SELECT s.state, s.drug_name FROM state_med_counts s JOIN max_per_state m ON s.state = m.state; - May return multiple rows per state if counts tie - Correct: SELECT s.state, s.drug_name FROM state_med_counts s JOIN max_per_state m ON s.state = m.state AND s.total_claim_count = m.max_total_claim_count;"
98,bq234,all,generic,aggregation;cte_definition,all,all,all,all,"VERIFY: aggregated CTE column aliases must match all downstream references | PRINCIPLE: When chaining CTEs or subqueries, using inconsistent aliases for derived columns leads to join failures or unexpected NULLs | WHEN_TO_APPLY: Whenever you define a CTE or subquery with an aggregate or expression and then reference that column later | EXAMPLE_USAGE: - Incorrect: WITH sums AS (SELECT id, SUM(amount) AS total_amt FROM sales GROUP BY id) SELECT s.id, s.total_amount  -- total_amount doesn’t exist FROM sums s; - Correct: WITH sums AS (SELECT id, SUM(amount) AS total_amt FROM sales GROUP BY id) SELECT s.id, s.total_amt FROM sums s;"
99,bq234,all,generic,aggregation;join,all,all,all,all,"ENSURE: use MAX() plus a join to pick the highest-value record per group instead of defaulting to window functions when only one top record is needed | PRINCIPLE: A two-CTE pattern (aggregate by group, then select max and join back) is often clearer and more performant for retrieving the single largest value per category | WHEN_TO_APPLY: When you need only the record(s) with the maximum aggregated metric per group | EXAMPLE_USAGE: - Window function approach (valid but more complex): WITH totals AS ( SELECT category, item, SUM(score) AS total_score FROM data GROUP BY category, item , ranked AS ( SELECT *, ROW_NUMBER() OVER (PARTITION BY category ORDER BY total_score DESC) AS rn FROM totals SELECT category, item FROM ranked WHERE rn = 1; - Aggregate + join approach (clearer for single top record): WITH totals AS ( SELECT category, item, SUM(score) AS total_score FROM data GROUP BY category, item , max_totals AS ( SELECT category, MAX(total_score) AS max_score FROM totals GROUP BY category SELECT t.category, t.item FROM totals t JOIN max_totals m ON t.category = m.category AND t.total_score = m.max_score;"
100,bq234,all,generic,all,all,all,unspecified,all,"CHECK: GROUP BY clauses must reference the actual columns used in SELECT, not their aliases | PRINCIPLE: Many SQL dialects require grouping on original column names, so aliasing in SELECT does not carry into GROUP BY | WHEN_TO_APPLY: Whenever you use GROUP BY alongside SELECT column aliases | EXAMPLE_USAGE:, - Incorrect:, SELECT user_id AS uid, COUNT(*) AS cnt, FROM events, GROUP BY uid;  -- uid not recognized in GROUP BY in most dialects, - Correct:, SELECT user_id AS uid, COUNT(*) AS cnt, FROM events, GROUP BY user_id;"
101,bq234,cms_data,question,NA,NA,NA,NA,NA,"The query was using the wrong field (drug_name) and row-number ranking, so switching to generic_name with a MAX aggregation CTE and join corrected the counts to match the GOLD output."
102,bq234,cms_data,db,column;select,all,all,all,all,"ENSURE: Use column names that are directly referenced in queries or schema, do not substitute with synonyms | PRINCIPLE: If a query requirement directly references a column name (e.g., 'drug_name') or the schema shows a specific column (e.g., 'generic_name'), use that exact column; do not change it to a synonym even if semantically similar, as direct references are safer and more accurate | WHEN_TO_APPLY: When a column is explicitly named in requirements or visible in schema, use that exact column name; avoid mapping to semantically similar columns unless explicitly required | EXAMPLE_USAGE: If requirement says 'for each drug_name in NY' and table has drug_name column, use 'drug_name' directly; do not substitute with 'generic_name' even if they seem equivalent. Conversely, if schema has 'generic_name' but not 'drug_name', use 'generic_name' directly (you can alias as drug_name for output). In cms_medicare data: the table has 'generic_name' column, so use 'generic_name' in WHERE/GROUP BY, not a different name - direct schema references are safest."
103,bq234,cms_data,generic,all,all,all,all,all,"ENSURE: Do not map or normalize state codes/categorical values unless explicitly required; trust the data as-is | PRINCIPLE: Attempting to map raw state codes to standard abbreviations with partial CASE statements only maps some values and misses others, causing incorrect results; if data needs normalization, it should be complete or not done at all | WHEN_TO_APPLY: When querying state codes, region codes, or similar categorical data, use values directly from the table; only apply mapping/normalization if requirement explicitly asks for it AND you can map ALL possible values completely | EXAMPLE_USAGE: For state column in prescriber data, use 'nppes_provider_state AS state' directly is correct; incorrect: using 'CASE WHEN state = ''TX'' THEN ''TX'' WHEN state = ''CA'' THEN ''CA'' ... ELSE NULL END' which only maps partial values and misses others. Similarly for region, country, or category codes - use the raw column unless explicit mapping is required."
104,bq268,ga360,db,null_handling,ftm,ftm.first_mobile_txn_date,date,Yes,"ENSURE: when determining last_event_date in the user_last_event CTE, choose ftm.first_mobile_txn_date whenever both lvm.last_mobile_visit_date and ftm.first_mobile_txn_date are non‐NULL instead of using GREATEST() | CONTEXT: user_last_event CTE pulls lvm.last_mobile_visit_date and ftm.first_mobile_txn_date to compute a single last_event_date, and using GREATEST() here overstates the “last” event by always picking the chronologically later date regardless of business intent | WHEN_TO_CHECK: whenever writing or reviewing the CASE expression in user_last_event CTE | EXAMPLE_USAGE: Correct: CASE WHEN lvm.last_mobile_visit_date IS NOT NULL AND ftm.first_mobile_txn_date IS NOT NULL THEN ftm.first_mobile_txn_date … END Incorrect: CASE WHEN lvm.last_mobile_visit_date IS NOT NULL AND ftm.first_mobile_txn_date IS NOT NULL THEN GREATEST(lvm.last_mobile_visit_date, ftm.first_mobile_txn_date) … END"
105,bq268,all,generic,null_handling,all,all,all,all,"VERIFY: CASE logic must reflect business priority when choosing among multiple date columns, not just use date‐max functions | PRINCIPLE: Blindly applying GREATEST() or MAX() can violate business rules if one event type should be preferred over another even when it’s earlier | WHEN_TO_APPLY: whenever selecting a “last” or “primary” date from two or more event‐date columns | EXAMPLE_USAGE: When you have abstract columns A_date and B_date and business dictates B_date represents the true last event: Correct: CASE WHEN A_date IS NOT NULL AND B_date IS NOT NULL THEN B_date … END Incorrect: GREATEST(A_date, B_date)"
106,bq268,all,generic,null_handling,all,all,all,Yes,"CHECK: Explicit NULL checks in CASE branches should precede any fallback to built‐in functions | PRINCIPLE: CASE branches are evaluated in order; missing an IS NOT NULL check before a function can lead to unintended branches executing | WHEN_TO_APPLY: in any derived column logic that mixes null checks with functions like GREATEST(), COALESCE(), or MAX() | EXAMPLE_USAGE: When deriving combined_date from X_date and Y_date: Correct: CASE WHEN X_date IS NOT NULL AND Y_date IS NOT NULL THEN Y_date WHEN X_date IS NOT NULL THEN X_date WHEN Y_date IS NOT NULL THEN Y_date END Incorrect: CASE WHEN X_date IS NOT NULL AND Y_date IS NOT NULL THEN GREATEST(X_date, Y_date) ELSE COALESCE(X_date, Y_date) END"
107,bq268,ga360,question,NA,NA,NA,NA,NA,"The logic for selecting the last_event_date was simplified to always choose the first mobile transaction date when both a mobile visit and a mobile transaction exist, correcting the overestimation and producing the correct maximum day gap."
108,bq290,noaa_data,db,filter,valid_readings,valid_readings.temp,numeric,all,ENSURE: filter invalid readings in valid_readings by using g.temp != 9999.9 instead of g.max or g.min | CONTEXT: valid_readings table alias g stores temperature readings with sentinel value 9999.9 in the temp column | WHEN_TO_CHECK: When building the WHERE clause to exclude sentinel or invalid temperature readings | EXAMPLE_USAGE: Correct: … FROM valid_readings g WHERE g.temp != 9999.9 … Incorrect: … FROM valid_readings g WHERE g.max != 9999.9 AND g.min != 9999.9
109,bq290,noaa_data,db,aggregation,country_daily,country_daily.temp,numeric,all,"ENSURE: aggregate temperatures in country_daily CTE with MAX(temp) and MIN(temp), not MAX(max) or MIN(min) | CONTEXT: country_daily CTE computes daily temperature extremes per country and must reference the actual temp column, not flagged max/min columns | WHEN_TO_CHECK: When defining the SELECT list for calculating daily max_temp and min_temp in country_daily | EXAMPLE_USAGE: Correct: country_daily AS ( SELECT date, country, MAX(temp) AS max_temp, MIN(temp) AS min_temp FROM valid_readings … Incorrect: country_daily AS ( SELECT date, country, MAX(max) AS max_temp, MIN(min) AS min_temp FROM valid_readings …"
110,bq290,noaa_data,db,filter;where,all,all,all,all,"ENSURE: Filter out invalid weather stations by excluding records where USAF code equals '999999' when performing analysis over station data | PRINCIPLE: USAF code '999999' represents invalid or placeholder station identifiers in NOAA datasets and should be excluded to ensure data quality and accurate analysis | WHEN_TO_APPLY: When querying weather station data, especially when aggregating statistics, counting stations, or analyzing station-level metrics | EXAMPLE_USAGE: Incorrect: SELECT COUNT(*) FROM stations; Correct: SELECT COUNT(*) FROM stations WHERE usaf != '999999'; Also applies to station identifiers in related tables like GSOD where station filtering is needed."
111,bq290,all,generic,filter,all,all,all,all,"ENSURE: sentinel-value filters should be applied directly on the measurement column, not on derived or flag columns | PRINCIPLE: Direct filtering on raw data columns prevents logical errors and simplifies query conditions | WHEN_TO_APPLY: When cleaning data containing sentinel or placeholder values prior to aggregation or joins | EXAMPLE_USAGE: Correct: WHERE measurement != 999 Incorrect: WHERE measurement_min != 999 AND measurement_max != 999"
112,bq290,all,generic,filter;aggregation,all,all,all,all,"VERIFY: aggregation functions must target the same column used in sentinel-value filters | PRINCIPLE: Excluding invalid data only works if the filter predicate and the aggregate function reference the same measurement column | WHEN_TO_APPLY: Whenever you filter out sentinel or invalid values before performing MAX, MIN, AVG, etc. | EXAMPLE_USAGE: Correct: SELECT MAX(value) FROM readings WHERE value != -1; Incorrect: SELECT MAX(value) FROM readings WHERE status_flag != -1;"
113,bq290,noaa_data,question,NA,NA,NA,NA,NA,The original query aggregated on the wrong columns (`max`/`min`) and filtered their flags; switching to aggregate and filter on `temp` aligned results with the GOLD SQL.
114,bq290,noaa_data,generic,aggregation;avg;divide;safe_divide,all,all,numeric,all,"ENSURE: Use simple aggregation functions (AVG, SUM) unless query explicitly requires weighted calculations; avoid SAFE_DIVIDE for weighted averages when AVG works | PRINCIPLE: When aggregating values like temperature, trip_duration, or income, AVG(column) is sufficient unless requirement explicitly asks for population-weighted average; using SAFE_DIVIDE(SUM(column * weight), SUM(weight)) unnecessarily complicates the query when AVG produces correct results | WHEN_TO_APPLY: Use AVG, SUM, COUNT for standard aggregations; only use SAFE_DIVIDE with weighted calculations if requirement explicitly specifies weighted average, population-weighted, or similar complex aggregation | EXAMPLE_USAGE: For aggregating temperature by region, 'AVG(temp) AS avg_temp' is correct; using 'SAFE_DIVIDE(SUM(temp * station_count), SUM(station_count))' is incorrect unless weighted average is explicitly required. Similarly for trip duration: use AVG(duration) unless question asks for distance-weighted or passenger-weighted average."
115,bq302,stackoverflow,db,filter,monthly_python,monthly_python.python_questions,int,Yes,"ENSURE: include “WHERE p.python_questions IS NOT NULL” when filtering by python_questions | CONTEXT: the query uses table alias p with column python_questions; months that have no python questions appear as NULL and must be excluded to match the expected row count | WHEN_TO_CHECK: whenever selecting month-level python question counts from table alias p | EXAMPLE_USAGE: Correct: ```sql SELECT REPLACE(m.month_index, '-', '') AS month_index, p.python_questions FROM month_table m JOIN python_stats p ON m.month_index = p.month_index WHERE p.python_questions IS NOT NULL; ``` Incorrect (returns extra NULL rows): ```sql SELECT REPLACE(m.month_index, '-', '') AS month_index, p.python_questions FROM month_table m JOIN python_stats p ON m.month_index = p.month_index; ```"
116,bq302,stackoverflow,db,string parsing,months_2022,months_2022.month_index,str,all,"VERIFY: apply `REPLACE(m.month_index, '-', '') AS month_index` to normalize month_index to ‘YYYYMM’ | CONTEXT: column m.month_index stores values like ‘2022-01’ but the expected output requires ‘202201’ format | WHEN_TO_CHECK: when selecting or displaying the month_index column for reporting or joins | EXAMPLE_USAGE: Correct: ```sql SELECT REPLACE(m.month_index, '-', '') AS month_index FROM month_table m; ``` Incorrect (retains hyphen, mismatches expected format): ```sql SELECT m.month_index AS month_index FROM month_table m; ```"
117,bq302,all,generic,filter,all,all,all,Yes,"VERIFY: filter out NULL metric values before aggregation or display | PRINCIPLE: including NULLs for a key metric can introduce unintended rows or miscount totals; explicit `WHERE metric IS NOT NULL` ensures only meaningful data is processed | WHEN_TO_APPLY: whenever querying a column that represents a count, measurement, or key indicator and NULL indicates absence of data | EXAMPLE_USAGE: Correct: ```sql SELECT category, measurement FROM data_table WHERE measurement IS NOT NULL; ``` Incorrect: ```sql SELECT category, measurement FROM data_table; ```"
118,bq302,all,generic,string parsing,all,all,str,all,"ENSURE: standardize string-based keys by removing delimiters with string functions | PRINCIPLE: formatting characters (e.g., hyphens, slashes) in string keys can prevent correct sorting, filtering, or matching; using functions like `REPLACE` yields a consistent format | WHEN_TO_APPLY: when outputting or comparing date-like or code-like string columns that include separators | EXAMPLE_USAGE: Correct: ```sql SELECT REPLACE(code, '-', '') AS clean_code FROM codes_table; ``` Incorrect: ```sql SELECT code AS clean_code FROM codes_table; ```"
119,bq302,stackoverflow,question,NA,NA,NA,NA,NA,"Filtered out months lacking python questions with `WHERE p.python_questions IS NOT NULL` and reformatted month_index by removing hyphens (`REPLACE(m.month_index, '-', '')`) to produce ‘YYYYMM’, aligning row count and format with the GOLD result."
120,bq327,world_bank,db,all,bigquery-public-data.world_bank_intl_debt.international_debt,all,all,all,REMEMBER: use `bigquery-public-data.world_bank_intl_debt.international_debt` as the source for country debt indicators | CONTEXT: Queries on international debt must reference this dedicated table rather than health or other population tables | WHEN_TO_CHECK: When specifying the FROM clause for debt-related queries | EXAMPLE_USAGE: Correct:
121,bq327,world_bank,db,filter,international_debt,international_debt.country_code,str,all,"ENSURE: filter `country_code` with the three-letter ISO code in `international_debt` (e.g., 'RUS') | CONTEXT: The international_debt table stores country codes in ISO alpha-3 format; using a two-letter code returns zero rows | WHEN_TO_CHECK: When writing WHERE clauses on country_code in this table | EXAMPLE_USAGE: Correct:"
122,bq327,world_bank,db,filter,international_debt,all,str,all,"VERIFY: do not apply debt-specific LIKE filters on `indicator_name` or `indicator_code` in `international_debt` | CONTEXT: The international_debt dataset exclusively contains debt indicators, so filtering on LIKE '%debt%' is redundant and excludes valid rows | WHEN_TO_CHECK: When constructing WHERE clauses against this table | EXAMPLE_USAGE: Correct:"
123,bq327,all,generic,all,all,all,all,all,"VERIFY: the selected table must align with the data domain of the query | PRINCIPLE: Using the correct source table ensures data context matches query intent and avoids missing or irrelevant rows | WHEN_TO_APPLY: Whenever writing the FROM clause for a thematic query (e.g., sales, inventory, health) | EXAMPLE_USAGE: Correct:"
124,bq327,all,generic,filter,all,all,all,all,"ENSURE: filter values match the column’s code format (e.g., two-letter vs three-letter codes) | PRINCIPLE: Mismatched code formats yield no results or incomplete datasets because the filter doesn’t match stored values | WHEN_TO_APPLY: When applying WHERE filters on code columns such as country_code, product_code, etc. | EXAMPLE_USAGE: Correct:"
125,bq327,all,generic,filter,all,all,all,all,"CHECK: avoid redundant filters that replicate the table’s inherent scope | PRINCIPLE: Applying filters redundant with the table’s focus can unnecessarily shrink result sets and indicate schema misunderstandings | WHEN_TO_APPLY: When filtering fields already implied by the table’s domain (e.g., genre filters on a genre-specific table) | EXAMPLE_USAGE: Correct:"
126,bq327,world_bank,question,NA,NA,NA,NA,NA,"Switched to the international_debt table, corrected country_code to 'RUS', and dropped the redundant debt filter to obtain the correct count of 12."
127,bq354,cms_data,db,order by,conditions,conditions.skin_condition,str,all,"ENSURE: when ordering c.skin_condition in result sets, replace simple ORDER BY c.skin_condition with a CASE expression mapping each condition to its required display order | CONTEXT: the conditions table (aliased as c) contains a skin_condition column whose display order must follow a clinical priority (Vitiligo→Psoriasis→Acne→Atopic dermatitis) rather than alphabetical order | WHEN_TO_CHECK: any query using “ORDER BY c.skin_condition” | EXAMPLE_USAGE: Incorrect: SELECT c.skin_condition FROM conditions c ORDER BY c.skin_condition; Correct: SELECT c.skin_condition FROM conditions c ORDER BY CASE c.skin_condition WHEN 'Vitiligo' THEN 1 WHEN 'Psoriasis' THEN 2 WHEN 'Acne' THEN 3 WHEN 'Atopic dermatitis' THEN 4 END;"
128,bq354,all,generic,order by,all,all,all,all,"ENSURE: custom categorical ordering must use a CASE expression in the ORDER BY clause instead of default lexical sorting | PRINCIPLE: to enforce a non-alphabetical sequence for discrete category values, assign each category a numeric rank via CASE in the ORDER BY | WHEN_TO_APPLY: whenever a query requires categories to appear in a specific order that does not match their natural sort order | EXAMPLE_USAGE: Incorrect: SELECT priority_level FROM tasks ORDER BY priority_level; Correct: SELECT priority_level FROM tasks ORDER BY CASE priority_level WHEN 'High' THEN 1 WHEN 'Medium' THEN 2 WHEN 'Low' THEN 3 END;"
129,bq354,cms_data,question,NA,NA,NA,NA,NA,Adjusted the ORDER BY clause to a CASE expression to produce the required non-alphabetical ordering of skin_condition.
130,bq360,nppes,db,union;trim,bigquery-public-data.nppes.npi_optimized,healthcare_provider_taxonomy_1_specialization,str,all,"ENSURE: In the mv_providers CTE, only select TRIM(healthcare_provider_taxonomy_1_specialization) as specialization and remove all UNION ALL references to taxonomy_2 through taxonomy_15 | CONTEXT: The business requirement counts each provider once by their primary specialization field (healthcare_provider_taxonomy_1_specialization); unpivoting all 15 taxonomy slots duplicates providers and inflates counts | WHEN_TO_CHECK: When defining or reviewing the mv_providers CTE against bigquery-public-data.nppes.npi_optimized | EXAMPLE_USAGE:"
131,bq360,nppes,db,filter;where;trim;null_handling,bigquery-public-data.nppes.npi_optimized,healthcare_provider_taxonomy_1_specialization,str,Yes,ENSURE: Add filters “healthcare_provider_taxonomy_1_specialization IS NOT NULL” and “TRIM(healthcare_provider_taxonomy_1_specialization) <> ''” in the WHERE clause of mv_providers | CONTEXT: Excluding NULL or empty string specialization values prevents grouping on blank categories and matches the GOLD logic | WHEN_TO_CHECK: When filtering specializations in the mv_providers CTE | EXAMPLE_USAGE:
132,bq360,all,generic,union;unpivot,all,all,all,all,VERIFY: Unpivot or UNION ALL should include only the columns required by business logic | PRINCIPLE: Unnecessary unpivot across multiple similarly named columns duplicates rows and skews aggregate results when only a subset of columns is relevant | WHEN_TO_APPLY: Whenever using UNION ALL or UNPIVOT to combine multiple columns into one output column | EXAMPLE_USAGE:
133,bq360,all,generic,filter;where;group by;count;trim,all,all,all,Yes,ENSURE: Filter out NULL or empty strings before grouping or counting on text fields | PRINCIPLE: Blank or whitespace-only strings represent missing data and can create phantom categories in GROUP BY or COUNT | WHEN_TO_APPLY: Whenever aggregating or grouping by text-based columns across any table | EXAMPLE_USAGE:
134,bq360,nppes,question,NA,NA,NA,NA,NA,"The original query unpivoted all 15 taxonomy fields, but the GOLD logic counts only the primary specialization (`healthcare_provider_taxonomy_1_specialization`); simplifying to use taxonomy_1 and filtering out null/empty values fixed the result."
135,bq366,the_met,db,aggregation,objects,objects.object_id,int,all,ENSURE: Use COUNT(*) AS c in the period_label_counts CTE instead of COUNT(DISTINCT o.object_id) | CONTEXT: period_label_counts aggregates object counts by period and label using o.object_id and assigns alias c; applying DISTINCT on object_id undercounts when each row is already unique per period and label | WHEN_TO_CHECK: When defining the period_label_counts CTE for grouping by o.period and l.description | EXAMPLE_USAGE:
136,bq366,the_met,db,filter,all,period_label_counts.c,numeric,all,ENSURE: Filter aggregated label counts with c >= 500 in the outer WHERE clause to include only labels meeting the minimum count threshold | CONTEXT: The final SELECT pulls from the period_label_counts CTE (aliasing the aggregated count as c) and must exclude low‐volume labels | WHEN_TO_CHECK: When selecting top labels per period and applying a minimum‐count filter | EXAMPLE_USAGE:
137,bq366,the_met,db,filter,period_label_counts,period_label_counts.period,str,Yes,ENSURE: Exclude NULL period values in the final result using AND period IS NOT NULL | CONTEXT: The period column in period_label_counts may contain NULLs that should not appear in the top‐three label rankings | WHEN_TO_CHECK: When finalizing results from period_label_counts and applying ranking or other filters on period | EXAMPLE_USAGE:
138,bq366,all,generic,aggregation,all,all,all,all,"VERIFY: Use COUNT(*) when you need the total number of rows per group and reserve COUNT(DISTINCT col) only for deduplicating a specific column | PRINCIPLE: COUNT(*) counts all rows in each group, while COUNT(DISTINCT col) counts unique values of that column, which can undercount if rows are already unique | WHEN_TO_APPLY: Whenever grouping rows to compute the total size of each group | EXAMPLE_USAGE:"
139,bq366,all,generic,filter;aggregation,all,all,all,all,"ENSURE: Apply filters on aggregated results using HAVING or in an outer query rather than in the pre‐aggregation WHERE clause | PRINCIPLE: WHERE filters individual rows before aggregation and cannot reference aggregate aliases; HAVING or an outer SELECT is required to filter by aggregated values | WHEN_TO_APPLY: When enforcing minimum or maximum thresholds on aggregates like SUM, COUNT, or AVG | EXAMPLE_USAGE:"
140,bq366,all,generic,filter;window,all,all,all,Yes,"CHECK: Exclude NULL grouping keys before ranking or ordering to prevent unpredictable inclusion of NULL values in top-N results | PRINCIPLE: NULLs can appear first or last in sort order and may skew ranking functions like ROW_NUMBER or RANK | WHEN_TO_APPLY: Whenever performing ROW_NUMBER(), RANK(), DENSE_RANK(), or ORDER BY on a column that may contain NULLs | EXAMPLE_USAGE:"
141,bq366,the_met,question,NA,NA,NA,NA,NA,Fixed aggregation to COUNT(*) and applied missing filters (`c >= 500` and non-null period) to produce the correct top-three-per-period counts.
142,bq374,ga360,db,filter;coalesce;null_handling;cte_definition,totals,totals.newVisits,int,Yes,"ENSURE: first_visits CTE includes “AND COALESCE(totals.newVisits, 0) = 1” to capture only new users | CONTEXT: The first_visits CTE selects users from the totals table where newVisits may be NULL or greater than one; without this filter, users with zero or multiple visits slip into the cohort and undercount true first‐time visitors | WHEN_TO_CHECK: When defining or validating the first_visits CTE (or any cohort based on totals.newVisits) | EXAMPLE_USAGE: Incorrect: WITH first_visits AS ( SELECT user_id FROM totals WHERE event_date BETWEEN start_date AND end_date Correct: WITH first_visits AS ( SELECT user_id FROM totals WHERE event_date BETWEEN start_date AND end_date AND COALESCE(totals.newVisits, 0) = 1"
143,bq374,all,generic,filter;coalesce;null_handling,all,all,all,Yes,"VERIFY: filters on nullable or aggregated metric columns should wrap the column in COALESCE before comparison to avoid unintended exclusions | PRINCIPLE: A direct comparison like “WHERE metric = value” will fail for NULLs, excluding rows that should be treated as zero or default and causing undercounts | WHEN_TO_APPLY: Whenever filtering on a count, sum, or other derived metric that can be NULL after aggregation or a left join | EXAMPLE_USAGE: Incorrect: … WHERE visit_count = 1 Correct: … WHERE COALESCE(visit_count, 0) = 1"
144,bq374,all,generic,filter;aggregation;group by;having;cte_definition,all,all,all,all,"ENSURE: criteria defining a cohort or segment are applied within the CTE or subquery that builds the set, not only in the outer query | PRINCIPLE: Deferring filters until after aggregation or final selection can allow extraneous rows into the intermediate result, skewing counts or rates | WHEN_TO_APPLY: When constructing cohorts, segments, or any multi‐step aggregation using CTEs or subqueries | EXAMPLE_USAGE: Incorrect: WITH events AS ( SELECT user_id, COUNT(*) AS event_count FROM user_events GROUP BY user_id SELECT user_id FROM events WHERE event_count = 1 Correct: WITH events AS ( SELECT user_id FROM user_events GROUP BY user_id HAVING COUNT(*) = 1 SELECT user_id FROM events"
145,bq374,ga360,question,NA,NA,NA,NA,NA,The query was undercounting new users by omitting `totals.newVisits = 1`; adding that filter in the first_visits CTE corrected the cohort and raised the result to the expected level.
146,bq397,ecommerce,db,distinct,data-to-insights.ecommerce.rev_transactions,all,all,all,"ENSURE: deduped_txns CTE uses SELECT DISTINCT * instead of selecting only specific columns to avoid undercounting transactions | CONTEXT: deduped_txns pulls data from the source table including channelGrouping, geoNetwork_country, totals_transactions, and other session attributes; limiting DISTINCT to a subset of columns dropped unique rows | WHEN_TO_CHECK: When defining the deduped_txns CTE for transaction deduplication | EXAMPLE_USAGE: Incorrect: WITH deduped_txns AS ( SELECT DISTINCT channelGrouping, geoNetwork_country, totals_transactions FROM source_table Correct: WITH deduped_txns AS ( SELECT DISTINCT * FROM source_table"
147,bq397,ecommerce,db,order by,deduped_txns,deduped_txns.channelGrouping,str,all,"ENSURE: final ORDER BY for channelGrouping uses a CASE expression to enforce the required campaign channel sequence instead of default alphabetical sorting | CONTEXT: The final SELECT returns channelGrouping and totals_transactions and must list channels in the order Social, Paid Search, Display, Direct, Referral, Organic Search | WHEN_TO_CHECK: When ordering the final result set by channelGrouping | EXAMPLE_USAGE: Incorrect: SELECT channelGrouping, totals_transactions FROM deduped_txns ORDER BY channelGrouping - yields: Direct, Display, Organic Search, Paid Search, Referral, Social Correct: SELECT channelGrouping, totals_transactions FROM deduped_txns ORDER BY CASE channelGrouping WHEN 'Social' THEN 1 WHEN 'Paid Search' THEN 2 WHEN 'Display' THEN 3 WHEN 'Direct' THEN 4 WHEN 'Referral' THEN 5 WHEN 'Organic Search' THEN 6 END"
148,bq397,all,generic,distinct,all,all,all,all,"VERIFY: DISTINCT clauses include all columns that define a record’s uniqueness | PRINCIPLE: SELECT DISTINCT only regards the columns you list; omitting relevant columns can cause valid unique rows to be collapsed or true duplicates to remain | WHEN_TO_APPLY: Whenever using SELECT DISTINCT for deduplication or counting unique records | EXAMPLE_USAGE: Situation: You need unique user sessions defined by (user_id, session_id, date). Incorrect: SELECT DISTINCT user_id, session_id FROM sessions; - drops uniqueness on date, merging sessions across days Correct: SELECT DISTINCT user_id, session_id, date FROM sessions;"
149,bq397,all,generic,order by,all,all,all,all,"ENSURE: custom ordering requirements that deviate from default sort order are implemented via CASE expressions or lookup tables in ORDER BY | PRINCIPLE: ORDER BY on a column follows natural sort (alphabetical/numeric); to impose a business-specific sequence, you must map values to sort keys | WHEN_TO_APPLY: Whenever the desired output order of categorical values is not alphabetical or numeric | EXAMPLE_USAGE: Task: Sort priority levels as High, Medium, Low. Incorrect: ORDER BY priority; - yields: High, Low, Medium Correct: ORDER BY CASE priority WHEN 'High' THEN 1 WHEN 'Medium' THEN 2 WHEN 'Low' THEN 3 END"
150,bq397,ecommerce,question,NA,NA,NA,NA,NA,The original deduplication on only three columns undercounted transactions—switching to `SELECT DISTINCT *` restored correct totals—and replacing the simple `ORDER BY channelGrouping` with a `CASE`-based ordering aligned the row order to match the GOLD output.
151,bq402,ecommerce,db,aggregation;avg;subquery,data-to-insights.ecommerce.web_analytics,web_analytics.transactions,int,Yes,"ENSURE: when calculating avg_transactions_per_purchaser, use a direct AVG on web_analytics.transactions via a scalar subquery rather than averaging the pre-aggregated purchasers.total_transactions | CONTEXT: web_analytics table contains session-level transactions; the purchasers CTE sums transactions per visitor into total_transactions, and averaging that CTE yields a different metric | WHEN_TO_CHECK: any time you compute avg_transactions_per_purchaser or similar session-level averages in ecommerce.web_analytics | EXAMPLE_USAGE: Incorrect: ``` WITH purchasers AS ( SELECT visitor_id, SUM(transactions) AS total_transactions FROM `data-to-insights.ecommerce.web_analytics` GROUP BY visitor_id SELECT AVG(p.total_transactions) AS avg_transactions_per_purchaser FROM purchasers p; ``` Correct: ``` SELECT ( SELECT AVG(w.transactions) FROM `data-to-insights.ecommerce.web_analytics` w WHERE w.transactions IS NOT NULL AS avg_transactions_per_purchaser; ```"
152,bq402,all,generic,aggregation;avg;group by,all,all,all,all,"VERIFY: that average calculations reflect the intended aggregation level and are not applied on already grouped or summed results | PRINCIPLE: AVG over raw data points differs from AVG over aggregated sums, so averaging intermediate aggregates can misrepresent the true mean | WHEN_TO_APPLY: whenever you compute an average after grouping or summing in a prior step | EXAMPLE_USAGE: Given a raw table A with column value and an aggregated CTE agg_data as: ``` WITH agg_data AS ( SELECT key, SUM(value) AS total_value FROM A GROUP BY key ``` Wrong average of raw values: ``` SELECT AVG(ad.total_value) FROM agg_data ad; ``` Correct average of raw values: ``` SELECT AVG(value) FROM A; ```"
153,bq402,ecommerce,question,NA,NA,NA,NA,NA,"The purchaser‐level average was originally calculated on summed totals per visitor; switching to the direct session‐level AVG(totals.transactions) produced the expected 1.039, aligning with the GOLD result."
154,bq430,all,generic,cast;type conversion,all,all,all,all,"ENSURE: Use SAFE_CAST instead of CAST when dealing with uncertain or potentially invalid data types to avoid query failures | PRINCIPLE: CAST throws an error when conversion fails (e.g., non-numeric strings to INT64), causing the entire query to fail, whereas SAFE_CAST returns NULL for invalid conversions, allowing the query to continue processing valid rows | WHEN_TO_APPLY: When casting columns that may contain mixed or invalid data types, especially user input, text fields that should be numeric, or data from external sources | EXAMPLE_USAGE: Incorrect: CAST(page_number AS INT64) - fails if page_number contains ""N/A"" or other non-numeric values; Correct: SAFE_CAST(page_number AS INT64) - returns NULL for invalid values, allowing aggregations and ordering to proceed with valid data."
155,ga002,ga4,db,cte_definition,bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*,all,all,all,"ENSURE: Use the full events_* wildcard instead of events_2020* in all CTEs querying the GA4 ecommerce tables | CONTEXT: The tee_buyers and other_purchases CTEs originally referenced `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_2020*`, which excluded January 2021 data | WHEN_TO_CHECK: Whenever writing a FROM clause against `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` tables | EXAMPLE_USAGE: Incorrect: SELECT user_pseudo_id FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_2020*` … Correct: SELECT user_pseudo_id FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` …"
156,ga002,all,generic,where,all,all,all,all,VERIFY: Wildcard table patterns must cover the entire intended date range | PRINCIPLE: Using a narrow wildcard like `table_2020*` can omit tables with suffixes outside 2020; a broader wildcard or explicit date filters on `_TABLE_SUFFIX` ensures no data gaps | WHEN_TO_APPLY: Whenever selecting from time-partitioned or date-suffixed tables using wildcard patterns | EXAMPLE_USAGE: Incorrect: SELECT * FROM `dataset.events_2020*` WHERE event_date BETWEEN '20210101' AND '20210131'; (This misses `events_202101` entirely) Correct: SELECT * FROM `dataset.events_*` WHERE _TABLE_SUFFIX BETWEEN '202001' AND '202101'; (This includes all monthly tables from January 2020 through January 2021)
157,ga002,ga4,question,NA,NA,NA,NA,NA,"The original wildcard only included 2020 tables, excluding January 2021; changing to `events_*` captured the missing month’s data."
158,ga008,ga4,db,distinct;count;group by;left join;coalesce,events_202011*,all,all,Yes,"ENSURE: daily_user_views CTE selects DISTINCT purchase days and LEFT JOINs aggregated page_view counts with COALESCE to zero | CONTEXT: uses `events_202011*` table with columns event_date, user_pseudo_id, event_name and aliases pd (purchases) and nv (page_view counts) to restrict page_view metrics to purchase days | WHEN_TO_CHECK: when building per-user daily metrics restricted to purchase events | EXAMPLE_USAGE: Incorrect: WITH daily_user_views AS ( SELECT event_date, user_pseudo_id, COUNT(*) AS user_day_views FROM `...events_202011*` WHERE event_name IN ('purchase','page_view') GROUP BY event_date, user_pseudo_id Correct: WITH distinct_purchases AS ( SELECT DISTINCT event_date, user_pseudo_id FROM `...events_202011*` WHERE event_name = 'purchase' , page_view_counts AS ( SELECT event_date, user_pseudo_id, COUNT(*) AS user_day_views FROM `...events_202011*` WHERE event_name = 'page_view' GROUP BY event_date, user_pseudo_id SELECT pd.event_date, pd.user_pseudo_id, COALESCE(nv.user_day_views, 0) AS user_day_views FROM distinct_purchases pd LEFT JOIN page_view_counts nv ON pd.event_date = nv.event_date AND pd.user_pseudo_id = nv.user_pseudo_id;"
159,ga008,ga4,db,date_parse,all,all,date,all,"ENSURE: final SELECT parses event_date from YYYYMMDD string to DATE type with PARSE_DATE | CONTEXT: final projection of event_date, avg_page_views, f0_ uses string event_date in ‘YYYYMMDD’ format | WHEN_TO_CHECK: when outputting or comparing dates stored as strings | EXAMPLE_USAGE: Incorrect: SELECT event_date, avg_page_views FROM daily_user_metrics; - event_date remains string '20201105' Correct: SELECT PARSE_DATE('%Y%m%d', event_date) AS event_date, avg_page_views FROM daily_user_metrics;"
160,ga008,all,generic,distinct;count;group by;left join,all,all,all,all,"VERIFY: filter the primary subset of records before joining aggregated metrics rather than grouping on combined event types | PRINCIPLE: isolating the driving dimension via DISTINCT or a WHERE clause before left joining prevents inclusion of metrics for non-relevant keys | WHEN_TO_APPLY: when computing metrics of one event type (e.g., views) only for a subset defined by another event type (e.g., purchases) | EXAMPLE_USAGE: Incorrect: SELECT user_id, COUNT(*) AS view_count FROM events WHERE event_type IN ('purchase','view') GROUP BY user_id; Correct: WITH base AS ( SELECT DISTINCT user_id FROM events WHERE event_type = 'purchase' , views AS ( SELECT user_id, COUNT(*) AS view_count FROM events WHERE event_type = 'view' GROUP BY user_id SELECT b.user_id, COALESCE(v.view_count,0) AS view_count FROM base b LEFT JOIN views v ON b.user_id = v.user_id;"
161,ga008,all,generic,left join;coalesce,all,all,all,Yes,"VERIFY: wrap LEFT JOIN aggregates with COALESCE to convert NULL counts to zero | PRINCIPLE: left joins yield NULL for missing matches, which should be treated as zero in count-based metrics | WHEN_TO_APPLY: after LEFT JOINing aggregated count subqueries | EXAMPLE_USAGE: Incorrect: SELECT b.id, v.count FROM base b LEFT JOIN (SELECT id, COUNT(*) AS count FROM events GROUP BY id) v ON b.id = v.id; - v.count is NULL when no events exist Correct: SELECT b.id, COALESCE(v.count, 0) AS count FROM base b LEFT JOIN (SELECT id, COUNT(*) AS count FROM events GROUP BY id) v ON b.id = v.id;"
162,ga008,all,generic,date_parse,all,all,date,all,"CHECK: convert string-formatted dates to DATE type using appropriate parsing functions | PRINCIPLE: string representations of dates must be cast or parsed to date types for correct date logic and uniform formatting | WHEN_TO_APPLY: whenever selecting or comparing date fields stored as strings | EXAMPLE_USAGE: Incorrect: SELECT date_str FROM orders; - returns '20210115' Correct: SELECT PARSE_DATE('%Y%m%d', date_str) AS order_date FROM orders; - returns DATE ’2021-01-15’"
163,ga008,ga4,question,NA,NA,NA,NA,NA,"The core issue was including all page_views for purchasing users rather than only those on purchase days; rewriting the daily_user_views CTE with a LEFT JOIN on distinct purchase days restricts aggregation correctly, and parsing event_date to DATE matches the GOLD date format."
164,ga008,ga4,db,filter;where;event_name,all,event_name,all,all,"CAUTION: Event names alone may not be sufficient indicators for filtering events - verify using additional columns when possible | PRINCIPLE: event_name may be missing, NULL, or contain unexpected values in some rows; relying solely on event_name='purchase' might miss legitimate purchase events that have other purchase indicators (e.g., ecommerce.transaction_id IS NOT NULL, purchase_revenue > 0), and similarly for engagement events (engagement_time_msec > 0) or other event types | WHEN_TO_APPLY: When filtering for specific event types in GA4/Firebase analytics data, especially for critical business metrics like purchases, conversions, or user engagement | EXAMPLE_USAGE: Less robust: WHERE event_name = 'purchase'; More robust: WHERE event_name = 'purchase' OR (ecommerce.transaction_id IS NOT NULL AND ecommerce.purchase_revenue > 0). For engagement: WHERE event_name IN ('user_engagement', 'session_start') OR engagement_time_msec > 0. Consider defensive filtering that accounts for data quality issues."
165,bq004,ga360,generic,like;regex,all,all,str,all,"ENSURE: Use LIKE for substring matching, REGEX with \b only for whole-word matching | PRINCIPLE: LIKE '%word%' matches the substring anywhere (e.g., 'education' matches 'educational', 're-education'); REGEX with \b (word boundary) like r'\bword\b' only matches complete words, excluding substrings within other words | WHEN_TO_APPLY: When searching for text patterns, use LIKE '%pattern%' if substring matches are needed (e.g., finding 'education' in 'educational'); use REGEXP_CONTAINS with \b only when whole-word matching is explicitly required | EXAMPLE_USAGE: For finding articles mentioning 'education', use 'LOWER(body) LIKE ''%education%''' matches 'education', 'educational', 're-education'; using 'REGEXP_CONTAINS(LOWER(body), r''\beducation\b'')' only matches 'education' as a whole word, missing 'educational' and 're-education'. For 'containing YouTube', use 'product_name LIKE ''%YouTube%''' to catch all YouTube variants."
166,bq161,pancancer_atlas_2,db,filter;null check;pre-filtered,Filtered_clinical_PANCAN_patient_with_followup,all,all,all,"ENSURE: Do not apply NULL/empty filters on Filtered_clinical_PANCAN_patient_with_followup table | PRINCIPLE: Filtered_clinical_PANCAN_patient_with_followup table name indicates pre-filtered clinical data; adding filters like days_to_last_followup IS NOT NULL excludes valid rows that should be included | WHEN_TO_CHECK: When querying Filtered_clinical_PANCAN_patient_with_followup, avoid redundant NULL/empty checks that would exclude valid data | EXAMPLE_USAGE: Correct: SELECT bcr_patient_barcode FROM Filtered_clinical_PANCAN_patient_with_followup WHERE acronym = 'PAAD'; Incorrect: SELECT bcr_patient_barcode FROM Filtered_clinical_PANCAN_patient_with_followup WHERE acronym = 'PAAD' AND days_to_last_followup IS NOT NULL"
167,bq161,all,generic,filter;table naming;pre-filtered,all,all,all,all,"ENSURE: Do not apply redundant NULL/empty filters on tables with 'Filtered', 'Clean', or 'Validated' prefixes | PRINCIPLE: Tables with filtering indicators in names (Filtered_*, Clean_*, Validated_*) already contain pre-filtered data; adding NULL/empty checks like 'column IS NOT NULL' or 'column != ''' can exclude valid rows that should be included | WHEN_TO_APPLY: When querying tables with filtering prefixes, avoid redundant NULL/empty filters unless explicitly required; trust that the table name indicates data is already filtered | EXAMPLE_USAGE: For Filtered_clinical_PANCAN_patient_with_followup, use 'WHERE acronym = ''PAAD''' is correct; adding 'AND days_to_last_followup IS NOT NULL' is incorrect as the table already contains filtered data"
