instance_id,user_query,used_gold_tables,used_gold_joins,used_predicted_tables_cols,used_predicted_tables_cols_raw,used_external_knowledge,model,examples_used,predicted_cte_briefs,raw_output,example_selection,timestamp
sf_bq029,"Get the average number of inventors per patent and the total count of patent publications in Canada (CA) for each 5-year period from 1960 to 2020, based on publication dates. Only include patents that have at least one inventor listed, and group results by 5-year intervals (1960-1964, 1965-1969, etc.).",false,false,true,true,false,azure/o3,,"filtered_ca_pubs: Canadian patent publications 1960-2020 with ≥1 inventor, keeping publication_number and publication_date; inventor_counts: Distinct inventor tally per publication from filtered_ca_pubs; period_buckets: Attach 5-year interval label to each record using publication_date; period_metrics: Aggregate by interval to compute publication count and average inventors per patent","filtered_ca_pubs: Canadian patent publications 1960-2020 with ≥1 inventor, keeping publication_number and publication_date; inventor_counts: Distinct inventor tally per publication from filtered_ca_pubs; period_buckets: Attach 5-year interval label to each record using publication_date; period_metrics: Aggregate by interval to compute publication count and average inventors per patent","{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:45:53
sf_bq026,"For the assignee who has been the most active in the patent category 'A61', I'd like to know the five patent jurisdictions code where they filed the most patents during their busiest year, separated by commas.",false,false,true,true,false,azure/o3,,"filtered_a61_patents: Filter publications with CPC beginning 'A61'; keep assignee, filing_date, country_code; yearly_counts: Count patents per assignee and filing year from filtered set; busiest_years: For each assignee, select year with maximum filings and its count; top_assignee: Retrieve assignee and year with highest overall filings; assignee_year_patents: Patents for that assignee during their busiest year; country_counts: Count patents by country_code within that subset, ordered by count desc; top_country_list: Concatenate top five country_codes into a comma-separated string","filtered_a61_patents: Filter publications with CPC beginning 'A61'; keep assignee, filing_date, country_code; yearly_counts: Count patents per assignee and filing year from filtered set; busiest_years: For each assignee, select year with maximum filings and its count; top_assignee: Retrieve assignee and year with highest overall filings; assignee_year_patents: Patents for that assignee during their busiest year; country_counts: Count patents by country_code within that subset, ordered by count desc; top_country_list: Concatenate top five country_codes into a comma-separated string","{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:46:10
sf_bq091,In which year did the assignee with the most applications in the patent category 'A61' file the most?,false,false,true,true,false,azure/o3,,category_a61: Filter publications where ipc LIKE 'A61%' to isolate relevant category; assignee_counts: Count applications per assignee within category_a61; top_assignee: Select assignee with highest application count; top_assignee_filings: All filings in category_a61 by top_assignee; yearly_counts: Count filings per year from top_assignee_filings; peak_year: Retrieve year with maximum filing count,category_a61: Filter publications where ipc LIKE 'A61%' to isolate relevant category; assignee_counts: Count applications per assignee within category_a61; top_assignee: Select assignee with highest application count; top_assignee_filings: All filings in category_a61 by top_assignee; yearly_counts: Count filings per year from top_assignee_filings; peak_year: Retrieve year with maximum filing count,"{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:46:31
sf_bq099,"For patent class A01B3, I want to analyze the information of the top 3 assignees based on the total number of applications. Please provide the following five pieces of information: the name of this assignee,  total number of applications, the year with the most applications, the number of applications in that year, and the country code with the most applications during that year.",false,false,true,true,false,azure/o3,,"cpc_filtered: Select publications in CPC A01B3 with filing_date, country_code, assignee identifier columns; assignee_totals: Aggregate cpc_filtered by assignee to count total applications; top_assignees: Select top 3 assignees ordered by total applications; yearly_counts: Count applications for each top assignee per filing year; peak_years: For each assignee, pick year with max applications and record its count; top_country: Within each assignee’s peak year, find country_code with highest applications","cpc_filtered: Select publications in CPC A01B3 with filing_date, country_code, assignee identifier columns; assignee_totals: Aggregate cpc_filtered by assignee to count total applications; top_assignees: Select top 3 assignees ordered by total applications; yearly_counts: Count applications for each top assignee per filing year; peak_years: For each assignee, pick year with max applications and record its count; top_country: Within each assignee’s peak year, find country_code with highest applications","{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:46:51
sf_bq033,"How many U.S. publications related to IoT (where the abstract includes the phrase 'internet of things') were filed each month from 2008 to 2022, including months with no filings?",false,false,true,true,false,azure/o3,,date_months: create sequence of all months from Jan 2008 to Dec 2022; iot_us_pubs: select US publications filed 2008-2022 where abstract ilike '%internet of things%'; monthly_pub_counts: count distinct application_number per YYYY-MM filing date from iot_us_pubs; monthly_totals: left join date_months with monthly_pub_counts to fill missing months with zero filings,date_months: create sequence of all months from Jan 2008 to Dec 2022; iot_us_pubs: select US publications filed 2008-2022 where abstract ilike '%internet of things%'; monthly_pub_counts: count distinct application_number per YYYY-MM filing date from iot_us_pubs; monthly_totals: left join date_months with monthly_pub_counts to fill missing months with zero filings,"{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:47:03
sf_bq209,"Can you calculate the number of utility patents that were granted in 2010 and have exactly one forward citation within a 10-year window following their application/filing date? For this analysis, forward citations should be counted as distinct citing application numbers that cited the patent within 10 years after the patent's own filing date.",false,false,true,true,false,azure/o3,,utility_patents_2010: Utility patents granted in 2010 with filing_date retained; forward_citations: Citing applications referencing 2010 utility patents within 10 years of their filing_date; citation_counts: Aggregate forward citations per patent counting distinct citing application_numbers; single_citation_patents: Select patents with exactly one forward citation; result_count: Total number of such patents,utility_patents_2010: Utility patents granted in 2010 with filing_date retained; forward_citations: Citing applications referencing 2010 utility patents within 10 years of their filing_date; citation_counts: Aggregate forward citations per patent counting distinct citing application_numbers; single_citation_patents: Select patents with exactly one forward citation; result_count: Total number of such patents,"{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:47:18
sf_bq027,"For patents granted between 2010 and 2018, provide the publication number of each patent and the number of backward citations it has received in the SEA category.",false,false,true,true,false,azure/o3,,"patents_in_range: Patents granted 2010-2018, returning publication_number; sea_citations: Citation rows with category 'SEA', each cited_pub_number; citation_totals: Count SEA citations per cited_pub_number; results: Join patents_in_range with citation_totals, output publication_number and citation_count","patents_in_range: Patents granted 2010-2018, returning publication_number; sea_citations: Citation rows with category 'SEA', each cited_pub_number; citation_totals: Count SEA citations per cited_pub_number; results: Join patents_in_range with citation_totals, output publication_number and citation_count","{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:47:35
sf_bq210,How many US B2 patents granted between 2008 and 2018 contain claims that do not include the word 'claim'?,false,false,true,true,false,azure/o3,,pubs_core: Select required columns from PATENTS.PUBLICATIONS; us_b2: Filter pubs_core to US country_code and B2 kind_code; grants_2008_2018: Limit us_b2 to grant_date 2008-01-01–2018-12-31; no_claim_term: Keep grants_2008_2018 where lower(claims_localized) lacks 'claim' word for final count,pubs_core: Select required columns from PATENTS.PUBLICATIONS; us_b2: Filter pubs_core to US country_code and B2 kind_code; grants_2008_2018: Limit us_b2 to grant_date 2008-01-01–2018-12-31; no_claim_term: Keep grants_2008_2018 where lower(claims_localized) lacks 'claim' word for final count,"{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:47:49
sf_bq211,"Among patents granted between 2010 and 2023 in CN, how many of them belong to families that have a total of over one distinct applications?",false,false,true,true,false,azure/o3,,granted_cn_2010_2023: CN publications granted between 2010-01-01 and 2023-12-31; family_app_counts: count distinct application_number per family across all publications; multi_app_families: filter families with application_count > 1; qualifying_patents: granted_cn_2010_2023 records whose family_id is in multi_app_families,granted_cn_2010_2023: CN publications granted between 2010-01-01 and 2023-12-31; family_app_counts: count distinct application_number per family across all publications; multi_app_families: filter families with application_count > 1; qualifying_patents: granted_cn_2010_2023 records whose family_id is in multi_app_families,"{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:48:01
sf_bq213,What is the most common 4-digit IPC code among US B2 utility patents granted from June to August in 2022?,false,false,true,true,true,azure/o3,,"filtered_us_b2_pubs: US utility patents with kind B2 granted 2022-06-01 to 2022-08-31; main_ipc_expanded: Unnest ipc array from filtered publications keeping first=true records; ipc4_counts: Aggregate by 4-digit ipc prefix counting distinct publications; top_ipc4: Select prefix with highest count, break ties alphabetically","filtered_us_b2_pubs: US utility patents with kind B2 granted 2022-06-01 to 2022-08-31; main_ipc_expanded: Unnest ipc array from filtered publications keeping first=true records; ipc4_counts: Aggregate by 4-digit ipc prefix counting distinct publications; top_ipc4: Select prefix with highest count, break ties alphabetically","{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:48:16
sf_bq212,"For United States utility patents under the B2 classification granted between June and September of 2022, identify the most frequent 4-digit IPC code for each patent. Then, list the publication numbers and IPC4 codes of patents where this code appears 10 or more times.",false,false,true,true,true,azure/o3,,"filtered_pubs: Select US utility patents with kind B2 granted 2022-06-01–2022-09-30; ipc_per_pub: Unnest ipc array, derive 4-digit code, count occurrences for each publication-ipc4 pair; top_ipc4_per_pub: Pick ipc4 with highest count per publication (break ties by earliest code); popular_ipc4: Aggregate top codes, keep ipc4 occurring in at least 10 publications; final_list: Return publication_number and ipc4 where top code is in popular_ipc4 set","filtered_pubs: Select US utility patents with kind B2 granted 2022-06-01–2022-09-30; ipc_per_pub: Unnest ipc array, derive 4-digit code, count occurrences for each publication-ipc4 pair; top_ipc4_per_pub: Pick ipc4 with highest count per publication (break ties by earliest code); popular_ipc4: Aggregate top codes, keep ipc4 occurring in at least 10 publications; final_list: Return publication_number and ipc4 where top code is in popular_ipc4 set","{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:48:32
sf_bq214,"For United States utility patents under the B2 classification granted between 2010 and 2014, find the one with the most forward citations within a month of its filing date, and identify the most similar patent from the same filing year, regardless of its type.",false,false,true,true,true,azure/o3,,filter_us_b2: US B2 utility patents granted 2010-2014 with filing and grant dates; early_forward_cites: map cited_by to citing filings within 30-day window and count per patent; top_forward_patent: select patent with highest timely forward citation count; same_year_candidates: gather patents from top patent’s filing year across all types with embeddings; similarity_rank: compute and rank embedding similarity to top patent to pick closest match,filter_us_b2: US B2 utility patents granted 2010-2014 with filing and grant dates; early_forward_cites: map cited_by to citing filings within 30-day window and count per patent; top_forward_patent: select patent with highest timely forward citation count; same_year_candidates: gather patents from top patent’s filing year across all types with embeddings; similarity_rank: compute and rank embedding similarity to top patent to pick closest match,"{""target_db"": ""PATENTS_GOOGLE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:48:53
sf_bq216,Identify the top five patents filed in the same year as `US-9741766-B2` that are most similar to it based on technological similarities. Please provide the publication numbers.,false,false,true,true,true,azure/o3,,"target_info: Retrieve filing year and embedding for US-9741766-B2; same_year_pats: Patents filed same year, excluding target, with embeddings; sim_scores: Compute dot product similarity between target and each candidate; ranked_similar: Sort by similarity descending, assign rank; top_five: Return publication_numbers for top five ranks","target_info: Retrieve filing year and embedding for US-9741766-B2; same_year_pats: Patents filed same year, excluding target, with embeddings; sim_scores: Compute dot product similarity between target and each candidate; ranked_similar: Sort by similarity descending, assign rank; top_five: Return publication_numbers for top five ranks","{""target_db"": ""PATENTS_GOOGLE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:49:09
sf_bq247,"From the publications dataset, first identify the top six families with the most publications whose family_id is not '-1'. Then, using the abs_and_emb table (joined on publication_number), provide each of those families’ IDs alongside every non-empty abstract associated with their publications.",false,false,true,true,false,azure/o3,,"filtered_pubs: select publication_number and family_id where family_id <> '-1'; family_counts: count publications per family from filtered_pubs; top_families: retrieve six families with highest publication counts; family_pubs: publications from filtered_pubs belonging to top_families; abstracts_join: join family_pubs with abs_and_emb, keeping rows with non-empty abstract","filtered_pubs: select publication_number and family_id where family_id <> '-1'; family_counts: count publications per family from filtered_pubs; top_families: retrieve six families with highest publication counts; family_pubs: publications from filtered_pubs belonging to top_families; abstracts_join: join family_pubs with abs_and_emb, keeping rows with non-empty abstract","{""target_db"": ""PATENTS_GOOGLE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:49:17
sf_bq127,"For each publication family whose earliest publication was first published in January 2015, please provide the earliest publication date, the distinct publication numbers, their country codes, the distinct CPC and IPC codes, distinct families (namely, the ids) that cite and are cited by this publication family. Please present all lists as comma-separated values, sorted alphabetically",false,false,true,true,false,azure/o3,,"family_first_pub: Earliest publication_date per family_id from PUBLICATIONS; jan2015_families: Families with earliest publication in January 2015; family_publications: Publications for jan2015_families with numbers, country_code, cpc, ipc; outgoing_citations: Distinct family_ids cited by family_publications via PUBLICATIONS.citation; incoming_citations: Distinct family_ids citing family_publications via ABS_AND_EMB.cited_by; family_aggregates: Combine earliest date, publication details, CPC, IPC, citing and cited families into sorted comma lists per family","family_first_pub: Earliest publication_date per family_id from PUBLICATIONS; jan2015_families: Families with earliest publication in January 2015; family_publications: Publications for jan2015_families with numbers, country_code, cpc, ipc; outgoing_citations: Distinct family_ids cited by family_publications via PUBLICATIONS.citation; incoming_citations: Distinct family_ids citing family_publications via ABS_AND_EMB.cited_by; family_aggregates: Combine earliest date, publication details, CPC, IPC, citing and cited families into sorted comma lists per family","{""target_db"": ""PATENTS_GOOGLE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:49:35
sf_bq215,Which US patent (with a B2 kind code and a grant date between 2015 and 2018) has the highest originality score calculated as 1 - (the sum of squared occurrences of distinct 4-digit IPC codes in its backward citations divided by the square of the total occurrences of these 4-digit IPC codes)?,false,false,true,true,true,azure/o3,,filtered_b2_us: US B2 patents granted 2015–2018 with citation arrays; backward_citations: explode citations into citing–cited pairs; citations_ipc4: attach 4-digit IPC codes of each cited patent; ipc4_stats: counts per citing patent of each IPC4 and total occurrences; originality_calc: compute 1-Σ(n_k²)/(N²) originality per patent; ranked_originality: order patents by score and select top,filtered_b2_us: US B2 patents granted 2015–2018 with citation arrays; backward_citations: explode citations into citing–cited pairs; citations_ipc4: attach 4-digit IPC codes of each cited patent; ipc4_stats: counts per citing patent of each IPC4 and total occurrences; originality_calc: compute 1-Σ(n_k²)/(N²) originality per patent; ranked_originality: order patents by score and select top,"{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:49:48
sf_bq222,"Find the CPC technology areas in Germany that had the highest exponential moving average (smoothing factor 0.1) of patent filings per year, specifically for patents granted in December 2016. For each CPC group at level 4, show the full title, CPC group, and the year with the highest exponential moving average of patent filings.",false,false,true,true,true,azure/o3,,"dec_2016_grants: German patents granted in December 2016 with filing year and CPC codes; cpc_group_map: Level-4 CPC symbols with full titles from CPC_DEFINITION; patent_group_year: Map patents to level-4 CPC group symbols per filing year; yearly_counts: Count patents per group_symbol and filing_year; ema_by_year: Calculate exponential moving average (alpha 0.1) of yearly counts by group; top_ema_year: Select year with highest EMA per group; final_result: Join top_ema_year with cpc_group_map for title, group, peak_year, peak_ema","dec_2016_grants: German patents granted in December 2016 with filing year and CPC codes; cpc_group_map: Level-4 CPC symbols with full titles from CPC_DEFINITION; patent_group_year: Map patents to level-4 CPC group symbols per filing year; yearly_counts: Count patents per group_symbol and filing_year; ema_by_year: Calculate exponential moving average (alpha 0.1) of yearly counts by group; top_ema_year: Select year with highest EMA per group; final_result: Join top_ema_year with cpc_group_map for title, group, peak_year, peak_ema","{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:50:06
sf_bq221,"Identify the CPC technology areas with the highest exponential moving average of patent filings each year (with a smoothing factor of 0.2), considering only the first CPC code for each patent that has a valid filing date and a non-empty application number, and report the full CPC title along with the best year associated with the highest exponential moving average for each CPC group at level 5.",false,false,true,true,true,azure/o3,,"filtered_pubs: Publications with non-null application_number and valid filing_date, derive filing_year; primary_cpc5: First CPC code per patent, join definitions, keep level 5 symbols; yearly_counts: Count patents per CPC5 and filing_year; ema_yearly: Compute exponential moving average alpha 0.2 of annual counts per CPC5 ordered by year; best_years: Select year with highest EMA per CPC5 and its value; final_result: Attach full CPC title, output CPC symbol best_year and max_ema ordered by max_ema desc","filtered_pubs: Publications with non-null application_number and valid filing_date, derive filing_year; primary_cpc5: First CPC code per patent, join definitions, keep level 5 symbols; yearly_counts: Count patents per CPC5 and filing_year; ema_yearly: Compute exponential moving average alpha 0.2 of annual counts per CPC5 ordered by year; best_years: Select year with highest EMA per CPC5 and its value; final_result: Attach full CPC title, output CPC symbol best_year and max_ema ordered by max_ema desc","{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:50:30
sf_bq223,"Which assignees, excluding DENSO CORP itself, have cited patents assigned to DENSO CORP, and what are the titles of the primary CPC subclasses associated with these citations? Provide the name of each citing assignee (excluding DENSO CORP), the full title of the primary CPC subclass (based on the first CPC code), and the count of citations grouped by the citing assignee and the CPC subclass title. Ensure that only citations of patents with valid filing dates are considered, and focus on the first CPC code for each citing patent. The results should specifically exclude DENSO CORP as a citing assignee.",false,false,true,true,true,azure/o3,,"denso_patents: select DENSO CORP–assigned publication_numbers with valid filing_date; citation_links: explode citations to link each citing publication to cited denso_patent; citing_core: fetch citing publications, exclude DENSO CORP assignees, keep valid filing_date, extract first cpc symbol; primary_cpc_titles: join first cpc symbol to CPC_DEFINITION for full subclass title; assignee_cpc_counts: aggregate citation counts by citing assignee and subclass title","denso_patents: select DENSO CORP–assigned publication_numbers with valid filing_date; citation_links: explode citations to link each citing publication to cited denso_patent; citing_core: fetch citing publications, exclude DENSO CORP assignees, keep valid filing_date, extract first cpc symbol; primary_cpc_titles: join first cpc symbol to CPC_DEFINITION for full subclass title; assignee_cpc_counts: aggregate citation counts by citing assignee and subclass title","{""target_db"": ""PATENTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:50:39
sf_bq420,"Can you identify the top 5 patents that were initially rejected under section 101 with no allowed claims, based on the length of their granted claims? The patents should have been granted in the US between 2010 and 2023. Additionally, ensure to select the first office action date for each application. Please include their first publication numbers, along with their first publication dates, length of the filed claims and grant dates.",false,false,true,true,false,azure/o3,,"first_office_action: earliest office action per application with rejection_101 flag and zero allowed_claims; granted_pubs: US patents granted 2010-2023 with grant_date, publication_number, publication_date; granted_claims: claim and word counts for granted patents from PATENT_DOCUMENT_STATS; pub_claims: filed claim and word counts for first publications from PGPUB_DOCUMENT_STATS; patent_merged: combine granted_pubs, first_office_action, granted_claims, pub_claims via application ids; ranked_top5: top five patents by granted claim length after all filters","first_office_action: earliest office action per application with rejection_101 flag and zero allowed_claims; granted_pubs: US patents granted 2010-2023 with grant_date, publication_number, publication_date; granted_claims: claim and word counts for granted patents from PATENT_DOCUMENT_STATS; pub_claims: filed claim and word counts for first publications from PGPUB_DOCUMENT_STATS; patent_merged: combine granted_pubs, first_office_action, granted_claims, pub_claims via application ids; ranked_top5: top five patents by granted claim length after all filters","{""target_db"": ""PATENTS_USPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:50:49
sf_bq207,"Could you provide the earliest publication numbers, corresponding application numbers, claim numbers, and word counts for the top 100 independent patent claims, based on the highest word count, retrieved from claims stats within uspto_oce_claims (filtered by ind_flg='1'), matched with their publication numbers from uspto_oce_claims match, and further joined with patents publications to ensure only the earliest publication for each application is included, ordered by descending word count, and limited to the top 100 results?",false,false,true,true,false,azure/o3,,"independent_claims: Select ind_flg='1' claims with appl_id, pat_no, claim_no, word_ct; pat_pub_links: Map pat_no to pub_no distinct from MATCH; claims_with_pubs: Join claims to pub links and publications adding application_number and publication_date; earliest_pubs: Keep earliest publication per application using row_number over publication_date; top_claims: Select earliest pubs claims ordered by word_ct desc limit 100","independent_claims: Select ind_flg='1' claims with appl_id, pat_no, claim_no, word_ct; pat_pub_links: Map pat_no to pub_no distinct from MATCH; claims_with_pubs: Join claims to pub links and publications adding application_number and publication_date; earliest_pubs: Keep earliest publication per application using row_number over publication_date; top_claims: Select earliest pubs claims ordered by word_ct desc limit 100","{""target_db"": ""PATENTS_USPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:51:04
sf_bq128,"Retrieve the following information for U.S. patents filed between January 1, 2014, and February 1, 2014. The patent title and abstract. The publication date of the patent. The number of backward citations for each patent (i.e., the number of patents cited by the current patent before its filing date). The number of forward citations for each patent within the first 5 years of its publication (i.e., the number of patents that cited the current patent within 5 years after its publication). For each patent, ensure the forward citations are counted only for citations within 5 years after the publication date, and backward citations are counted for citations before the filing date.",false,false,true,true,true,azure/o3,,"filtered_patents: U.S. patents filed 2014-01-01–2014-02-01 with title, abstract, publication_date; backward_cites: links where filtered patent cites earlier patents before its filing date; backward_counts: aggregate backward_cites per patent; forward_cites_5yr: links where other patents cite filtered patents within 5 years post-publication; forward_counts: aggregate forward_cites_5yr per patent; final_output: combine filtered_patents with backward_counts and forward_counts for result set","filtered_patents: U.S. patents filed 2014-01-01–2014-02-01 with title, abstract, publication_date; backward_cites: links where filtered patent cites earlier patents before its filing date; backward_counts: aggregate backward_cites per patent; forward_cites_5yr: links where other patents cite filtered patents within 5 years post-publication; forward_counts: aggregate forward_cites_5yr per patent; final_output: combine filtered_patents with backward_counts and forward_counts for result set","{""target_db"": ""PATENTSVIEW"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:51:17
sf_bq246,"Retrieve U.S. patents with the number of forward citations within the first 3 years after the patent application date (i.e., patents citing the current patent within 3 years). Only include patents with both backward citations within 1 year before the application date and forward citations within 1 year after the application date. The query should focus on specific CPC categories, sort results by backward citations in descending order, and return the patent with the most backward citations, limiting to one result.",false,false,true,true,false,azure/o3,,"cpc_us_patents: US patents in requested CPC categories with application_date; backward_citations_1yr: Count prior patents cited within 1 year before each patent’s application; forward_citations_1yr: Count patents citing each within 1 year after application; forward_citations_3yr: Count patents citing each within 3 years after application; eligible_patents: Retain patents having ≥1 backward and ≥1 forward_1yr citation, join counts; ranked_patents: Sort eligible patents by backward count desc and limit to top record","cpc_us_patents: US patents in requested CPC categories with application_date; backward_citations_1yr: Count prior patents cited within 1 year before each patent’s application; forward_citations_1yr: Count patents citing each within 1 year after application; forward_citations_3yr: Count patents citing each within 3 years after application; eligible_patents: Retain patents having ≥1 backward and ≥1 forward_1yr citation, join counts; ranked_patents: Sort eligible patents by backward count desc and limit to top record","{""target_db"": ""PATENTSVIEW"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:51:29
sf_bq052,"Retrieve the following information for U.S. patents: The patent ID, title, and application date. The number of backward citations within 1 month before the application date (i.e., patents that cited the current patent before its application). The number of forward citations within 1 month after the application date (i.e., patents that cited the current patent after its application). The abstract text of the patent. Only include patents that belong to specific CPC categories, such as subsection 'C05' or group 'A01G'. The query should filter patents to include only those that have at least one backward citation or one forward citation in the 1-month period specified. Sort the results by application date and return all matching records.",false,false,true,true,false,azure/o3,,"relevant_patents: patents in C05 or A01G CPC categories with id,title,date,abstract; citation_links: USAPPLICATIONCITATION joined to patents to expose citing_date and cited_date for each pair; back_citations: count citations where cited patent is target and citing_date between date-30 and date; fwd_citations: count citations where cited patent is target and citing_date within 30 days after date; qualified_patents: combine patents with backward and forward counts, keep rows where at least one count >0","relevant_patents: patents in C05 or A01G CPC categories with id,title,date,abstract; citation_links: USAPPLICATIONCITATION joined to patents to expose citing_date and cited_date for each pair; back_citations: count citations where cited patent is target and citing_date between date-30 and date; fwd_citations: count citations where cited patent is target and citing_date within 30 days after date; qualified_patents: combine patents with backward and forward counts, keep rows where at least one count >0","{""target_db"": ""PATENTSVIEW"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:52:13
sf_bq036,What was the average number of GitHub commits made per month in 2016 for repositories containing Python code?,false,false,true,true,false,azure/o3,,python_repos: Repositories whose languages list includes Python; commits_2016: Commits dated 2016 for python_repos; monthly_commit_counts: Total 2016 commits per calendar month; avg_monthly_commits: Average commits across the twelve 2016 months,python_repos: Repositories whose languages list includes Python; commits_2016: Commits dated 2016 for python_repos; monthly_commit_counts: Total 2016 commits per calendar month; avg_monthly_commits: Average commits across the twelve 2016 months,"{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:52:32
sf_bq100,"How can we identify the top 10 most frequently used packages in GitHub repository contents by looking for import statements enclosed in parentheses, splitting any multi-line imports by newlines, extracting package names that appear within double quotes, counting how often these packages appear, ignoring any null results, and finally ordering them in descending order of their frequency? The final answer should remove the quotation marks.",false,false,true,true,false,azure/o3,,import_blocks: Extract parenthesized import sections from file contents; import_lines: Split each import block into individual lines; package_tokens: Pull substrings within double quotes from lines; clean_packages: Remove quotes and discard null or empty names; package_counts: Count occurrences of each package across repos; top_packages: Select top 10 packages ordered by descending frequency,import_blocks: Extract parenthesized import sections from file contents; import_lines: Split each import block into individual lines; package_tokens: Pull substrings within double quotes from lines; clean_packages: Remove quotes and discard null or empty names; package_counts: Count occurrences of each package across repos; top_packages: Select top 10 packages ordered by descending frequency,"{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:52:40
sf_bq101,"From GitHub Repos contents, how can we identify the top 10 most frequently imported package names in Java source files by splitting each file's content into lines, filtering for valid import statements, extracting only the package portion using a suitable regex, grouping by these extracted package names, counting their occurrences, and finally returning the 10 packages that appear most often in descending order of frequency?",false,false,true,true,false,azure/o3,,"java_files: Filter SAMPLE_CONTENTS to Java source rows; split_lines: Unnest each file’s content into individual lines retaining file metadata; import_lines: Select lines starting with 'import' ignoring comments and static qualifiers; extracted_packages: Regex extract package segment before last dot or wildcard from import lines; package_freq: Count and rank package occurrences, returning top 10 descending","java_files: Filter SAMPLE_CONTENTS to Java source rows; split_lines: Unnest each file’s content into individual lines retaining file metadata; import_lines: Select lines starting with 'import' ignoring comments and static qualifiers; extracted_packages: Regex extract package segment before last dot or wildcard from import lines; package_freq: Count and rank package occurrences, returning top 10 descending","{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:52:53
sf_bq182,"Which primary programming languages, determined by the highest number of bytes in each repository, had at least 100 PullRequestEvents on January 18, 2023 across all their repositories?",false,false,true,true,false,azure/o3,,daily_pr_events: Filter PullRequestEvent rows dated 2023-01-18 from MONTH_202301; repo_pr_counts: Count events per repository from daily_pr_events; repo_primary_lang: Pick primary language per repo by highest byte count; lang_total_prs: Aggregate repo_pr_counts by primary language; qualifying_languages: Keep languages with total PRs >= 100 ordered desc,daily_pr_events: Filter PullRequestEvent rows dated 2023-01-18 from MONTH_202301; repo_pr_counts: Count events per repository from daily_pr_events; repo_primary_lang: Pick primary language per repo by highest byte count; lang_total_prs: Aggregate repo_pr_counts by primary language; qualifying_languages: Keep languages with total PRs >= 100 ordered desc,"{""target_db"": ""GITHUB_REPOS_DATE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:53:09
sf_bq217,"On January 18, 2023, how many pull request creation events occurred in GitHub repositories that include JavaScript as one of their programming languages? Use data from the githubarchive  table for the events and the languages table for repository language information.",false,false,true,true,false,azure/o3,,events_filter: Select pull request creation events from githubarchive for 2023-01-18; js_repo_list: Retrieve repositories where languages include JavaScript; events_with_js_repos: Join filtered events to JavaScript repos; daily_pr_count: Aggregate total pull request creations for the date,events_filter: Select pull request creation events from githubarchive for 2023-01-18; js_repo_list: Retrieve repositories where languages include JavaScript; events_with_js_repos: Join filtered events to JavaScript repos; daily_pr_count: Aggregate total pull request creations for the date,"{""target_db"": ""GITHUB_REPOS_DATE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:53:22
sf_bq191,"From the 2017 GitHub WatchEvent data, find the top two repositories that have more than 300 distinct watchers, ensuring the results are joined with the 'sample_files' table so that we return each repository's name along with its distinct watcher count, and limit the output to the two repositories with the highest watcher counts.",false,false,true,true,false,azure/o3,,"watch_events_2017: isolate 2017 WatchEvent rows; repo_watcher_counts: count distinct watchers per repo from watch_events_2017; popular_repos: keep repos with watcher_count > 300; top_two_with_names: join popular_repos to sample_files, order by watcher_count desc, limit 2","watch_events_2017: isolate 2017 WatchEvent rows; repo_watcher_counts: count distinct watchers per repo from watch_events_2017; popular_repos: keep repos with watcher_count > 300; top_two_with_names: join popular_repos to sample_files, order by watcher_count desc, limit 2","{""target_db"": ""GITHUB_REPOS_DATE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:53:31
sf_bq224,"Which repository with an approved license in `licenses.md` had the highest combined total of forks, issues, and watches in April 2022?",false,false,true,true,false,azure/o3,,"approved_licenses: compile approved license identifiers from licenses.md; licensed_repos: repos with licenses in approved_licenses from GITHUB_REPOS_DATE.GITHUB_REPOS.LICENSES; april_events: filter GITHUB_REPOS_DATE.MONTH.202204 to forks, issues, watches in April 2022; repo_totals: aggregate april_events by repo summing event counts; top_repo: join repo_totals with licensed_repos, rank by total desc to get highest repository","approved_licenses: compile approved license identifiers from licenses.md; licensed_repos: repos with licenses in approved_licenses from GITHUB_REPOS_DATE.GITHUB_REPOS.LICENSES; april_events: filter GITHUB_REPOS_DATE.MONTH.202204 to forks, issues, watches in April 2022; repo_totals: aggregate april_events by repo summing event counts; top_repo: join repo_totals with licensed_repos, rank by total desc to get highest repository","{""target_db"": ""GITHUB_REPOS_DATE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:53:47
sf_bq192,"Find the most active Python repository on GitHub based on watcher count, issues, and forks. The query should select repositories with specific open-source licenses (`artistic-2.0`, `isc`, `mit`, `apache-2.0`), count distinct watchers, issue events, and forks for each repository in April 2022, and include only those with `.py` files on the `master` branch. Join the license data with watch counts, issue events, and fork counts, then sort by a combined metric of forks, issues, and watches, returning the name and count of the most active repository.",false,false,true,true,false,azure/o3,,missing_context: Task details not provided; unable to generate CTE briefs,missing_context: Task details not provided; unable to generate CTE briefs,"{""target_db"": ""GITHUB_REPOS_DATE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:53:57
sf_bq225,"From the GitHub repository files in 'github_repos.sample_files' joined with 'github_repos.sample_contents', which 10 programming languages occur most frequently (based on recognized file extensions) in files that have non-empty content, ordered by their file counts in descending order?",false,false,true,true,true,azure/o3,,joined_files: Join sample_files with sample_contents; filter non-empty content; ext_lkp: Inline table mapping file extensions to programming languages; files_with_lang: Extract file extension from path and attach language via ext_lkp; lang_counts: Aggregate file counts per language; top_languages: Select top 10 languages ordered by descending file count,joined_files: Join sample_files with sample_contents; filter non-empty content; ext_lkp: Inline table mapping file extensions to programming languages; files_with_lang: Extract file extension from path and attach language via ext_lkp; lang_counts: Aggregate file counts per language; top_languages: Select top 10 languages ordered by descending file count,"{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:54:07
sf_bq180,"Get the top 5 most frequently used module names from Python (`.py`) and R (`.r`) scripts, counting occurrences of modules in `import` and `from` statements for Python, and `library()` calls for R. The query should consider only Python and R files, group by module name, and return the top 5 modules ordered by frequency.",false,false,true,true,false,azure/o3,,filtered_samples: Filter rows to Python (.py) and R (.r) files only; code_lines: Split each file’s content into individual lines; extracted_modules: Extract module names via regex from import/from/library statements; module_usage_counts: Aggregate occurrence counts per module; top_5_modules: Return top five modules ordered by descending usage count,filtered_samples: Filter rows to Python (.py) and R (.r) files only; code_lines: Split each file’s content into individual lines; extracted_modules: Extract module names via regex from import/from/library statements; module_usage_counts: Aggregate occurrence counts per module; top_5_modules: Return top five modules ordered by descending usage count,"{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:54:13
sf_bq233,"Can you analyze the joined data from github repos files and github_repos contents, focusing only on files ending with '.py' or '.r', then extract Python modules from 'import' or 'from ... import' lines and R libraries from 'library(...)' lines, count their occurrences, and finally list the results sorted by language and by the number of occurrences in descending order?",false,false,true,true,false,azure/o3,,"filtered_files: Filter SAMPLE_FILES for .py or .r extensions, deriving language column; file_contents: Join filtered_files with SAMPLE_CONTENTS on repo and path to attach code text; parsed_imports: Extract module/library names via regex per line for Python import/from and R library calls, returning language and module; module_counts: Aggregate parsed_imports by language and module, counting occurrences; ranked_modules: Order module_counts by language then count descending for presentation","filtered_files: Filter SAMPLE_FILES for .py or .r extensions, deriving language column; file_contents: Join filtered_files with SAMPLE_CONTENTS on repo and path to attach code text; parsed_imports: Extract module/library names via regex per line for Python import/from and R library calls, returning language and module; module_counts: Aggregate parsed_imports by language and module, counting occurrences; ranked_modules: Order module_counts by language then count descending for presentation","{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:54:33
sf_bq248,"Among all repositories that do not use any programming language whose name (case-insensitively) includes the substring ""python,"" what is the proportion of files whose paths include ""readme.md"" and whose contents contain the phrase ""Copyright (c)""?",false,false,true,true,false,azure/o3,,python_repos: Repos with language ILIKE '%python%'; eligible_files: Files+contents from repos not in python_repos; target_files: Eligible_files with 'readme.md' path and 'Copyright (c)' text; aggregated_counts: Aggregate total eligible files and target_files to calculate proportion,python_repos: Repos with language ILIKE '%python%'; eligible_files: Files+contents from repos not in python_repos; target_files: Eligible_files with 'readme.md' path and 'Copyright (c)' text; aggregated_counts: Aggregate total eligible files and target_files to calculate proportion,"{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:55:01
sf_bq193,"Retrieve all non-empty, non-commented lines from `README.md` files in GitHub repositories, excluding lines that are comments (either starting with `#` for Markdown or `//` for code comments). For each line, calculate how often each unique line appears across all repositories and return a comma-separated list of the programming languages used in each repository containing that line, sorted alphabetically, with the results ordered by the frequency of occurrence in descending order.",false,false,true,true,false,azure/o3,,readme_files: Filter SAMPLE_CONTENTS to README.md entries with repo and content; exploded_lines: Split README content into individual trimmed lines with associated repo; filtered_lines: Exclude empty lines and those starting with '#' or '//'; line_repo_distinct: Keep distinct line–repository combinations for accurate counting; line_counts: Compute occurrence count per unique line from distinct pairs; line_langs: Join languages table and list sorted distinct languages per line,readme_files: Filter SAMPLE_CONTENTS to README.md entries with repo and content; exploded_lines: Split README content into individual trimmed lines with associated repo; filtered_lines: Exclude empty lines and those starting with '#' or '//'; line_repo_distinct: Keep distinct line–repository combinations for accurate counting; line_counts: Compute occurrence count per unique line from distinct pairs; line_langs: Join languages table and list sorted distinct languages per line,"{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:55:21
sf_bq295,"Using the 2017 GitHub Archive data for watch events, which three repositories that include at least one Python file (with a .py extension) smaller than 15,000 bytes and containing the substring ""def "" in its content have the highest total number of watch events for that year?",false,false,true,true,false,azure/o3,,filtered_python_samples: .py samples size <15000 and content contains 'def '; qualifying_repos: distinct repo names from filtered_python_samples; watch_events: 2017 rows where type='WatchEvent' with repo parsed; watch_counts: total watch_events per repo; ranked_repos: join qualifying_repos with watch_counts ordered by total desc limit 3,filtered_python_samples: .py samples size <15000 and content contains 'def '; qualifying_repos: distinct repo names from filtered_python_samples; watch_events: 2017 rows where type='WatchEvent' with repo parsed; watch_counts: total watch_events per repo; ranked_repos: join qualifying_repos with watch_counts ordered by total desc limit 3,"{""target_db"": ""GITHUB_REPOS_DATE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:55:35
sf_bq249,"Please provide a report on the number of occurrences of specific line types across files from the GitHub repository. Categorize a line as 'trailing' if it ends with a blank character, as 'Space' if it starts with a space, and as 'Other' if it meets neither condition. The report should include the total number of occurrences for each category, considering all lines across all files.",false,false,true,true,false,azure/o3,,"files_with_content: Join SAMPLE_FILES and SAMPLE_CONTENTS to retrieve repo, file path, and content; exploded_lines: Split file content into individual lines, emitting one row per line with associated file metadata; classified_lines: Categorize each line as 'Trailing', 'Space', or 'Other' using leading/trailing whitespace rules; category_totals: Aggregate and count lines per category across all files for final summary","files_with_content: Join SAMPLE_FILES and SAMPLE_CONTENTS to retrieve repo, file path, and content; exploded_lines: Split file content into individual lines, emitting one row per line with associated file metadata; classified_lines: Categorize each line as 'Trailing', 'Space', or 'Other' using leading/trailing whitespace rules; category_totals: Aggregate and count lines per category across all files for final summary","{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:55:55
sf_bq375,"Determine which file type among Python (.py), C (.c), Jupyter Notebook (.ipynb), Java (.java), and JavaScript (.js) in the GitHub codebase has the most files with a directory depth greater than 10, and provide the file count.",false,false,true,true,false,azure/o3,,"all_files: Retrieve file path and repo identifiers from SAMPLE_FILES; deep_files: Compute directory depth, keeping records with depth greater than 10; target_types: Filter deep_files to files ending .py .c .ipynb .java .js; type_counts: Count files per extension from target_types; top_type: Select extension with highest count from type_counts","all_files: Retrieve file path and repo identifiers from SAMPLE_FILES; deep_files: Compute directory depth, keeping records with depth greater than 10; target_types: Filter deep_files to files ending .py .c .ipynb .java .js; type_counts: Count files per extension from target_types; top_type: Select extension with highest count from type_counts","{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:56:13
sf_bq255,"How many commit messages are there in repositories that use the 'Shell' programming language and 'apache-2.0' license, where the length of the commit message is more than 5 characters but less than 10,000 characters, and the messages do not start with the word 'merge', 'update' or 'test'?",false,false,true,true,false,azure/o3,,"shell_repos: repos with language 'Shell'; licensed_repos: repos licensed under 'apache-2.0'; eligible_repos: intersection of shell_repos and licensed_repos; valid_commits: messages length 6-9999 not starting 'merge','update','test'; commit_count: count valid_commits for eligible_repos","shell_repos: repos with language 'Shell'; licensed_repos: repos licensed under 'apache-2.0'; eligible_repos: intersection of shell_repos and licensed_repos; valid_commits: messages length 6-9999 not starting 'merge','update','test'; commit_count: count valid_commits for eligible_repos","{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:56:25
sf_bq194,"Among all Python (*.py), R (*.r, *.R, *.Rmd, *.rmd), and IPython notebook (*.ipynb) files in the GitHub sample dataset, which library or module is identified as the second most frequently imported or loaded based on the extracted import statements?",false,false,true,true,false,azure/o3,,"relevant_files: join file metadata with contents; keep .py .r .R .rmd .Rmd .ipynb paths; import_lines: isolate lines containing import/library/require/load calls; extracted_libs: regex extract library or module names from import_lines; normalized_libs: lowercase and trim names, remove quotes and blanks; lib_counts: count occurrences per library across all files; ranked_libs: rank libraries by descending count to identify second most","relevant_files: join file metadata with contents; keep .py .r .R .rmd .Rmd .ipynb paths; import_lines: isolate lines containing import/library/require/load calls; extracted_libs: regex extract library or module names from import_lines; normalized_libs: lowercase and trim names, remove quotes and blanks; lib_counts: count occurrences per library across all files; ranked_libs: rank libraries by descending count to identify second most","{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:56:43
sf_bq377,Extract and count the frequency of all package names listed in the require section of JSON-formatted content,false,false,true,true,false,azure/o3,,"raw_with_require: select content rows containing a ""require"" section; require_packages: parse JSON to isolate the require object as key-value pairs; package_rows: unnest require keys into individual package_name rows; package_freq: aggregate and order package_name counts descending","raw_with_require: select content rows containing a ""require"" section; require_packages: parse JSON to isolate the require object as key-value pairs; package_rows: unnest require keys into individual package_name rows; package_freq: aggregate and order package_name counts descending","{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:56:50
sf_bq359,List the repository names and commit counts for the top two GitHub repositories with JavaScript as the primary language and the highest number of commits.,false,false,true,true,false,azure/o3,,filter_js_repos: select repo_name where primary language is JavaScript; commit_counts: aggregate SAMPLE_COMMITS to count commits per repo; js_repos_commits: join JS repos with their commit counts; top_two_js_repos: rank by commit_count descending and keep top two,filter_js_repos: select repo_name where primary language is JavaScript; commit_counts: aggregate SAMPLE_COMMITS to count commits per repo; js_repos_commits: join JS repos with their commit counts; top_two_js_repos: rank by commit_count descending and keep top two,"{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:56:57
sf_bq252,"Could you please find the name of the repository that contains the most copied non-binary Swift file in the dataset, ensuring each file is uniquely identified by its ID?",false,false,true,true,false,azure/o3,,filtered_swift: Join contents and files on id; keep non-binary '.swift' files with copies and repo_name; max_copies: Select highest copies value from filtered_swift; top_repo: Return distinct repo_name where copies equals max_copies,filtered_swift: Join contents and files on id; keep non-binary '.swift' files with copies and repo_name; max_copies: Select highest copies value from filtered_swift; top_repo: Return distinct repo_name where copies equals max_copies,"{""target_db"": ""GITHUB_REPOS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:57:06
sf_bq251,"I want to know the GitHub project URLs for the top 3 most downloaded PyPI packages based on download count. First, extract PyPI package metadata including name, version, and project URLs. Filter these URLs to only include those that link to GitHub repositories. Use a regular expression to clean the GitHub URLs by removing unnecessary parts like 'issues', 'pull', 'blob', and 'tree' paths, keeping only the main repository URL. For packages with multiple versions, use only the most recent version based on upload time. Join this data with download metrics to determine the most downloaded packages. Return only the cleaned GitHub repository URLs (without quotation marks) for the top 3 packages by total download count, ensuring that only packages with valid GitHub URLs are included in the results.",false,false,true,true,false,azure/o3,,"latest_meta: latest metadata row per package by max upload_time; github_links_raw: extract GitHub URLs from project_urls or home_page of latest packages; cleaned_links: trim GitHub URLs to root repo, removing issues/pull/blob/tree segments; download_stats: aggregate FILE_DOWNLOADS for total package downloads; top3_packages: join cleaned_links with download_stats, filter non-null URLs, select top three by downloads","latest_meta: latest metadata row per package by max upload_time; github_links_raw: extract GitHub URLs from project_urls or home_page of latest packages; cleaned_links: trim GitHub URLs to root repo, removing issues/pull/blob/tree segments; download_stats: aggregate FILE_DOWNLOADS for total package downloads; top3_packages: join cleaned_links with download_stats, filter non-null URLs, select top three by downloads","{""target_db"": ""PYPI"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:57:19
sf_bq117,"What is the total number of severe storm events that occurred in the most affected month over the past 15 years according to NOAA records, considering only the top 100 storm events with the highest property damage?",false,false,true,true,false,azure/o3,,"recent_15yr_storms: storms from NOAA_HISTORIC_SEVERE_STORMS.STORMS with event_begin_time in past 15 years; top_damage_100: top 100 rows from recent_15yr_storms ordered by damage_property desc; month_event_counts: count events per yyyy_mm extracted from event_begin_time in top_damage_100; peak_month: month_year with maximum event count, tie resolved by earliest month; final_result: total number of storms in top_damage_100 occurring during peak_month","recent_15yr_storms: storms from NOAA_HISTORIC_SEVERE_STORMS.STORMS with event_begin_time in past 15 years; top_damage_100: top 100 rows from recent_15yr_storms ordered by damage_property desc; month_event_counts: count events per yyyy_mm extracted from event_begin_time in top_damage_100; peak_month: month_year with maximum event count, tie resolved by earliest month; final_result: total number of storms in top_damage_100 occurring during peak_month","{""target_db"": ""NOAA_DATA"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:57:40
sf_bq071,"Can you provide the count of hurricanes and a list of hurricane names (sorted alphabetically and separated by commas) for each city and its associated zip code, where the hurricanes fall within the boundaries of the zip codes? Please exclude any unnamed hurricanes, and sort the results by the count of hurricanes in descending order. The output should include the following columns: city, zip code, state, count of hurricanes, and the list of hurricanes.",false,false,true,true,true,azure/o3,,"named_hurricanes: select hurricanes with non-null names, build geography point; hurricanes_in_zips: spatially join named_hurricanes to ZIP_CODES via ST_WITHIN; zip_hurricane_stats: aggregate by city/state/zip, count hurricanes and alphabetically list names; ordered_results: sort stats by hurricane_count descending for final output","named_hurricanes: select hurricanes with non-null names, build geography point; hurricanes_in_zips: spatially join named_hurricanes to ZIP_CODES via ST_WITHIN; zip_hurricane_stats: aggregate by city/state/zip, count hurricanes and alphabetically list names; ordered_results: sort stats by hurricane_count descending for final output","{""target_db"": ""NOAA_DATA_PLUS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:57:47
sf_bq236,What are the top 5 zip codes of the areas in the United States that have experienced the most hail storm events in the past 10 years? Don't use data from hail reports table.,false,false,true,true,true,azure/o3,,storms_last_decade: Union storm year tables and retain events within past 10 years; hail_events: Filter storms_last_decade to event_type='Hail' and keep event_point; zip_matched: Spatially join hail_events to ZIP_CODES where event_point within zip_code_geom; zip_hail_totals: Aggregate hail event counts per zip_code with state and county detail; top_zip5: Select top 5 zip_codes by hail event count descending for final result,storms_last_decade: Union storm year tables and retain events within past 10 years; hail_events: Filter storms_last_decade to event_type='Hail' and keep event_point; zip_matched: Spatially join hail_events to ZIP_CODES where event_point within zip_code_geom; zip_hail_totals: Aggregate hail event counts per zip_code with state and county detail; top_zip5: Select top 5 zip_codes by hail event count descending for final result,"{""target_db"": ""NOAA_DATA_PLUS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:58:00
sf_bq358,"Can you tell me which bike trip in New York City on July 15, 2015, started and ended in ZIP Code areas with the highest average temperature for that day, as recorded by the Central Park weather station (WBAN '94728')? If there's more than one trip that meets these criteria, I'd like to know about the one that starts in the smallest ZIP Code and ends in the largest ZIP Code. Please return the starting and ending ZIP Codes of this trip.",false,false,true,true,true,azure/o3,,"daily_weather: Obtain average temperature for 2015-07-15 from GSOD where wban = 94728; station_zip: Map each Citibike station to its containing zip_code via geospatial join; day_trips: Filter CITIBIKE_TRIPS to records on 2015-07-15; trips_with_zips: Attach start and end zip_codes to day_trips using station_zip mappings; hottest_zips: Select zip_codes associated with daily_weather temperature (ties allowed); qualifying_trips: Keep trips_with_zips whose start_zip and end_zip are in hottest_zips; ranked_trip: Rank qualifying_trips by start_zip asc, end_zip desc and pick top","daily_weather: Obtain average temperature for 2015-07-15 from GSOD where wban = 94728; station_zip: Map each Citibike station to its containing zip_code via geospatial join; day_trips: Filter CITIBIKE_TRIPS to records on 2015-07-15; trips_with_zips: Attach start and end zip_codes to day_trips using station_zip mappings; hottest_zips: Select zip_codes associated with daily_weather temperature (ties allowed); qualifying_trips: Keep trips_with_zips whose start_zip and end_zip are in hottest_zips; ranked_trip: Rank qualifying_trips by start_zip asc, end_zip desc and pick top","{""target_db"": ""NEW_YORK_CITIBIKE_1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:58:26
sf_bq050,"I want to analyze bike trips in New York City for 2014 by linking trip data with weather information to understand how weather conditions (temperature, wind speed, and precipitation) affect bike trips between neighborhoods. For each combination of starting and ending neighborhoods, I need the following: 1. Total number of bike trips between the neighborhoods. 2. Average trip duration in minutes (rounded to 1 decimal). 3. Average temperature at the start of the trip (rounded to 1 decimal). 4. Average wind speed at the start (in meters per second, rounded to 1 decimal). 5. Average precipitation at the start (in centimeters, rounded to 1 decimal). 6. The month with the most trips (e.g., `4` for April). The data should be grouped by the starting and ending neighborhoods, with:`zip_codes` in `geo_us_boundaries` used to map the bike trip locations based on latitude and longitude. `zip_codes` in `cyclistic` used to obtain the borough and neighborhood names. Using weather data from the Central Park station for the trip date, covering all trips in 2014.",false,false,true,true,true,azure/o3,,"trips_2014: Filter bike trips to 2014, compute start_date, start_month, trip_minutes; start_zip: Spatial join start coords to GEO zip polygons, return start_zip; end_zip: Spatial join end coords to GEO zip polygons, return end_zip; mapped_trips: Join trips_2014 with start_zip, end_zip and CYCLISTIC zip table to add neighborhoods; weather_daily: Select Central Park GSOD 2014, derive avg_temp_c, wind_mps, prcp_cm per date; trips_weather: Join mapped_trips with weather_daily on start_date, attaching weather metrics; monthly_pair_stats: Count trips per start_neighborhood, end_neighborhood, month; final_metrics: Aggregate totals, average duration, weather, and identify peak trip month per neighborhood pair","trips_2014: Filter bike trips to 2014, compute start_date, start_month, trip_minutes; start_zip: Spatial join start coords to GEO zip polygons, return start_zip; end_zip: Spatial join end coords to GEO zip polygons, return end_zip; mapped_trips: Join trips_2014 with start_zip, end_zip and CYCLISTIC zip table to add neighborhoods; weather_daily: Select Central Park GSOD 2014, derive avg_temp_c, wind_mps, prcp_cm per date; trips_weather: Join mapped_trips with weather_daily on start_date, attaching weather metrics; monthly_pair_stats: Count trips per start_neighborhood, end_neighborhood, month; final_metrics: Aggregate totals, average duration, weather, and identify peak trip month per neighborhood pair","{""target_db"": ""NEW_YORK_CITIBIKE_1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:58:47
sf_bq426,"What user type recorded the highest average temperature for trips starting and ending in New York City's zip code 10019 during 2018? Include average precipitation, wind speed, and temperature for that user type based on weather data from the New York Central Park station.",false,false,true,true,true,azure/o3,,"zip_10019: Retrieve geometry row for ZIP 10019; in_zip_stations: Select station_ids within zip_10019 geometry; trips_2018: Filter 2018 trips with both stations in_zip_stations, keep usertype and trip_date; weather_cp_2018: Get Central Park daily temp, prcp, wdsp for 2018; trips_weather: Join trips_2018 with weather_cp_2018 on trip_date; usertype_avgs: Compute average temp, prcp, wdsp per usertype; top_usertype_weather: Select usertype with highest avg temp and its metrics","zip_10019: Retrieve geometry row for ZIP 10019; in_zip_stations: Select station_ids within zip_10019 geometry; trips_2018: Filter 2018 trips with both stations in_zip_stations, keep usertype and trip_date; weather_cp_2018: Get Central Park daily temp, prcp, wdsp for 2018; trips_weather: Join trips_2018 with weather_cp_2018 on trip_date; usertype_avgs: Compute average temp, prcp, wdsp per usertype; top_usertype_weather: Select usertype with highest avg temp and its metrics","{""target_db"": ""NEW_YORK_CITIBIKE_1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:59:08
sf_bq291,"Can you provide a daily weather summary for July 2019 within a 5 km radius of latitude 26.75 and longitude 51.5? I need the maximum, minimum, and average temperatures; total precipitation; average cloud cover between 10 AM and 5 PM; total snowfall (when average temperature is below 32°F); and total rainfall (when average temperature is 32°F or above) for each forecast date. The data should correspond to forecasts created in July 2019 for the following day.",false,false,true,true,true,azure/o3,,"creation_filtered: Forecasts created in July 2019 selecting forecast_time on following day; spatial_filtered: Limit to records within 5 km of point 26.75 51.5; weather_parsed: Extract hourly temperature, precipitation, snowfall, rainfall, cloud_cover from forecast; cloud_window: Subset weather_parsed to hours 10–17 for cloud metrics; daily_aggregates: Compute daily max/min/avg temp, total precip, snow, rain, avg daytime cloud; apply_precip_logic: Choose snowfall when avg_temp<32°F else rainfall, output final summary","creation_filtered: Forecasts created in July 2019 selecting forecast_time on following day; spatial_filtered: Limit to records within 5 km of point 26.75 51.5; weather_parsed: Extract hourly temperature, precipitation, snowfall, rainfall, cloud_cover from forecast; cloud_window: Subset weather_parsed to hours 10–17 for cloud metrics; daily_aggregates: Compute daily max/min/avg temp, total precip, snow, rain, avg daytime cloud; apply_precip_logic: Choose snowfall when avg_temp<32°F else rainfall, output final summary","{""target_db"": ""NOAA_GLOBAL_FORECAST_SYSTEM"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:59:28
sf_bq017,"What are the five longest types of highways within the multipolygon boundary of Denmark (as defined by Wikidata ID 'Q35') by total length, analyzed through planet features?",false,false,true,true,true,azure/o3,,denmark_polygon: Denmark multipolygon geometry from relations with wikidata 'Q35'; highway_features: extract way geometries tagged highway with highway type value; highways_in_denmark: highway_features whose geometry intersects denmark_polygon; length_by_type: geodesic length summed per highway type; top_types: five highway types with greatest total length,denmark_polygon: Denmark multipolygon geometry from relations with wikidata 'Q35'; highway_features: extract way geometries tagged highway with highway type value; highways_in_denmark: highway_features whose geometry intersects denmark_polygon; length_by_type: geodesic length summed per highway type; top_types: five highway types with greatest total length,"{""target_db"": ""GEO_OPENSTREETMAP"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T18:59:41
sf_bq131,"What is the number of bus stops for the bus network with the most stops within the multipolygon boundary of Denmark (as defined by Wikidata ID 'Q35'), analyzed through planet features?",false,false,true,true,true,azure/o3,,denmark_boundary: Fetch Denmark multipolygon geometry using tag wikidata='Q35'; bus_stops: Select point features where all_tags indicate highway='bus_stop'; bus_stops_in_dk: Filter bus_stops whose geometry lies within denmark_boundary; network_counts: Group bus_stops_in_dk by network tag and count stops; top_network: Select network with maximum stop count and its total,denmark_boundary: Fetch Denmark multipolygon geometry using tag wikidata='Q35'; bus_stops: Select point features where all_tags indicate highway='bus_stop'; bus_stops_in_dk: Filter bus_stops whose geometry lies within denmark_boundary; network_counts: Group bus_stops_in_dk by network tag and count stops; top_network: Select network with maximum stop count and its total,"{""target_db"": ""GEO_OPENSTREETMAP"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:00:03
sf_bq349,"Which OpenStreetMap ID from the planet features table corresponds to an administrative boundary, represented as multipolygons, whose total number of 'amenity'-tagged Points of Interest (POIs), as derived from the planet nodes table, is closest to the median count among all such boundaries?",false,false,true,true,true,azure/o3,,"admin_boundaries: Administrative multipolygon features with osm_id and geometry; amenity_nodes: Nodes tagged with 'amenity' and their geometry; boundary_poi_counts: Count amenity_nodes within each admin_boundaries geometry; median_count: Single-row CTE holding median of boundary_poi_counts.count; ranked_boundaries: Attach absolute difference to median, order to find closest boundary","admin_boundaries: Administrative multipolygon features with osm_id and geometry; amenity_nodes: Nodes tagged with 'amenity' and their geometry; boundary_poi_counts: Count amenity_nodes within each admin_boundaries geometry; median_count: Single-row CTE holding median of boundary_poi_counts.count; ranked_boundaries: Attach absolute difference to median, order to find closest boundary","{""target_db"": ""GEO_OPENSTREETMAP"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:00:12
sf_bq007,"Identify the top 10 U.S. states with the highest vulnerable population, calculated based on a weighted sum of employment sectors using 2017 ACS 5-Year data, and determine their average median income change from 2015 to 2018 using zip code data. ",false,false,true,true,true,azure/o3,,state_employment_2017: pull 2017 ACS employment counts by sector per state; vulnerable_score: apply provided weights to compute vulnerable population per state; zip_income_history: gather median household income per zip for 2015 and 2018; income_change_state: average zip income change over 2015-2018 for each state; combined_state_metrics: join vulnerable scores with income change to build state metrics; ranked_states: rank states by vulnerable population and return top 10,state_employment_2017: pull 2017 ACS employment counts by sector per state; vulnerable_score: apply provided weights to compute vulnerable population per state; zip_income_history: gather median household income per zip for 2015 and 2018; income_change_state: average zip income change over 2015-2018 for each state; combined_state_metrics: join vulnerable scores with income change to build state metrics; ranked_states: rank states by vulnerable population and return top 10,"{""target_db"": ""CENSUS_BUREAU_ACS_2"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:00:29
sf_bq429,"Which are the top five states with the greatest average difference in median income between 2015 and 2018 at the ZIP code level, and what is the corresponding average number of vulnerable employees across wholesale trade, natural resources and construction, arts and entertainment, information, and retail trade industries in 2017 according to the ACS Five-Year Estimates and ZIP code boundaries data?",false,false,true,true,true,azure/o3,,"zcta_2015_income: 2015 median household income per ZCTA; zcta_2018_income: 2018 median household income per ZCTA; income_diff: join 2015 and 2018 incomes, compute income change per ZCTA; zip_state_map: add state_code and state_name to each ZCTA via ZIP boundaries; state_avg_diff: calculate average income change by state; top_income_gap_states: keep five states with highest average change; state_vulnerable_avg: compute weighted 2017 vulnerable employment per top state","zcta_2015_income: 2015 median household income per ZCTA; zcta_2018_income: 2018 median household income per ZCTA; income_diff: join 2015 and 2018 incomes, compute income change per ZCTA; zip_state_map: add state_code and state_name to each ZCTA via ZIP boundaries; state_avg_diff: calculate average income change by state; top_income_gap_states: keep five states with highest average change; state_vulnerable_avg: compute weighted 2017 vulnerable employment per top state","{""target_db"": ""CENSUS_BUREAU_ACS_2"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:00:51
sf_bq073,"Using data on ZIP-level median income differences between 2015 and 2018, along with the 2017 ACS employment figures, list each state in descending order of total vulnerable workers, where “vulnerable” is defined as 38% of wholesale trade employees and 41% of manufacturing employees in 2017. Your results should include the state name, the number of vulnerable wholesale trade workers, the number of vulnerable manufacturing workers, and the combined total of these vulnerable workers.",false,false,true,true,false,azure/o3,,"income_change: Compute 2018-2015 median income difference per ZIP; acs_2017_jobs: Select 2017 manufacturing and wholesale employment counts per ZIP; vulnerable_workers_zip: Apply 41% manufacturing and 38% wholesale rates to derive vulnerable counts per ZIP; zip_to_state: Map ZIP codes to state names using boundaries table; vulnerable_workers_state: Aggregate vulnerable wholesale, manufacturing, and total counts by state and sort descending","income_change: Compute 2018-2015 median income difference per ZIP; acs_2017_jobs: Select 2017 manufacturing and wholesale employment counts per ZIP; vulnerable_workers_zip: Apply 41% manufacturing and 38% wholesale rates to derive vulnerable counts per ZIP; zip_to_state: Map ZIP codes to state names using boundaries table; vulnerable_workers_state: Aggregate vulnerable wholesale, manufacturing, and total counts by state and sort descending","{""target_db"": ""CENSUS_BUREAU_ACS_2"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:01:07
sf_bq410,"Find the top 3 states with the smallest adjusted non-labor force population using 2017 ACS tract-level data. Calculate the adjusted non-labor force population as (unemployed_pop + not_in_labor_force - group_quarters), clamping any negative values to zero. For each of these states, display the state abbreviation, the total median income change between 2015 and 2018 across all tracts, the total adjusted non-labor force population, and the average population-adjusted proportion (calculated as the ratio of adjusted non-labor force to total population at the tract level). Join tract data to states using FIPS code prefixes, exclude any tracts with null income differences, and sort results by the adjusted non-labor force population in ascending order.",false,false,true,true,false,azure/o3,,"tract_data_2017: Retrieve 2017 tract GEOID, labor, population, group quarters, 2015 and 2018 incomes; tract_metrics: Compute clamped adjusted_non_labor_force, income_change, and proportion; filter null income_change; tract_with_state: Attach state postal_code via GEOID prefix join to state_fips; state_summary: Aggregate per state summing adjusted_non_labor_force and income_change, averaging proportion; top_states: Select three states with smallest adjusted_non_labor_force for final output","tract_data_2017: Retrieve 2017 tract GEOID, labor, population, group quarters, 2015 and 2018 incomes; tract_metrics: Compute clamped adjusted_non_labor_force, income_change, and proportion; filter null income_change; tract_with_state: Attach state postal_code via GEOID prefix join to state_fips; state_summary: Aggregate per state summing adjusted_non_labor_force and income_change, averaging proportion; top_states: Select three states with smallest adjusted_non_labor_force for final output","{""target_db"": ""CENSUS_BUREAU_ACS_2"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:01:26
sf_bq348,"Within the rectangular area defined by the geogpoints (31.1798246, 18.4519921), (54.3798246, 18.4519921), (54.3798246, 33.6519921), and (31.1798246, 33.6519921), which are the top three usernames responsible for the highest number of historical nodes, originally tagged with the amenities ‘hospital’, ‘clinic’, or ‘doctors’, that do not appear anymore in the current planet_nodes dataset?",false,false,true,true,true,azure/o3,,"boundary_poly: construct geography polygon for specified rectangular coordinates; hist_amenity_nodes: history_nodes inside polygon with amenity in ('hospital','clinic','doctors'); current_node_ids: gather all ids from planet_nodes; vanished_hist_nodes: filter hist_amenity_nodes whose ids not in current_node_ids; user_node_counts: count vanished_hist_nodes per username and rank to top three","boundary_poly: construct geography polygon for specified rectangular coordinates; hist_amenity_nodes: history_nodes inside polygon with amenity in ('hospital','clinic','doctors'); current_node_ids: gather all ids from planet_nodes; vanished_hist_nodes: filter hist_amenity_nodes whose ids not in current_node_ids; user_node_counts: count vanished_hist_nodes per username and rank to top three","{""target_db"": ""GEO_OPENSTREETMAP"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:01:36
sf_bq253,"Find the name of the OpenStreetMap relation that encompasses the most features within the same geographic area as the multipolygon tagged with the Wikidata item 'Q1095'. The relation should have a specified name and no 'wikidata' tag, and at least one of its included features must have a 'wikidata' tag. The analysis should be conducted using the planet_features table. Return the name of this relation.",false,false,true,true,true,azure/o3,,"q1095_area: geometry of multipolygon tagged wikidata 'Q1095'; area_features: features located within q1095_area, flagging those with wikidata tag; candidate_relations: relations within q1095_area having name tag and no wikidata tag; rel_feature_stats: count area_features per candidate relation, retaining ones with at least one wikidata-feature; top_relation: choose relation with highest feature count for result","q1095_area: geometry of multipolygon tagged wikidata 'Q1095'; area_features: features located within q1095_area, flagging those with wikidata tag; candidate_relations: relations within q1095_area having name tag and no wikidata tag; rel_feature_stats: count area_features per candidate relation, retaining ones with at least one wikidata-feature; top_relation: choose relation with highest feature count for result","{""target_db"": ""GEO_OPENSTREETMAP"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:01:53
sf_bq254,"Among all multipolygons located within the same geographic area as the multipolygon associated with Wikidata item Q191, but lacking a 'wikidata' tag themselves, which two rank highest by the number of points that lie within their boundaries, and what are their names?",false,false,true,true,true,azure/o3,,q191_poly: geometry of reference multipolygon tagged wikidata=Q191; candidate_polys: multipolygons intersecting q191_poly and missing wikidata tag; points_in_polys: points contained within candidate_polys geometries; poly_counts: aggregate point counts and extract name for each candidate; top_polys: pick two polygons with highest point counts,q191_poly: geometry of reference multipolygon tagged wikidata=Q191; candidate_polys: multipolygons intersecting q191_poly and missing wikidata tag; points_in_polys: points contained within candidate_polys geometries; poly_counts: aggregate point counts and extract name for each candidate; top_polys: pick two polygons with highest point counts,"{""target_db"": ""GEO_OPENSTREETMAP"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:02:19
sf_bq056,"How many different pairs of roads classified as motorway, trunk, primary, secondary, or residential in California overlap each other without sharing nodes and do not have a bridge tag, where these roads are tagged with 'highway', analyzed through planet ways",false,false,true,true,true,azure/o3,,"ca_boundary: Select California state geometry; filtered_ways: Highway ways in California, classes motorway/trunk/primary/secondary/residential, excluding bridge tag; overlapping_pairs: Unique way id pairs with intersecting geometries; node_disjoint_pairs: Filter overlapping_pairs to pairs with no shared nodes; pair_count: Total count of unique node_disjoint_pairs","ca_boundary: Select California state geometry; filtered_ways: Highway ways in California, classes motorway/trunk/primary/secondary/residential, excluding bridge tag; overlapping_pairs: Unique way id pairs with intersecting geometries; node_disjoint_pairs: Filter overlapping_pairs to pairs with no shared nodes; pair_count: Total count of unique node_disjoint_pairs","{""target_db"": ""GEO_OPENSTREETMAP_BOUNDARIES"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:02:36
sf_bq289,"Can you find the shortest distance between any two amenities (either a library, place of worship, or community center) located within Philadelphia, analyzed through pennsylvania table and planet features points?",false,false,true,true,true,azure/o3,,"philly_boundary: Retrieve Philadelphia place_geom from Pennsylvania places table; amenity_points: Filter planet feature points for amenities library, place_of_worship, community_centre; philly_amenities: Select amenity_points contained within philly_boundary via ST_CONTAINS; pairwise_distances: Compute ST_DISTANCE between each distinct philly_amenities pair; min_distance_pair: Retrieve pair with smallest distance","philly_boundary: Retrieve Philadelphia place_geom from Pennsylvania places table; amenity_points: Filter planet feature points for amenities library, place_of_worship, community_centre; philly_amenities: Select amenity_points contained within philly_boundary via ST_CONTAINS; pairwise_distances: Compute ST_DISTANCE between each distinct philly_amenities pair; min_distance_pair: Retrieve pair with smallest distance","{""target_db"": ""GEO_OPENSTREETMAP_CENSUS_PLACES"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:02:50
sf_bq250,"Based on the most recent 1km population grid data in Singapore before January 2023, using ST_CONVEXHULL to aggregate all population grid centroids into a bounding region and ST_INTERSECTS to identify hospitals from OpenStreetMap’s planet layer (layer_code in (2110, 2120)) that fall within this region, then calculating the distance from each grid cell to its nearest hospital, what is the total population of the grid cell that is farthest from any hospital?",false,false,true,true,true,azure/o3,,"sg_grid_history: Singapore 1 km population grids updated before 2023-01-01; latest_grids: most recent record per grid cell from sg_grid_history; grid_hull: convex hull of latest_grids centroids forming study region; region_hospitals: planet_layers hospitals (layer_code 2110,2120) intersecting grid_hull; grid_distances: each latest_grid with distance to nearest region_hospitals; farthest_cell: select grid with max distance and its population","sg_grid_history: Singapore 1 km population grids updated before 2023-01-01; latest_grids: most recent record per grid cell from sg_grid_history; grid_hull: convex hull of latest_grids centroids forming study region; region_hospitals: planet_layers hospitals (layer_code 2110,2120) intersecting grid_hull; grid_distances: each latest_grid with distance to nearest region_hospitals; farthest_cell: select grid with max distance and its population","{""target_db"": ""GEO_OPENSTREETMAP_WORLDPOP"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:03:03
sf_bq083,"Can you calculate the daily change in the market value of USDC tokens (address `0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48`) for 2023, based on Ethereum transactions? The change should be computed from minting (input pattern `0x40c10f19%`) and burning (input pattern `0x42966c68%`) operations. For each transaction, minting should be positive and burning negative. Extract the relevant amount from the 'input' field as a hexadecimal, convert it to millions, express it in USD format. Group the results by date and order them in descending order.",false,false,true,true,true,azure/o3,,"usdc_txns_2023: select 2023 transactions to USDC contract with mint/burn method signatures; classified_ops: add operation_type and sign based on input prefix 0x40c10f19/0x42966c68; parsed_values: extract 32-byte amount from input, hex-to-decimal, apply sign, convert to millions; daily_changes: sum signed millions per transaction_date for net daily change ordered descending","usdc_txns_2023: select 2023 transactions to USDC contract with mint/burn method signatures; classified_ops: add operation_type and sign based on input prefix 0x40c10f19/0x42966c68; parsed_values: extract 32-byte amount from input, hex-to-decimal, apply sign, convert to millions; daily_changes: sum signed millions per transaction_date for net daily change ordered descending","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:03:09
sf_bq184,"Using only the traces, can you calculate daily cumulative counts of smart contracts created by external addresses (where the trace_address is NULL) versus those created by other contracts (where the trace_address is NOT NULL) for each date from 2017-01-01 through 2021-12-31, ensuring that all dates in this range are included even if no new contracts were created on some days, and showing monotonically increasing cumulative totals for both categories?",false,false,true,true,false,azure/o3,,"creations_raw: Filter TRACES for contract creation traces in date range with creation_date and creator_type flag; daily_counts: Aggregate creations_raw to count contracts per date and creator_type; calendar_days: Generate continuous date series 2017-01-01 to 2021-12-31; daily_counts_complete: Ensure every calendar date has counts, defaulting missing creator_type totals to zero; cumulative_totals: Compute running cumulative counts by creator_type over ascending dates","creations_raw: Filter TRACES for contract creation traces in date range with creation_date and creator_type flag; daily_counts: Aggregate creations_raw to count contracts per date and creator_type; calendar_days: Generate continuous date series 2017-01-01 to 2021-12-31; daily_counts_complete: Ensure every calendar date has counts, defaulting missing creator_type totals to zero; cumulative_totals: Compute running cumulative counts by creator_type over ascending dates","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:03:25
sf_bq195,"What are the top 10 Ethereum addresses by balance, considering both value transactions and gas fees, before September 1, 2021? Only keep successful transactions with no call type or where the call type is 'call'.",false,false,true,true,false,azure/o3,,"tx_value_changes: Positive to to_address, negative from_address for each pre-2021-09-01 transaction; tx_gas_costs: Negative gas_fee (gas_price*receipt_gas_used) for each sender in filtered transactions; trace_value_changes: Positive to_address, negative from_address for successful pre-2021-09-01 call/empty traces; combined_changes: Union all transaction value, gas, and trace changes into single address, amount list; address_balances: Aggregate combined_changes sums per address to derive net balance; top_10_addresses: Select top 10 addresses by highest balance","tx_value_changes: Positive to to_address, negative from_address for each pre-2021-09-01 transaction; tx_gas_costs: Negative gas_fee (gas_price*receipt_gas_used) for each sender in filtered transactions; trace_value_changes: Positive to_address, negative from_address for successful pre-2021-09-01 call/empty traces; combined_changes: Union all transaction value, gas, and trace changes into single address, amount list; address_balances: Aggregate combined_changes sums per address to derive net balance; top_10_addresses: Select top 10 addresses by highest balance","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:03:54
sf_bq256,"Determine the final Ether balance of the Ethereum address that initiated the highest number of successful transactions prior to September 1, 2021 (UTC), excluding calls of type delegatecall, callcode, or staticcall and including all relevant incoming and outgoing transfers, miner rewards, and gas fee deductions, with the final balance presented in Ether after converting from the native unit.",false,false,true,true,false,azure/o3,,filtered_txs: successful transactions before 2021-09-01 with gas fields retained; top_initiator: address with highest count in filtered_txs; filtered_traces: pre-cutoff traces for that address excluding delegatecall/callcode/staticcall; value_flows: aggregate incoming minus outgoing wei from filtered_traces; miner_rewards: total reward wei to address from reward traces; gas_fees: sum effective_gas_price * gas_used for address in filtered_txs; final_balance_eth: compute (net transfers + rewards − gas fees) and convert wei to Ether,filtered_txs: successful transactions before 2021-09-01 with gas fields retained; top_initiator: address with highest count in filtered_txs; filtered_traces: pre-cutoff traces for that address excluding delegatecall/callcode/staticcall; value_flows: aggregate incoming minus outgoing wei from filtered_traces; miner_rewards: total reward wei to address from reward traces; gas_fees: sum effective_gas_price * gas_used for address in filtered_txs; final_balance_eth: compute (net transfers + rewards − gas fees) and convert wei to Ether,"{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:04:10
sf_bq080,"Using only the Ethereum traces table, can you provide a daily cumulative count of smart contracts created by external users (where trace_address is null) versus contracts created by other contracts (where trace_address is not null) between August 30, 2018, and September 30, 2018? Ensure results include every date in this range, even if no new contracts were created, and show strictly increasing cumulative totals.",false,false,true,true,false,azure/o3,,"filtered_creates: Select contract-creation traces within date range, flagging external (trace_address null) vs internal (not null); daily_new_contracts: Sum new contracts per date and creator_type; calendar_dates: Build continuous date series from 2018-08-30 to 2018-09-30; complete_daily: Left join counts to calendar, defaulting missing values to zero; cumulative_totals: Compute running totals per creator_type ordered by date","filtered_creates: Select contract-creation traces within date range, flagging external (trace_address null) vs internal (not null); daily_new_contracts: Sum new contracts per date and creator_type; calendar_dates: Build continuous date series from 2018-08-30 to 2018-09-30; complete_daily: Left join counts to calendar, defaulting missing values to zero; cumulative_totals: Compute running totals per creator_type ordered by date","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:04:21
sf_bq342,"What is the difference between the average hourly changes in transaction values for the Ethereum token 0x68e54af74b22acaccffa04ccaad13be16ed14eac, specifically considering only transactions where the address 0x8babf0ba311aab914c00e8fda7e8558a8b66de5d was the sender or the address 0xfbd6c6b112214d949dcdfb1217153bc0a742862f was the receiver, between January 1, 2019, and December 31, 2020, when comparing 2019 to 2020?",false,false,true,true,false,azure/o3,,"transfers_filt: Filter TOKEN_TRANSFERS by target token, 2019-01-01–2020-12-31, and specified sender or receiver; hourly_sums: Sum filtered transfer values per DATE_TRUNC hour; hourly_deltas: Compute hour-over-hour value change with LAG on hourly totals; yearly_avg: Derive average hourly change for each calendar year; diff_calc: Produce difference between 2020 and 2019 average hourly changes","transfers_filt: Filter TOKEN_TRANSFERS by target token, 2019-01-01–2020-12-31, and specified sender or receiver; hourly_sums: Sum filtered transfer values per DATE_TRUNC hour; hourly_deltas: Compute hour-over-hour value change with LAG on hourly totals; yearly_avg: Derive average hourly change for each calendar year; diff_calc: Produce difference between 2020 and 2019 average hourly changes","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:04:31
sf_bq341,"Which Ethereum address has the top 3 smallest positive balance from transactions involving the token at address ""0xa92a861fc11b99b24296af880011b47f9cafb5ab""?",false,false,true,true,false,azure/o3,,filtered_transfers: Transfers involving specified token address; address_deltas: Encode each transfer as positive incoming or negative outgoing per address; address_balances: Aggregate signed values per address to get net balance; positive_balances: Keep addresses with balance > 0; smallest_three: Order ascending balance and select first three addresses,filtered_transfers: Transfers involving specified token address; address_deltas: Encode each transfer as positive incoming or negative outgoing per address; address_balances: Aggregate signed values per address to get net balance; positive_balances: Keep addresses with balance > 0; smallest_three: Order ascending balance and select first three addresses,"{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:04:42
sf_bq444,"Can you pull the blockchain timestamp, block number, and transaction hash for the first five mint and burn events from Ethereum logs for the address '0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8'? Please include mint events identified by the topic '0x7a53080ba414158be7ec69b987b5fb7d07dee101fe85488f0853ae16239d0bde' and burn events by '0x0c396cd989a39f4459b5fa1aed6a9a8dcdbc45908acfd67e028cd568da98982c', and order them by block timestamp from the oldest to the newest.",false,false,true,true,true,azure/o3,,"filtered_logs: logs for target address filtered to mint or burn topic hashes; classified_events: add event_type column ('mint'/'burn') based on topic hash; ordered_events: sort events ascending by block_timestamp and block_number for tie-break; first_five_events: select first five sorted events with timestamp, block_number, transaction_hash, event_type","filtered_logs: logs for target address filtered to mint or burn topic hashes; classified_events: add event_type column ('mint'/'burn') based on topic hash; ordered_events: sort events ascending by block_timestamp and block_number for tie-break; first_five_events: select first five sorted events with timestamp, block_number, transaction_hash, event_type","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:04:52
sf_bq340,"Which six Ethereum addresses, excluding '0x0000000000000000000000000000000000000000', have the largest absolute differences between their previous and current balances from the tokens at addresses '0x0d8775f648430679a709e98d2b0cb6250d2887ef0' and '0x1e15c05cbad367f044cbfbafda3d9a1510db5513'?",false,false,true,true,false,azure/o3,,"token_transfers_filtered: Filter transfers to the two target tokens; address_balances: Compute cumulative balance per address at each block; latest_balance: Select most recent balance snapshot per address; previous_balance: Select balance from block before latest for each address; balance_change_ranked: Calculate absolute change, exclude null address, rank top six","token_transfers_filtered: Filter transfers to the two target tokens; address_balances: Compute cumulative balance per address at each block; latest_balance: Select most recent balance snapshot per address; previous_balance: Select balance from block before latest for each address; balance_change_ranked: Calculate absolute change, exclude null address, rank top six","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:05:11
sf_bq005,"Calculate the daily average Bitcoin block interval (in seconds) for 2023 by joining consecutive blocks via row-numbered self-joins (including cross-day intervals), excluding the genesis block, and list the first 10 dates with their unadjusted averages.",false,false,true,true,false,azure/o3,,"all_blocks: select bitcoin blocks through 2023 with hash, number, timestamp; numbered_blocks: assign row_number ordered by timestamp for sequencing; consecutive_pairs: self-join to attach previous block timestamp, omitting genesis; intervals_2023: keep pairs where current block date is in 2023 and compute seconds_diff; daily_avg: average interval_seconds per block_date; top_10_dates: return first 10 dates chronologically with their unadjusted averages","all_blocks: select bitcoin blocks through 2023 with hash, number, timestamp; numbered_blocks: assign row_number ordered by timestamp for sequencing; consecutive_pairs: self-join to attach previous block timestamp, omitting genesis; intervals_2023: keep pairs where current block date is in 2023 and compute seconds_diff; daily_avg: average interval_seconds per block_date; top_10_dates: return first 10 dates chronologically with their unadjusted averages","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:05:23
sf_bq334,"Calculate the annual differences in Bitcoin output value averages between two methods: Merged input/output records: Combine the inputs and outputs tables, filter to only output records, and calculate yearly averages. Transactions table: Directly use the output_value field from the transactions table for yearly averages. Show the difference (merged outputs average minus transactions average) only for years with data in both methods.",false,false,true,true,false,azure/o3,,"merged_records: Union INPUTS and OUTPUTS, tag source and extract year from block_timestamp; outputs_yearly_avg: Filter output records, compute average value per year from merged_records; tx_yearly_avg: Compute average output_value per year from TRANSACTIONS; annual_diff: Join yearly averages present in both methods, output merged minus transactions difference","merged_records: Union INPUTS and OUTPUTS, tag source and extract year from block_timestamp; outputs_yearly_avg: Filter output records, compute average value per year from merged_records; tx_yearly_avg: Compute average output_value per year from TRANSACTIONS; annual_diff: Join yearly averages present in both methods, output merged minus transactions difference","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:05:35
sf_bq335,"Among all Bitcoin addresses that have at least one transaction in October 2017 (combining both inputs and outputs), which address conducted its final transaction on the latest date in that month, and, among any addresses sharing that same latest date, which one has the highest sum of transaction values?",false,false,true,true,false,azure/o3,,"inputs_oct: filter INPUTS table to October 2017 rows with address, timestamp, value; outputs_oct: filter OUTPUTS table to October 2017 rows with address, timestamp, value; oct_transactions: union inputs and outputs for combined October activity; addr_metrics: compute each address’s last_transaction_date and total_value from oct_transactions; latest_date: derive overall max last_transaction_date; ranked_candidates: pick addresses matching latest_date ordered by total_value desc for final selection","inputs_oct: filter INPUTS table to October 2017 rows with address, timestamp, value; outputs_oct: filter OUTPUTS table to October 2017 rows with address, timestamp, value; oct_transactions: union inputs and outputs for combined October activity; addr_metrics: compute each address’s last_transaction_date and total_value from oct_transactions; latest_date: derive overall max last_transaction_date; ranked_candidates: pick addresses matching latest_date ordered by total_value desc for final selection","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:05:58
sf_bq057,"Which month (e.g., 3 for March) in 2021 witnessed the highest percentage of Bitcoin transaction volume occurring in CoinJoin transactions (defined as transactions with >2 outputs, output value ≤ input value, and having multiple equal-value outputs)? Also provide the percentage of all Bitcoin transactions that were CoinJoins, the percentage of UTXOs involved in CoinJoin transactions (average of input and output percentages), and the percentage of total Bitcoin volume that occurred in CoinJoin transactions for that month. Round all percentages to 1 decimal place.",false,false,true,true,false,azure/o3,,"transactions_2021: Select 2021 transactions with month, hash, input/output counts and values; equal_output_hashes: Identify transaction hashes having ≥2 outputs with identical value; coinjoin_txns: 2021 transactions with >2 outputs, output_value≤input_value, in equal_output_hashes; monthly_totals: Sum total tx, input, output counts and output_value per month; coinjoin_totals: Sum CoinJoin tx, input, output counts and output_value per month; monthly_metrics: Calculate CoinJoin transaction, UTXO, and volume percentages per month, rounded; top_month: Select month with highest CoinJoin volume percentage and its metrics","transactions_2021: Select 2021 transactions with month, hash, input/output counts and values; equal_output_hashes: Identify transaction hashes having ≥2 outputs with identical value; coinjoin_txns: 2021 transactions with >2 outputs, output_value≤input_value, in equal_output_hashes; monthly_totals: Sum total tx, input, output counts and output_value per month; coinjoin_totals: Sum CoinJoin tx, input, output counts and output_value per month; monthly_metrics: Calculate CoinJoin transaction, UTXO, and volume percentages per month, rounded; top_month: Select month with highest CoinJoin volume percentage and its metrics","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:06:20
sf_bq068,"Using double-entry bookkeeping principles by treating transaction inputs as debits (negative values) and outputs as credits (positive values) for all Bitcoin Cash transactions between 2014-03-01 and 2014-04-01, how can we calculate the maximum and minimum final balances grouped by address type from these transactions?",false,false,true,true,false,azure/o3,,"filtered_inputs: Inputs within 2014-03-01–2014-04-01 window, value negated as amount; filtered_outputs: Outputs in same window, positive amount; combined_entries: Union debits and credits into single ledger; address_balances: Sum amount per address and type for final balance; type_balance_extremes: Max and min balances per address type","filtered_inputs: Inputs within 2014-03-01–2014-04-01 window, value negated as amount; filtered_outputs: Outputs in same window, positive amount; combined_entries: Union debits and credits into single ledger; address_balances: Sum amount per address and type for final balance; type_balance_extremes: Max and min balances per address type","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:06:37
sf_bq092,"In April 2023, what are the highest and lowest balances across all Dash addresses when calculating the net balance for each address using double-entry bookkeeping (where inputs are treated as debits/negative values and outputs as credits/positive values)? Consider all transactions filtered by block_timestamp_month='2023-04-01', and when an address appears as an array in the data, concatenate the array elements into a comma-separated string. For each address and type combination, sum all the values to determine the balance.",false,false,true,true,false,azure/o3,,tx_april: hashes of April 2023 transactions; debit_entries: negative values from inputs with concatenated address string; credit_entries: positive values from outputs with concatenated address string; combined_entries: union of debit and credit rows; address_balances: sum combined values per address to compute net balance; extremes: identify max and min balances across all addresses,tx_april: hashes of April 2023 transactions; debit_entries: negative values from inputs with concatenated address string; credit_entries: positive values from outputs with concatenated address string; combined_entries: union of debit and credit rows; address_balances: sum combined values per address to compute net balance; extremes: identify max and min balances across all addresses,"{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:06:47
sf_bq093,"What were the maximum and minimum net balance changes for Ethereum Classic addresses on October 14, 2016? Calculate these by summing all transactions where addresses received funds (debits), sent funds (credits), and paid or received gas fees. Only include successful status transactions and exclude internal calls of types. For gas fees, consider both the fees paid by transaction senders and received by miners, calculated as multiplied by the gas price for both miners and senders",false,false,true,true,false,azure/o3,,"daily_blocks: filter blocks on 2016-10-14 returning block_number and miner; daily_txs: successful transactions in daily_blocks with value, gas_price, receipt_gas_used, from_address, to_address; value_moves: union positive to_address receipts and negative from_address sends per transaction; gas_moves: compute gas_price*receipt_gas_used, debit sender and credit miner; net_changes: aggregate value_moves and gas_moves by address to net_change; extremes: select addresses with highest and lowest net_change","daily_blocks: filter blocks on 2016-10-14 returning block_number and miner; daily_txs: successful transactions in daily_blocks with value, gas_price, receipt_gas_used, from_address, to_address; value_moves: union positive to_address receipts and negative from_address sends per transaction; gas_moves: compute gas_price*receipt_gas_used, debit sender and credit miner; net_changes: aggregate value_moves and gas_moves by address to net_change; extremes: select addresses with highest and lowest net_change","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:07:10
sf_bq292,"Analyze Bitcoin transactions since July 2023 to determine monthly percentages of: (1)Transactions classified as CoinJoins (defined by >2 outputs, output value ≤ input value, and multiple identical-value outputs), (2) UTXOs involved in CoinJoins (calculated as the average of CoinJoin input/output ratios against total network UTXOs), (3) Transaction volume (based on input value) attributed to CoinJoins. Provide results in a table with monthly metrics for transactions, UTXOs, and volume.",false,false,true,true,false,azure/o3,,"base_transactions: Bitcoin transactions on/after 2023-07-01 with month, input/output counts and values; identical_outputs: Derive per-transaction flag if multiple identical output values exist; coinjoin_tx: Transactions meeting >2 outputs, output_value ≤ input_value, and identical_outputs flag; monthly_network_stats: Monthly totals for transactions, summed input_value, and estimated network UTXO count; monthly_coinjoin_stats: Monthly CoinJoin counts, summed input_value, and average input/output UTXO ratio; final_metrics: Join monthly CoinJoin and network stats to calculate transaction, UTXO, and volume percentages","base_transactions: Bitcoin transactions on/after 2023-07-01 with month, input/output counts and values; identical_outputs: Derive per-transaction flag if multiple identical output values exist; coinjoin_tx: Transactions meeting >2 outputs, output_value ≤ input_value, and identical_outputs flag; monthly_network_stats: Monthly totals for transactions, summed input_value, and estimated network UTXO count; monthly_coinjoin_stats: Monthly CoinJoin counts, summed input_value, and average input/output UTXO ratio; final_metrics: Join monthly CoinJoin and network stats to calculate transaction, UTXO, and volume percentages","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:07:24
sf_bq135,Which date before 2022 had the highest total transaction amount in the Zilliqa blockchain data?,false,false,true,true,false,azure/o3,,"cutoff_txns: Select pre-2022 transactions with amount and timestamp; daily_sums: Aggregate cutoff_txns by date, summing amounts; ranked_days: Order daily_sums by total descending to find top day","cutoff_txns: Select pre-2022 transactions with amount and timestamp; daily_sums: Aggregate cutoff_txns by date, summing amounts; ranked_days: Order daily_sums by total descending to find top day","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:07:36
sf_bq136,"Find all exactly 2-hop transaction paths on Zilliqa blockchain between the source address 'zil1jrpjd8pjuv50cfkfr7eu6yrm3rn5u8rulqhqpz' and destination address 'zil19nmxkh020jnequql9kvqkf3pkwm0j0spqtd26e', considering both regular transactions and contract transitions. A 2-hop path means there must be an intermediate address between source and destination. Exclude paths where any intermediate address has more than 50 outgoing transactions to filter out exchanges and high-activity wallets. Ensure transactions in each path follow chronological order (earlier transaction timestamps first). Display results in the format: '<source> --(tx ABCDE..)--> <intermediate> --(tx FGHIJ..)--> <destination>' where the transaction IDs are truncated to the first 5 characters. Include only confirmed on-chain transactions in both steps of the path.",false,false,true,true,false,azure/o3,,"unified_transfers: Union confirmed transactions and transitions into sender, receiver, tx_id, timestamp; high_activity_senders: Identify senders with >50 outgoing transfers; src_edges: Transfers from given source to intermediates with tx_id and timestamp; dst_edges: Transfers from intermediates to given destination with tx_id and timestamp; two_hop_paths: Link src_edges to dst_edges on intermediate, enforce time order, exclude high_activity_senders","unified_transfers: Union confirmed transactions and transitions into sender, receiver, tx_id, timestamp; high_activity_senders: Identify senders with >50 outgoing transfers; src_edges: Transfers from given source to intermediates with tx_id and timestamp; dst_edges: Transfers from intermediates to given destination with tx_id and timestamp; two_hop_paths: Link src_edges to dst_edges on intermediate, enforce time order, exclude high_activity_senders","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:07:51
sf_bq065,"From the oracle requests table, retrieve the 10 most recent oracle requests with script ID 3. For each request, extract all symbol-rate pairs by matching each symbol in the ""symbols"" array with its corresponding rate at the same position in the ""rates"" array from the decoded result. Adjust each rate by dividing it by the request's multiplier value. Return the block timestamp, oracle request ID, symbol, and the adjusted rate for each symbol-rate pair. Sort the results in chronological order with the newest records first.",false,false,true,true,false,azure/o3,,"recent_requests: fetch 10 latest rows where oracle_script=3 with timestamp, id, decoded_result; parsed_data: extract symbols array, rates array, multiplier from decoded_result JSON; symbol_rate_pairs: unnest symbols and rates arrays per request keeping positional alignment; adjusted_rates: divide each rate by multiplier, output timestamp, request_id, symbol, adjusted_rate ordered newest first","recent_requests: fetch 10 latest rows where oracle_script=3 with timestamp, id, decoded_result; parsed_data: extract symbols array, rates array, multiplier from decoded_result JSON; symbol_rate_pairs: unnest symbols and rates arrays per request keeping positional alignment; adjusted_rates: divide each rate by multiplier, output timestamp, request_id, symbol, adjusted_rate ordered newest first","{""target_db"": ""CRYPTO"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:08:00
sf_bq037,"About the refined human genetic variations collected in phase 3 on 2015-02-20, I want to know the minimum and maximum start positions as well as the proportions of these two respectively for reference bases 'AT' and 'TA'.",false,false,true,true,false,azure/o3,,"filtered_variants: Pick 2015-02-20 phase 3 variants with reference_bases in ('AT','TA'); base_stats: Compute min_start, max_start, total_variants per reference_bases from filtered_variants; extreme_counts: Count variants matching each base's min or max start_position; proportion_calc: Join extreme_counts with base_stats to compute proportion of min and max variants per base","filtered_variants: Pick 2015-02-20 phase 3 variants with reference_bases in ('AT','TA'); base_stats: Compute min_start, max_start, total_variants per reference_bases from filtered_variants; extreme_counts: Count variants matching each base's min or max start_position; proportion_calc: Join extreme_counts with base_stats to compute proportion of min and max variants per base","{""target_db"": ""HUMAN_GENOME_VARIANTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:08:16
sf_bq012,"Calculate the average balance (in quadrillions, 10^15) of the top 10 Ethereum addresses by net balance, including incoming and outgoing transfers from traces (only successful transactions and excluding call types like delegatecall, callcode, and staticcall), miner rewards (sum of gas fees per block), and sender gas fee deductions. Exclude null addresses and round the result to two decimal places.",false,false,true,true,false,azure/o3,,"filtered_traces: select successful value traces excluding delegatecall, callcode, staticcall; transfer_entries: generate positive incoming and negative outgoing amounts per address; gas_deductions: calculate sender gas fees per transaction as negative amounts; miner_rewards: sum gas fees per block credited to miner addresses; address_balances: aggregate transfers, fees, and rewards per address excluding nulls; top10_avg_balance: take top 10 balances, average, convert to quadrillions, round to two decimals","filtered_traces: select successful value traces excluding delegatecall, callcode, staticcall; transfer_entries: generate positive incoming and negative outgoing amounts per address; gas_deductions: calculate sender gas fees per transaction as negative amounts; miner_rewards: sum gas fees per block credited to miner addresses; address_balances: aggregate transfers, fees, and rewards per address excluding nulls; top10_avg_balance: take top 10 balances, average, convert to quadrillions, round to two decimals","{""target_db"": ""ETHEREUM_BLOCKCHAIN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:08:41
sf_bq187,"Calculate the total circulating supply of 'BNB' tokens (in units divided by 10^18) by summing balances of all non-zero addresses, where each address’s balance equals its total received BNB minus sent BNB. Exclude transactions involving the zero address (0x000...) for both senders and receivers.",false,false,true,true,false,azure/o3,,no_task: no specific task details provided to generate CTEs,no_task: no specific task details provided to generate CTEs,"{""target_db"": ""ETHEREUM_BLOCKCHAIN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:08:59
sf_bq450,"Generate a comprehensive report of all Ethereum addresses active before January 1, 2017, calculating their net balances (adjusted for transaction fees and excluding delegatecall/callcode/staticcall transactions), hourly activity patterns, active days, incoming/outgoing transaction metrics (counts, unique counterparties, average ETH transfers), ERC20 token interactions (in/out counts, unique tokens, counterparties), mining rewards, contract creation frequency, failed transaction counts, and contract bytecode sizes, with all ETH values converted to standard units (divided by 10^18) and excluding addresses with no transaction history.",false,false,true,true,true,azure/o3,,"eth_tx_pre2017: Successful external transactions before 2017 with fees, values, timestamps, hour and date fields; filtered_traces_pre2017: Internal traces before 2017 excluding delegatecall/callcode/staticcall, capturing from/to, value, hour, date; token_moves_pre2017: ERC20 token transfers before 2017 with from/to, token_address, value, hour, date; eth_metrics: Per-address incoming/outgoing counts, unique counterparties, sums, averages, gas stats from eth_tx_pre2017 and filtered_traces_pre2017; token_metrics: Per-address token in/out counts, unique tokens and counterparties from token_moves_pre2017; activity_metrics: Active_days and R_active_hour via trigonometric hourly analysis using eth_tx_pre2017 and filtered_traces_pre2017; contract_reward_metrics: Mining rewards, contract creation count, failed transactions, contract bytecode sizes per address; balance_metrics: Net balance per address after fees, scaled to Ether","eth_tx_pre2017: Successful external transactions before 2017 with fees, values, timestamps, hour and date fields; filtered_traces_pre2017: Internal traces before 2017 excluding delegatecall/callcode/staticcall, capturing from/to, value, hour, date; token_moves_pre2017: ERC20 token transfers before 2017 with from/to, token_address, value, hour, date; eth_metrics: Per-address incoming/outgoing counts, unique counterparties, sums, averages, gas stats from eth_tx_pre2017 and filtered_traces_pre2017; token_metrics: Per-address token in/out counts, unique tokens and counterparties from token_moves_pre2017; activity_metrics: Active_days and R_active_hour via trigonometric hourly analysis using eth_tx_pre2017 and filtered_traces_pre2017; contract_reward_metrics: Mining rewards, contract creation count, failed transactions, contract bytecode sizes per address; balance_metrics: Net balance per address after fees, scaled to Ether","{""target_db"": ""ETHEREUM_BLOCKCHAIN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:09:33
sf_bq294,"Could you provide the details of the top 5 longest bike share trips that started between July 1, 2017, and December 31, 2017, including the trip ID, duration in seconds, start date, start station name, route (derived from start station name to end station name), bike number, subscriber type, member's birth year, the member's current age (calculated using the current year), an age classification based on whether the member is younger than 40, between 40 and 60, or older than 60, the member's gender, and the name of the region of the start station? Please exclude any trips where the start station name, member's birth year, or member's gender is not specified.",false,false,true,true,true,azure/o3,,"filtered_trips: 2017-07-01-2017-12-31 trips with mandatory non-null fields; station_dim: station_id, name, region_id lookup for joins; regions_dim: region_id with region_name for enrichment; trips_with_stations: join filtered_trips to station_dim twice for start/end names plus start_region_id; trips_enriched: add region_name, compute age and age_class, build route string; top_longest_trips: select trips_enriched ordered by duration_sec desc limit 5","filtered_trips: 2017-07-01-2017-12-31 trips with mandatory non-null fields; station_dim: station_id, name, region_id lookup for joins; regions_dim: region_id with region_name for enrichment; trips_with_stations: join filtered_trips to station_dim twice for start/end names plus start_region_id; trips_enriched: add region_name, compute age and age_class, build route string; top_longest_trips: select trips_enriched ordered by duration_sec desc limit 5","{""target_db"": ""SAN_FRANCISCO_PLUS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:09:53
sf_bq014,Can you help me figure out the revenue for the product category that has the highest number of customers making a purchase in their first non-cancelled and non-returned order?,false,false,true,true,false,azure/o3,,"valid_orders: filter orders to non-cancelled and non-returned; first_user_order: pick each user’s earliest valid order; first_order_items: join first_user_order with order_items retaining non-returned items; category_customer_counts: join to products, count distinct users per category; top_category: select category with maximum customer count; category_revenue: sum sale_price of all valid items for top_category","valid_orders: filter orders to non-cancelled and non-returned; first_user_order: pick each user’s earliest valid order; first_order_items: join first_user_order with order_items retaining non-returned items; category_customer_counts: join to products, count distinct users per category; top_category: select category with maximum customer count; category_revenue: sum sale_price of all valid items for top_category","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:10:15
sf_bq188,"Among all product categories in the dataset, identify the category with the highest total purchase quantity (based on order_items table), and for that specific category, what is the average time in minutes that users spend on each product page visit? The average time should be calculated as the difference between the timestamp when a user views a product page and the timestamp of the next event within the same session",false,false,true,true,false,azure/o3,,unknown_task: awaiting task details,unknown_task: awaiting task details,"{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:10:26
sf_bq258,"Generate a monthly report for each product category , where each row corresponds to orders that have a status of 'Complete' and were delivered before the year 2022, grouping by the month and year of delivery. For each category, calculate the total revenue (the sum of sale_price), the total number of completed orders, and compute the month-over-month percentage growth for both revenue and orders by comparing each month’s totals to the previous month’s. Then, for the same orders, aggregate and show the total cost (from product costs), total profit (revenue minus total cost), and finally the profit-to-cost ratio for each month.",false,false,true,true,false,azure/o3,,"filtered_orders: Filter orders delivered before 2022 with status 'Complete'; item_details: Join filtered_orders to order_items and products for category, sale_price, cost; monthly_category_sums: Group by category, year, month; compute revenue, completed_orders, total_cost, profit, profit_to_cost; growth_metrics: Add month-over-month percent growth for revenue and orders per category using window lag","filtered_orders: Filter orders delivered before 2022 with status 'Complete'; item_details: Join filtered_orders to order_items and products for category, sale_price, cost; monthly_category_sums: Group by category, year, month; compute revenue, completed_orders, total_cost, profit, profit_to_cost; growth_metrics: Add month-over-month percent growth for revenue and orders per category using window lag","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:10:39
sf_bq259,"Using data up to the end of 2022 and organized by the month of each user's first purchase, can you provide the percentage of users who made a purchase in each of the first, second, third, and fourth months since their initial purchase, where the ""first month"" refers to the month of their initial purchase?",false,false,true,true,false,azure/o3,,filtered_orders: Filter orders to dates ≤2022-12-31; select user_id and order_date; user_first_purchase: Find each user’s earliest order_date; derive cohort_month (YYYY-MM); orders_offset: Join filtered_orders to user_first_purchase; compute month_offset since first purchase up to 3; activity_counts: Count distinct users per cohort_month and month_offset within first four months; cohort_totals: Compute total users in each cohort_month (offset 0); retention_rates: Calculate percentage of active users by dividing counts by cohort totals,filtered_orders: Filter orders to dates ≤2022-12-31; select user_id and order_date; user_first_purchase: Find each user’s earliest order_date; derive cohort_month (YYYY-MM); orders_offset: Join filtered_orders to user_first_purchase; compute month_offset since first purchase up to 3; activity_counts: Count distinct users per cohort_month and month_offset within first four months; cohort_totals: Compute total users in each cohort_month (offset 0); retention_rates: Calculate percentage of active users by dividing counts by cohort totals,"{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:11:04
sf_bq189,"Based solely on completed orders, calculate the average monthly percentage growth rate in the number of unique orders (counting distinct order IDs) for each product category by comparing each month's count to the previous month within the same category. Identify the product category with the highest average of these monthly order growth rates. Then, for that specific product category, compute the average monthly revenue growth rate by calculating the percentage change in total revenue (sum of sale prices) from month to month and averaging these values over the entire period.",false,false,true,true,false,azure/o3,,completed_order_items: completed orders joined to items and products with categories; monthly_category_metrics: monthly distinct order counts and total revenue per category; monthly_growth: add month-over-month percent change for orders and revenue per category; avg_order_growth: compute average order growth per category and determine top category; top_category_metrics: retain monthly_growth rows for the top category; avg_revenue_growth: calculate average monthly revenue growth for the chosen category,completed_order_items: completed orders joined to items and products with categories; monthly_category_metrics: monthly distinct order counts and total revenue per category; monthly_growth: add month-over-month percent change for orders and revenue per category; avg_order_growth: compute average order growth per category and determine top category; top_category_metrics: retain monthly_growth rows for the top category; avg_revenue_growth: calculate average monthly revenue growth for the chosen category,"{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:11:15
sf_bq260,"From January 1, 2019, to April 30, 2022, how many users are at the youngest age and how many users are at the oldest age for each gender in the e-commerce platform, counting both youngest and oldest users separately for each gender?",false,false,true,true,false,azure/o3,,"date_filtered_users: filter users created between 2019-01-01 and 2022-04-30; age_extremes_by_gender: compute youngest and oldest age per gender; edge_age_users: keep users whose age matches gender's youngest or oldest, label type; gender_edge_counts: count youngest and oldest users per gender","date_filtered_users: filter users created between 2019-01-01 and 2022-04-30; age_extremes_by_gender: compute youngest and oldest age per gender; edge_age_users: keep users whose age matches gender's youngest or oldest, label type; gender_edge_counts: count youngest and oldest users per gender","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:11:26
sf_bq261,"For each month prior to January 2024, identify the product that achieved the highest total profit (calculated as the sum of sale_price minus the product’s cost) across all order items, then report the total cost and total profit for that top product per month, including all order items regardless of their status, and present the results chronologically by month.",false,false,true,true,false,azure/o3,,"item_profit: Join order_items with products; derive order_month, item_cost, item_profit per record; monthly_product_totals: Aggregate total_cost and total_profit per order_month and product_id before 2024-01-01; product_rank_by_month: Rank products in each month by total_profit descending; top_product_monthly_summary: Select rank 1 rows, attach product name, output monthly total_cost and total_profit chronologically","item_profit: Join order_items with products; derive order_month, item_cost, item_profit per record; monthly_product_totals: Aggregate total_cost and total_profit per order_month and product_id before 2024-01-01; product_rank_by_month: Rank products in each month by total_profit descending; top_product_monthly_summary: Select rank 1 rows, attach product name, output monthly total_cost and total_profit chronologically","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:11:46
sf_bq262,"Generate a monthly analysis report for e-commerce sales from June 2019 to December 2019 that includes, for each product category and each month, the total number of orders, total revenue, and total profit, along with their month-over-month growth rates using the data from June 2019 as the basis for calculating growth starting from July 2019. Ensure that all orders are included regardless of their status, and present the results sorted in ascending order by month (formatted as ""2019-07"") and then by product category. Omitting June 2019 from the final output but using it for the growth calculations.",false,false,true,true,false,azure/o3,,"item_details: Join orders, order_items, products for item-level date, sale_price, cost, category; period_items: Filter item_details to 2019-06-01–2019-12-31 and derive month_key; monthly_totals: Aggregate period_items by month_key and category for orders_count, revenue, profit; monthly_growth: Add prior-month metrics via lag and compute growth percentages, exclude June","item_details: Join orders, order_items, products for item-level date, sale_price, cost, category; period_items: Filter item_details to 2019-06-01–2019-12-31 and derive month_key; monthly_totals: Aggregate period_items by month_key and category for orders_count, revenue, profit; monthly_growth: Add prior-month metrics via lag and compute growth percentages, exclude June","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:12:00
sf_bq190,"Determine the number of users who are the youngest and oldest for each gender (male and female) separately, among those who signed up between January 1, 2019, and April 30, 2022. For each gender, identify the minimum and maximum ages within this date range, and count how many users fall into these respective age groups.",false,false,true,true,false,azure/o3,,"date_filtered_users: users created between 2019-01-01 and 2022-04-30 retaining id, gender, age; gender_age_bounds: get min_age and max_age for each gender from date_filtered_users; edge_users: identify users whose age equals their gender's min_age or max_age, label as youngest or oldest; gender_age_counts: count edge_users grouped by gender and youngest/oldest label for output","date_filtered_users: users created between 2019-01-01 and 2022-04-30 retaining id, gender, age; gender_age_bounds: get min_age and max_age for each gender from date_filtered_users; edge_users: identify users whose age equals their gender's min_age or max_age, label as youngest or oldest; gender_age_counts: count edge_users grouped by gender and youngest/oldest label for output","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:12:13
sf_bq263,"Please create a month-by-month report for the year 2023 that focuses on the 'Sleep & Lounge' category, showing for each month the total sales, total cost, number of complete orders, total profit, and the profit-to-cost ratio, ensuring that the order is marked as 'Complete,' the creation date is between January 1, 2023, and December 31, 2023, and the cost data is accurately associated with the corresponding product through the order items. ",false,false,true,true,false,azure/o3,,"complete_orders_2023: Orders with status 'Complete' created in 2023; sleep_lounge_products: Inventory items where product_category = 'Sleep & Lounge' with cost; sl_order_items: Order items linked to complete orders and sleep_lounge products, with line sales and cost; monthly_summary: Group sl_order_items by month, sum sales, sum cost, count distinct orders, compute profit and profit_to_cost","complete_orders_2023: Orders with status 'Complete' created in 2023; sleep_lounge_products: Inventory items where product_category = 'Sleep & Lounge' with cost; sl_order_items: Order items linked to complete orders and sleep_lounge products, with line sales and cost; monthly_summary: Group sl_order_items by month, sum sales, sum cost, count distinct orders, compute profit and profit_to_cost","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:12:27
sf_bq264,"Identify the difference in the number of the oldest and youngest users registered between January 1, 2019, and April 30, 2022, from our e-commerce platform data.",false,false,true,true,false,azure/o3,,date_filtered: filter users registered 2019-01-01 to 2022-04-30 with age; age_bounds: find min_age and max_age from date_filtered; extreme_counts: count users at min_age and max_age; diff_calc: compute difference between oldest and youngest user counts,date_filtered: filter users registered 2019-01-01 to 2022-04-30 with age; age_bounds: find min_age and max_age from date_filtered; extreme_counts: count users at min_age and max_age; diff_calc: compute difference between oldest and youngest user counts,"{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:12:39
sf_bq197,"For each month prior to July 2024, identify the single best-selling product (determined by highest sales volume, with total revenue as a tiebreaker) among all orders with a 'Complete' status and products with non-null brands. Return a report showing the month, product name, brand, category, total sales, rounded total revenue, and order status for these monthly top performers.",false,false,true,true,false,azure/o3,,"orders_complete: Select 'Complete' orders before 2024-07-01 and derive order_month; monthly_product_metrics: Aggregate item count and revenue per product and month via orders_complete join order_items; product_enriched: Attach product name, brand, category to metrics and filter non-null brand; product_month_rank: Assign rank per month by units desc then revenue desc; monthly_top_products: Keep rank 1 rows and round revenue for final output","orders_complete: Select 'Complete' orders before 2024-07-01 and derive order_month; monthly_product_metrics: Aggregate item count and revenue per product and month via orders_complete join order_items; product_enriched: Attach product name, brand, category to metrics and filter non-null brand; product_month_rank: Assign rank per month by units desc then revenue desc; monthly_top_products: Keep rank 1 rows and round revenue for final output","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:12:51
sf_bq265,"Can you list the email addresses of the top 10 users who registered in 2019 and made purchases in 2019, ranking them by their highest average order value, where average order value is calculated by multiplying the number of items in each order by the sale price, summing this total across all orders for each user, and then dividing by the total number of orders?",false,false,true,true,false,azure/o3,,"user_reg_2019: 2019-registered users with id and email; orders_2019: 2019 orders for those users; order_totals: compute order value via num_of_item * sale_price; user_avg_value: average order value per user with order count; top_users: top 10 users by avg value, include email","user_reg_2019: 2019-registered users with id and email; orders_2019: 2019 orders for those users; order_totals: compute order value via num_of_item * sale_price; user_avg_value: average order value per user with order count; top_users: top 10 users by avg value, include email","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:13:13
sf_bq266,"Please provide the names of the products that had sales in each month of 2020 and had the lowest profit, calculated as the difference between their retail price and cost from the products data. Exclude any months where this data isn't available. Please list the products in chronological order based on the month.",false,false,true,true,false,azure/o3,,"orders_2020: Filter ORDER_ITEMS to 2020 sales with product_id and month; monthly_product_sales: Summarize orders_2020 by month and product to confirm sales; product_profit: Calculate profit per product as retail_price minus cost; monthly_profit: Attach profit to each month-product combination; lowest_profit_per_month: Keep products whose profit equals the monthly minimum, ready for final ordering","orders_2020: Filter ORDER_ITEMS to 2020 sales with product_id and month; monthly_product_sales: Summarize orders_2020 by month and product to confirm sales; product_profit: Calculate profit per product as retail_price minus cost; monthly_profit: Attach profit to each month-product combination; lowest_profit_per_month: Keep products whose profit equals the monthly minimum, ready for final ordering","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-30T12:32:05
sf_bq333,"Which three browsers have the shortest average session duration—calculated by the difference in seconds between the earliest and latest timestamps for each user’s session—while only including browsers that have more than 10 total sessions, and what are their respective average session durations?",false,false,true,true,false,azure/o3,,"session_times: get earliest and latest created_at per session_id with browser; session_durations: compute duration_seconds as diff between timestamps for each session_id; browser_metrics: summarize sessions per browser, count sessions and average duration; filtered_browsers: keep browsers with session_count greater than 10; top_shortest: order by average duration asc and select top three browsers","session_times: get earliest and latest created_at per session_id with browser; session_durations: compute duration_seconds as diff between timestamps for each session_id; browser_metrics: summarize sessions per browser, count sessions and average duration; filtered_browsers: keep browsers with session_count greater than 10; top_shortest: order by average duration asc and select top three browsers","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:13:31
sf_bq361,"For the user cohort with a first purchase date in January 2020, what proportion of users returned in the subsequent months of 2020?",false,false,true,true,false,azure/o3,,"orders_base: Select user_id and order_date from orders; first_orders: Compute first_order_date per user; jan2020_cohort: Filter users with first_order in 2020-01, capture cohort size; cohort_monthly_activity: Count distinct cohort users returning each 2020 month after January; retention_rates: Calculate returned_user_ratio per month using cohort size","orders_base: Select user_id and order_date from orders; first_orders: Compute first_order_date per user; jan2020_cohort: Filter users with first_order in 2020-01, capture cohort size; cohort_monthly_activity: Count distinct cohort users returning each 2020 month after January; retention_rates: Calculate returned_user_ratio per month using cohort size","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:13:46
sf_bq271,"Please generate a report that, for each month in 2021, provides the number of orders, the number of unique purchasers, and the profit (calculated as the sum of product retail prices minus the sum of product costs), where the orders were placed during 2021 by users who registered in 2021 for inventory items created in 2021, and group the results by the users' country, product department, and product category.",false,false,true,true,false,azure/o3,,"users_2021: Users created in 2021, keep id and country; orders_2021: 2021 orders from users_2021, add month field; items_2021: Inventory items created in 2021 with pricing and categories; order_details: Join orders_2021, order_items, items_2021 and calculate retail_minus_cost profit per item; monthly_metrics: Aggregate by month, country, department, category deriving order count, unique purchasers, total profit","users_2021: Users created in 2021, keep id and country; orders_2021: 2021 orders from users_2021, add month field; items_2021: Inventory items created in 2021 with pricing and categories; order_details: Join orders_2021, order_items, items_2021 and calculate retail_minus_cost profit per item; monthly_metrics: Aggregate by month, country, department, category deriving order count, unique purchasers, total profit","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:14:05
sf_bq272,"Please provide the names of the top three most profitable products for each month from January 2019 through August 2022, excluding any products associated with orders that were canceled or returned. For each product in each month, the profit should be calculated as the sum of the sale prices of all order items minus the sum of the costs of those sold items in that month.",false,false,true,true,false,azure/o3,,"date_filtered_orders: Orders Jan 2019–Aug 2022 with non-canceled status; clean_order_items: Items from filtered orders excluding returns and canceled statuses; items_with_cost: clean_order_items joined to inventory_items to append item cost; monthly_profit: Sum profit (sale_price minus cost) per product per month; top_monthly_products: Rank products by monthly profit and retain top three; final_result: Attach product names and format output ordered by month, profit desc","date_filtered_orders: Orders Jan 2019–Aug 2022 with non-canceled status; clean_order_items: Items from filtered orders excluding returns and canceled statuses; items_with_cost: clean_order_items joined to inventory_items to append item cost; monthly_profit: Sum profit (sale_price minus cost) per product per month; top_monthly_products: Rank products by monthly profit and retain top three; final_result: Attach product names and format output ordered by month, profit desc","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:14:24
sf_bq273,"Can you list the top 5 months from August 2022 to November 2023 where the profit from Facebook-sourced completed orders showed the largest month-over-month increase? Calculate profit as sales minus costs, group by delivery month, and include only orders created between August 2022 and November 2023. Compare each month's profit to its previous month to find the largest increases.",false,false,true,true,false,azure/o3,,"filtered_fb_orders: Filter completed orders created between Aug 2022–Nov 2023, delivered, and linked to users with Facebook traffic_source; order_level_profit: Join filtered_fb_orders to order_items and inventory_items; calculate profit per order as sum(sale_price - cost); monthly_profit: Aggregate order_level_profit by delivered month; return monthly_profit value; mom_profit_change: Compute month-over-month profit change using LAG over monthly_profit; top5_growth_months: Select top 5 months with largest positive MoM profit increase","filtered_fb_orders: Filter completed orders created between Aug 2022–Nov 2023, delivered, and linked to users with Facebook traffic_source; order_level_profit: Join filtered_fb_orders to order_items and inventory_items; calculate profit per order as sum(sale_price - cost); monthly_profit: Aggregate order_level_profit by delivered month; return monthly_profit value; mom_profit_change: Compute month-over-month profit change using LAG over monthly_profit; top5_growth_months: Select top 5 months with largest positive MoM profit increase","{""target_db"": ""THELOOK_ECOMMERCE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:14:48
sf_bq020,What is the name of the reference sequence with the highest variant density in the given cannabis genome dataset?,false,false,true,true,false,azure/o3,,valid_variants: select variants where filter='PASS' to ensure high-quality; counted_variants: count variants per reference_name; ref_lengths: retrieve length per reference sequence; density_calc: join counts to lengths and compute density; ranked_density: order by density desc and isolate top sequence,valid_variants: select variants where filter='PASS' to ensure high-quality; counted_variants: count variants per reference_name; ref_lengths: retrieve length per reference sequence; density_calc: join counts to lengths and compute density; ranked_density: order by density desc and isolate top sequence,"{""target_db"": ""GENOMICS_CANNABIS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:15:06
sf_bq107,What is the variant density of the cannabis reference with the longest reference length? Pay attention that a variant is present if there is at least one variant call with a genotype greater than 0.,false,false,true,true,false,azure/o3,,reference_lengths: Retrieve each reference_name and its length; longest_reference: Identify reference with the greatest length; informative_variants: Select distinct variant positions on longest reference with genotype greater than 0; density_calc: Aggregate variant count and calculate variants per base length,reference_lengths: Retrieve each reference_name and its length; longest_reference: Identify reference with the greatest length; informative_variants: Select distinct variant positions on longest reference with genotype greater than 0; density_calc: Aggregate variant count and calculate variants per base length,"{""target_db"": ""GENOMICS_CANNABIS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:15:16
sf_bq084,"For each month in the year 2023, how many total transactions occurred (counting all transaction records without removing duplicates of transaction hashes), and how many transactions per second were processed each month, where the transactions-per-second value is calculated by dividing the monthly total count by the exact number of seconds in that month, including the correct leap-year logic if applicable based on the extracted year from the transaction timestamp? Show the monthly transaction count, the computed transactions per second, the year, and the month, and present the rows in descending order of the monthly transaction count.",false,false,true,true,false,azure/o3,,base_2023_tx: Transactions in 2023 with timestamps for counting; month_counts: Aggregate base_2023_tx by year-month to get tx_count; month_seconds: List each 2023 month with precise seconds between month start and next; monthly_metrics: Join counts and seconds to calculate tps and prepare final ordered output,base_2023_tx: Transactions in 2023 with timestamps for counting; month_counts: Aggregate base_2023_tx by year-month to get tx_count; month_seconds: List each 2023 month with precise seconds between month start and next; monthly_metrics: Join counts and seconds to calculate tps and prepare final ordered output,"{""target_db"": ""GOOG_BLOCKCHAIN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:15:27
sf_bq058,"Retrieve all finalized deposits into Optimism at block 29815485 using the Optimism Standard Bridge, including transaction hash, an Etherscan link (the complete URL), L1 and L2 token addresses, sender and receiver addresses (with leading zeroes stripped), and the deposited amount (converted from hex to decimal). Ensure data is properly formatted and parsed according to Optimism's address and token standards, and remove the prefix '0x' except transaction hash. Note that, the keccak-256 hash of the Ethereum event signature for DepositFinalized is ""0x3303facd24627943a92e9dc87cfbb34b15c49b726eec3ad3487c16be9ab8efe8"".",false,false,true,true,true,azure/o3,,"deposit_logs: filter DECODED_EVENTS for DepositFinalized hash at block 29815485; parsed_args: extract l1_token, l2_token, from_addr, to_addr, amount_hex, tx_hash from ARGS; cleaned_values: convert amount_hex to decimal, strip 0x and leading zeros from addresses, lowercase; add_tx_link: build full etherscan URL, retain 0x tx_hash; final_result: assemble requested columns, deduplicate, order by log_index","deposit_logs: filter DECODED_EVENTS for DepositFinalized hash at block 29815485; parsed_args: extract l1_token, l2_token, from_addr, to_addr, amount_hex, tx_hash from ARGS; cleaned_values: convert amount_hex to decimal, strip 0x and leading zeros from addresses, lowercase; add_tx_link: build full etherscan URL, retain 0x tx_hash; final_result: assemble requested columns, deduplicate, order by log_index","{""target_db"": ""GOOG_BLOCKCHAIN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:15:41
sf_bq416,"Could you retrieve the top three largest USDT transfers on the TRON blockchain by listing the block numbers, source addresses, destination addresses (in TronLink format), and transfer amounts, using the USDT contract address '0xa614f803b6fd780986a42c78ec9c7f77e6ded13c' and the transfer event signature '0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef', dividing the raw transfer value by 1,000,000 to convert it into the final USDT amount, and then ordering the results by the largest transferred amounts first?",false,false,true,true,true,azure/o3,,"usdt_transfer_logs: filter LOGS for USDT contract and transfer signature; decoded_transfers: extract from_address, to_address, raw_amount, block_number from topics and data; formatted_transfers: convert addresses to TronLink format and divide raw_amount by 1e6; top_transfers: rank by amount desc and limit to top three transfers","usdt_transfer_logs: filter LOGS for USDT contract and transfer signature; decoded_transfers: extract from_address, to_address, raw_amount, block_number from topics and data; formatted_transfers: convert addresses to TronLink format and divide raw_amount by 1e6; top_transfers: rank by amount desc and limit to top three transfers","{""target_db"": ""GOOG_BLOCKCHAIN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:15:50
sf_bq226,"Which sender address, represented as a complete URL on https://cronoscan.com, has been used most frequently on the Cronos blockchain in transactions to non-null 'to_address' fields, within blocks larger than 4096 bytes, since January 1, 2023?",false,false,true,true,false,azure/o3,,large_blocks: Select block_hash for blocks larger than 4096 bytes; tx_2023: Transactions since 2023-01-01 with non-null to_address; eligible_tx: Join tx_2023 with large_blocks to retain transactions in big blocks; sender_counts: Aggregate eligible_tx to count transactions per from_address; sender_urls_ranked: Build cronoscan URL for each sender and sort by descending count,large_blocks: Select block_hash for blocks larger than 4096 bytes; tx_2023: Transactions since 2023-01-01 with non-null to_address; eligible_tx: Join tx_2023 with large_blocks to retain transactions in big blocks; sender_counts: Aggregate eligible_tx to count transactions per from_address; sender_urls_ranked: Build cronoscan URL for each sender and sort by descending count,"{""target_db"": ""GOOG_BLOCKCHAIN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:16:05
sf_bq016,"Considering only the highest release versions of NPM packages, which dependency (package and its version) appears most frequently among the dependencies of these packages?",false,false,true,true,false,azure/o3,,latest_releases: filter PACKAGE_RELEASES to is_latest=true for each package; dependencies_latest: join latest releases to PACKAGE_DEPENDENCIES to list deps of current versions; dependency_usage: aggregate dependencies to count occurrence across latest packages; top_dependency: pick dependency_name and dependency_version with highest usage count,latest_releases: filter PACKAGE_RELEASES to is_latest=true for each package; dependencies_latest: join latest releases to PACKAGE_DEPENDENCIES to list deps of current versions; dependency_usage: aggregate dependencies to count occurrence across latest packages; top_dependency: pick dependency_name and dependency_version with highest usage count,"{""target_db"": ""DEPS_DEV_V1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:16:18
sf_bq062,What is the most frequently used license by packages in each system?,false,false,true,true,false,azure/o3,,pkg_license_map: Extract system and license identifiers for each package; license_usage_counts: Aggregate package counts per system and license; ranked_licenses: Assign row_number within each system ordered by descending package_count; top_license_per_system: Select rank 1 rows as each system’s most used license,pkg_license_map: Extract system and license identifiers for each package; license_usage_counts: Aggregate package counts per system and license; ranked_licenses: Assign row_number within each system ordered by descending package_count; top_license_per_system: Select rank 1 rows as each system’s most used license,"{""target_db"": ""DEPS_DEV_V1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:16:24
sf_bq063,"Find the GitHub URL (with link label 'SOURCE_REPO') of the latest released version of the NPM package that has the highest number of dependencies in its latest released version, excluding packages whose names contain the character '@' and only considering URLs where the link label is 'SOURCE_REPO' and the URL contains 'github.com'.",false,false,true,true,false,azure/o3,,"latest_pkg_versions: select latest version per package without '@', keeping dependencies_count and release date; max_dep_pkg: choose package(s) whose latest version has highest dependencies_count; github_links: filter links where link_label='SOURCE_REPO' and url contains 'github.com'; final_result: join max_dep_pkg with github_links to return desired GitHub URL","latest_pkg_versions: select latest version per package without '@', keeping dependencies_count and release date; max_dep_pkg: choose package(s) whose latest version has highest dependencies_count; github_links: filter links where link_label='SOURCE_REPO' and url contains 'github.com'; final_result: join max_dep_pkg with github_links to return desired GitHub URL","{""target_db"": ""DEPS_DEV_V1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:16:32
sf_bq028,"Considering only the latest release versions of NPM package, which packages are the top 8 most popular based on the Github star number, as well as their versions?",false,false,true,true,false,azure/o3,,"latest_release_dates: max release_date per package to locate latest versions; latest_releases: filter releases to latest date, retaining package and version; package_stats: join packages with latest_releases to pair github_stars and versions; top8_packages: select top 8 packages by github_stars descending with corresponding latest version","latest_release_dates: max release_date per package to locate latest versions; latest_releases: filter releases to latest date, retaining package and version; package_stats: join packages with latest_releases to pair github_stars and versions; top8_packages: select top 8 packages by github_stars descending with corresponding latest version","{""target_db"": ""DEPS_DEV_V1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:16:40
sf_bq325,"Please identify the top 10 genes with the strongest associations across all studies by first selecting, for each gene within each study, the variant with the lowest p-value, and then ranking all such gene–variant pairs to return the 10 genes with the smallest p-values overall.",false,false,true,true,false,azure/o3,,"raw_variants: select gene, study, variant identifiers and pval from disease_variant_gene; min_variant_by_study_gene: retain lowest p-value variant per gene within each study; gene_best_variant: choose minimal p-value record per gene across all studies; top_genes: order by pval ascending and limit to 10 genes","raw_variants: select gene, study, variant identifiers and pval from disease_variant_gene; min_variant_by_study_gene: retain lowest p-value variant per gene within each study; gene_best_variant: choose minimal p-value record per gene across all studies; top_genes: order by pval ascending and limit to 10 genes","{""target_db"": ""OPEN_TARGETS_GENETICS_2"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:17:13
sf_bq276,"Can you provide a comprehensive list of all ports in region number 6585 that lie within U.S. state boundaries and have been affected by named storms in the North Atlantic basin with wind speeds of at least 35 knots and a Saffir-Simpson classification of at least minimal tropical storm strength, including for each port its name, the state name, the distinct years in which storms occurred, the total count of distinct storms, the distinct storm names, the average storm category, the average wind speed, and the respective geometries for both the port and the tropical storm areas?",false,false,true,true,true,azure/o3,,"ports_region: select ports in WORLD_PORT_INDEX where region_number = 6585 with id,name,geom; ports_in_states: keep ports_region whose port_geom ST_WITHIN state_geom, add state_name; storms_filtered: select HURRICANES in North Atlantic with wind ≥35 kt and usa_status ≥ tropical storm; storms_categorized: derive storm_point geometry, map usa_status to numeric category; port_storm_matches: pair ports_in_states with storms_categorized within 50 nm using ST_DISTANCE/nautical_miles_conversion; port_storm_stats: aggregate matches per port compiling distinct seasons, storm count, storm names list, avg category, avg wind, plus port and storm geometries","ports_region: select ports in WORLD_PORT_INDEX where region_number = 6585 with id,name,geom; ports_in_states: keep ports_region whose port_geom ST_WITHIN state_geom, add state_name; storms_filtered: select HURRICANES in North Atlantic with wind ≥35 kt and usa_status ≥ tropical storm; storms_categorized: derive storm_point geometry, map usa_status to numeric category; port_storm_matches: pair ports_in_states with storms_categorized within 50 nm using ST_DISTANCE/nautical_miles_conversion; port_storm_stats: aggregate matches per port compiling distinct seasons, storm count, storm names list, avg category, avg wind, plus port and storm geometries","{""target_db"": ""NOAA_PORTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:17:31
sf_bq104,"Based on the most recent refresh date, identify the top-ranked rising search term for the week that is exactly one year prior to the latest available week in the dataset.",false,false,true,true,false,azure/o3,,combined_terms: Union international and domestic rising term tables into single set; latest_refresh: Max refresh_date from combined_terms; latest_week: Latest week tied to latest_refresh; target_week_terms: Rows where week equals latest_week minus one year and refresh_date = latest_refresh; top_rising_term: Term with rank 1 from target_week_terms,combined_terms: Union international and domestic rising term tables into single set; latest_refresh: Max refresh_date from combined_terms; latest_week: Latest week tied to latest_refresh; target_week_terms: Rows where week equals latest_week minus one year and refresh_date = latest_refresh; top_rising_term: Term with rank 1 from target_week_terms,"{""target_db"": ""GOOGLE_TRENDS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:17:52
sf_bq411,"Please retrieve the top three Google Trends search terms (ranks 1, 2, and 3) from top_terms for each weekday (Monday through Friday) between September 1, 2024, and September 14, 2024, grouped by the refresh_date column and ordered in descending order of refresh_date.",false,false,true,true,false,azure/o3,,date_range_terms: filter rows between 2024-09-01 and 2024-09-14; weekday_terms: keep Monday-Friday based on refresh_date weekday; top_rank_terms: retain rank 1–3 per refresh_date; ordered_results: select required columns and order by refresh_date desc,date_range_terms: filter rows between 2024-09-01 and 2024-09-14; weekday_terms: keep Monday-Friday based on refresh_date weekday; top_rank_terms: retain rank 1–3 per refresh_date; ordered_results: select required columns and order by refresh_date desc,"{""target_db"": ""GOOGLE_TRENDS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:18:04
sf_bq121,"How do the average reputation and number of badges vary among Stack Overflow users based on the number of complete years they have been members, considering only those who joined on or before October 1, 2021?",false,false,true,true,false,azure/o3,,"eligible_users: Users joined on/before 2021-10-01 with membership_years and reputation; badge_counts: Total badges per user_id; user_stats: Merge eligible_users with badge_counts, default zero badges; years_summary: Average reputation and badge_count by membership_years","eligible_users: Users joined on/before 2021-10-01 with membership_years and reputation; badge_counts: Total badges per user_id; user_stats: Merge eligible_users with badge_counts, default zero badges; years_summary: Average reputation and badge_count by membership_years","{""target_db"": ""STACKOVERFLOW"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:18:16
sf_bq307,"Find the top 10 gold badges that users most commonly earn as their first gold badge on Stack Overflow. For each of these badges, display the badge name, the number of users who earned it as their first gold badge, and the average number of days from the user's account creation date to the date they earned the badge, calculated in days without any adjustments for date formats.",false,false,true,true,false,azure/o3,,gold_badges: gold-class badge award records; first_gold_per_user: earliest gold badge date per user; first_gold_events: link earliest gold date back to badge name; badge_user_days: join users to compute days from account creation to badge date; badge_stats: aggregate by badge name for user count and average days; top_badges: top 10 badges by user count descending,gold_badges: gold-class badge award records; first_gold_per_user: earliest gold badge date per user; first_gold_events: link earliest gold date back to badge name; badge_user_days: join users to compute days from account creation to badge date; badge_stats: aggregate by badge name for user count and average days; top_badges: top 10 badges by user count descending,"{""target_db"": ""STACKOVERFLOW"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:18:35
sf_bq458,"Tokenize the body text of each article into words, excluding stop words, and obtain the corresponding word vectors for these words from the glove vector. For each word, weight its word vector by dividing each component by the 0.4th power of the word's frequency from the word frequencies. Then, for each article, aggregate these weighted word vectors by summing their components to form an article vector. Normalize each article vector to unit length by dividing by its magnitude. Finally, retrieve the ID, date, title, and the normalized article vector for each article.",false,false,true,true,false,azure/o3,,"tokenize_body: Split article bodies into lowercase tokens and remove stop words; word_stats: Join tokens with WORD_FREQUENCIES, compute weight 1/(frequency^0.4); weighted_word_vecs: Join tokens with GLOVE_VECTORS, multiply vector by weight; article_vector_sum: Sum weighted vectors per article for raw_article_vector; unit_vectors: Normalize raw_article_vector to unit length; final_output: Select article id, date, title, normalized vector","tokenize_body: Split article bodies into lowercase tokens and remove stop words; word_stats: Join tokens with WORD_FREQUENCIES, compute weight 1/(frequency^0.4); weighted_word_vecs: Join tokens with GLOVE_VECTORS, multiply vector by weight; article_vector_sum: Sum weighted vectors per article for raw_article_vector; unit_vectors: Normalize raw_article_vector to unit length; final_output: Select article id, date, title, normalized vector","{""target_db"": ""WORD_VECTORS_US"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:18:51
sf_bq459,"Please find the top 10 most relevant articles by only processing each article’s 'body' field, where each body is tokenized with no stopwords, each remaining token is turned into a GloVe-based word vector and weighted by dividing each dimension by the 0.4th power of its word frequency, then these weighted vectors are summed and normalized to get a unit vector for each article. Perform the same weighting and normalization on the query phrase 'Epigenetics and cerebral organoids: promising directions in autism spectrum disorders' and compute the cosine similarity between the query vector and each article vector. Finally, return the id, date, title, and the cosine similarity score for the top 10 articles with the highest similarity.",false,false,true,true,false,azure/o3,,"raw_tokens: Split article bodies into lowercase tokens, remove stopwords, output article_id and token; token_weights: Join tokens with word_frequencies and glove_vectors, derive weighted token vectors using frequency^-0.4; article_vectors: Sum weighted token vectors per article, compute L2 norm, store normalized unit vector; query_tokens: Tokenize input query, remove stopwords, output tokens; query_vector: Join query tokens with frequencies and vectors, sum weighted vectors, normalize to unit length; similarities: Dot-product article_vectors with query_vector, rank by similarity, return top 10 id, date, title, score","raw_tokens: Split article bodies into lowercase tokens, remove stopwords, output article_id and token; token_weights: Join tokens with word_frequencies and glove_vectors, derive weighted token vectors using frequency^-0.4; article_vectors: Sum weighted token vectors per article, compute L2 norm, store normalized unit vector; query_tokens: Tokenize input query, remove stopwords, output tokens; query_vector: Join query tokens with frequencies and vectors, sum weighted vectors, normalize to unit length; similarities: Dot-product article_vectors with query_vector, rank by similarity, return top 10 id, date, title, score","{""target_db"": ""WORD_VECTORS_US"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:19:04
sf_bq460,"Please process the articles from the 'nature' dataset by first tokenizing the body text into words and removing stopwords. For each remaining word, retrieve its word vector from the glove_vectors table and its frequency from the word_frequencies table, then divide each word vector by the 0.4th power of the word's frequency to weight it. Sum the weighted vectors to obtain an aggregate vector for each article, normalize this aggregate vector to unit length, and then compute the cosine similarity scores between these normalized vectors. Finally, return the IDs, dates, titles, and cosine similarity scores of the top 10 articles most similar to the article with the ID '8a78ef2d-d5f7-4d2d-9b47-5adb25cbd373'.",false,false,true,true,true,azure/o3,,"article_tokens: tokenize nature article bodies into individual non-stopword words per article; weighted_tokens: join tokens with glove vectors and word frequencies, compute weighted word vectors; aggregated_vectors: sum weighted vectors per article to form raw embedding; normalized_vectors: scale raw embeddings to unit length; target_vector: select normalized vector for article 8a78ef2d-d5f7-4d2d-9b47-5adb25cbd373; similarity_scores: compute cosine similarity between all normalized vectors and target, rank articles, limit top 10","article_tokens: tokenize nature article bodies into individual non-stopword words per article; weighted_tokens: join tokens with glove vectors and word frequencies, compute weighted word vectors; aggregated_vectors: sum weighted vectors per article to form raw embedding; normalized_vectors: scale raw embeddings to unit length; target_vector: select normalized vector for article 8a78ef2d-d5f7-4d2d-9b47-5adb25cbd373; similarity_scores: compute cosine similarity between all normalized vectors and target, rank articles, limit top 10","{""target_db"": ""WORD_VECTORS_US"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:19:22
sf_bq345,"How large are the DICOM image files with SEG or RTSTRUCT modalities and the SOP Class UID ""1.2.840.10008.5.1.4.1.1.66.4"", when grouped by collection, study, and series IDs, if they have no references to other series, images, or sources? Can you also provide a viewer URL formatted as ""https://viewer.imaging.datacommons.cancer.gov/viewer/"" followed by the study ID, and list these sizes in kilobytes, sorted from largest to smallest?",false,false,true,true,false,azure/o3,,"filtered_images: SEG or RTSTRUCT rows with target SOPClassUID from DICOM_PIVOT; referenced_series: SeriesInstanceUIDs in SEGMENTATIONS with any segmented_SeriesInstanceUID; isolated_images: filtered_images excluding referenced_series for reference-free data; size_agg_kb: sum instance_size to kilobytes grouped by collection, study, series; ordered_results: append viewer URL using study ID and sort sizes descending","filtered_images: SEG or RTSTRUCT rows with target SOPClassUID from DICOM_PIVOT; referenced_series: SeriesInstanceUIDs in SEGMENTATIONS with any segmented_SeriesInstanceUID; isolated_images: filtered_images excluding referenced_series for reference-free data; size_agg_kb: sum instance_size to kilobytes grouped by collection, study, series; ordered_results: append viewer URL using study ID and sort sizes descending","{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:19:41
sf_bq346,"In publicly accessible DICOM data where the Modality is 'SEG' and the SOPClassUID is '1.2.840.10008.5.1.4.1.1.66.4', and each segmentation references its original SOPInstanceUID, which five segmentation categories (by 'SegmentedPropertyCategory.CodeMeaning') occur most frequently?",false,false,true,true,false,azure/o3,,filtered_segs: Select DICOM_PIVOT rows where Modality='SEG' and SOPClassUID='1.2.840.10008.5.1.4.1.1.66.4'; seg_links: Join filtered_segs to SEGMENTATIONS on SOPInstanceUID to ensure referenced originals; category_parsed: Extract SegmentedPropertyCategory CodeMeaning for each linked segmentation; category_counts: Group by CodeMeaning and compute segmentation counts; top_five_categories: Retrieve five categories with highest counts for final output,filtered_segs: Select DICOM_PIVOT rows where Modality='SEG' and SOPClassUID='1.2.840.10008.5.1.4.1.1.66.4'; seg_links: Join filtered_segs to SEGMENTATIONS on SOPInstanceUID to ensure referenced originals; category_parsed: Extract SegmentedPropertyCategory CodeMeaning for each linked segmentation; category_counts: Group by CodeMeaning and compute segmentation counts; top_five_categories: Retrieve five categories with highest counts for final output,"{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:20:08
sf_bq347,"From the union of the specified MR series with SeriesInstanceUID 1.3.6.1.4.1.14519.5.2.1.3671.4754.105976129314091491952445656147 and all associated segmentation instances, which modality has the greatest number of SOP instances in total, and how many are there?",false,false,true,true,false,azure/o3,,target_mr_series: Retrieve SOPInstanceUIDs of the specified MR SeriesInstanceUID from DICOM_PIVOT; associated_seg_instances: Retrieve SOPInstanceUIDs from SEGMENTATIONS whose segmented_SeriesInstanceUID matches the target MR series; union_sop_instances: Union distinct SOPInstanceUIDs from MR and segmentation sources to form unified analysis set; modalities_sop_counts: Join union_sop_instances to DICOM_PIVOT for modalities and aggregate SOP counts per modality; top_modality: Select modality with highest SOP count from modalities_sop_counts for final output,target_mr_series: Retrieve SOPInstanceUIDs of the specified MR SeriesInstanceUID from DICOM_PIVOT; associated_seg_instances: Retrieve SOPInstanceUIDs from SEGMENTATIONS whose segmented_SeriesInstanceUID matches the target MR series; union_sop_instances: Union distinct SOPInstanceUIDs from MR and segmentation sources to form unified analysis set; modalities_sop_counts: Join union_sop_instances to DICOM_PIVOT for modalities and aggregate SOP counts per modality; top_modality: Select modality with highest SOP count from modalities_sop_counts for final output,"{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:20:20
sf_bq390,"In the ""qin_prostate_repeatability"" collection, please provide the distinct StudyInstanceUIDs for studies that include T2-weighted axial MR imaging and also contain anatomical structure segmentations labeled as ""Peripheral zone.""",false,false,true,true,false,azure/o3,,"t2_axial_mr_studies: MR DICOM_PIVOT rows in qin_prostate_repeatability with axial T2-weighted SeriesDescription, returning distinct StudyInstanceUIDs; peripheral_zone_studies: SEGMENTATIONS rows labeled 'Peripheral zone', returning distinct StudyInstanceUIDs; matched_studies: Intersect prior CTEs on StudyInstanceUID to produce final study list","t2_axial_mr_studies: MR DICOM_PIVOT rows in qin_prostate_repeatability with axial T2-weighted SeriesDescription, returning distinct StudyInstanceUIDs; peripheral_zone_studies: SEGMENTATIONS rows labeled 'Peripheral zone', returning distinct StudyInstanceUIDs; matched_studies: Intersect prior CTEs on StudyInstanceUID to produce final study list","{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:20:36
sf_bq421,"Can you list all unique pairs of embedding medium and staining substance code meanings, along with the number of occurrences for each pair, based on distinct embedding medium and staining substance codes from the 'SM' modality in the DICOM dataset's un-nested specimen preparation sequences, ensuring that the codes are from the SCT coding scheme?",false,false,true,true,false,azure/o3,,sm_instances: UIDs with modality 'SM' from DICOM_PIVOT; prep_codes: specimen preparation codes for sm_instances filtered to SCT scheme; embed_codes: embedding medium code meanings per UID from prep_codes; stain_codes: staining substance code meanings per UID from prep_codes; instance_pairs: distinct embedding medium–staining substance pairs per UID; pair_counts: count UIDs for each unique pair,sm_instances: UIDs with modality 'SM' from DICOM_PIVOT; prep_codes: specimen preparation codes for sm_instances filtered to SCT scheme; embed_codes: embedding medium code meanings per UID from prep_codes; stain_codes: staining substance code meanings per UID from prep_codes; instance_pairs: distinct embedding medium–staining substance pairs per UID; pair_counts: count UIDs for each unique pair,"{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:20:46
sf_bq422,"Using the 'nlst' collection's CT images, calculate and compare two separate metrics: 1) The average series size in MiB for the top 3 patients with the highest slice interval difference tolerance (defined as the difference between the maximum and minimum unique slice intervals across all their series), and 2) The average series size in MiB for the top 3 patients with the highest exposure difference (defined as the difference between the maximum and minimum unique exposure values across all their series). For each patient, calculate the series size by summing the instance sizes of all images in that series and converting to MiB. Return the results as two separate groups labeled ""Top 3 by Slice Interval"" and ""Top 3 by Max Exposure"" with their respective average series sizes.",false,false,true,true,false,azure/o3,,"filter_nlst_ct: isolate NLST CT instances with slice thickness, exposure and instance size; patient_level_ranges: compute per-patient max-min slice interval and exposure gaps; top3_slice_variance: select three patients with largest slice interval gap; top3_exposure_variance: select three patients with largest exposure gap; series_mib: calculate MiB size per patient series from summed instance_size; avg_series_size_by_group: derive labeled average series size for each top-3 patient set","filter_nlst_ct: isolate NLST CT instances with slice thickness, exposure and instance size; patient_level_ranges: compute per-patient max-min slice interval and exposure gaps; top3_slice_variance: select three patients with largest slice interval gap; top3_exposure_variance: select three patients with largest exposure gap; series_mib: calculate MiB size per patient series from summed instance_size; avg_series_size_by_group: derive labeled average series size for each top-3 patient set","{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:20:54
sf_bq069,"Could you help me generate a report of CT image series from the dicom_all table such that all series from the NLST collection are excluded, any localizers or JPEG-compressed series (transfer syntaxes 1.2.840.10008.1.2.4.70 or 1.2.840.10008.1.2.4.51) are skipped, and only those passing certain geometry checks—namely a single orientation, identical pixel spacing, matching SOP instance and position counts, uniform pixel rows and columns, and a near-unity dot product of image orientation vectors—are included, while also computing slice interval differences, exposure differences, and approximate series size in MB for each qualified series?",false,false,true,true,true,azure/o3,,"eligible_instances: CT instances joined to metadata; exclude NLST collection, localizer images, and forbidden JPEG transfer syntaxes; series_check: aggregate by series, enforce uniform geometry, positions, SOP count match, dot product ~1; slice_stats: compute z-position gaps per series, derive min, max, tolerance, distinct slice thickness count; exposure_stats: calculate distinct exposure count, min, max, range per series; size_totals: sum instance_size per series and convert to MiB; final_report: join metadata with all stats for qualified series, output requested fields, order by slice tolerance, exposure range, series id desc","eligible_instances: CT instances joined to metadata; exclude NLST collection, localizer images, and forbidden JPEG transfer syntaxes; series_check: aggregate by series, enforce uniform geometry, positions, SOP count match, dot product ~1; slice_stats: compute z-position gaps per series, derive min, max, tolerance, distinct slice thickness count; exposure_stats: calculate distinct exposure count, min, max, range per series; size_totals: sum instance_size per series and convert to MiB; final_report: join metadata with all stats for qualified series, output requested fields, order by slice tolerance, exposure range, series id desc","{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:21:12
sf_bq219,"In the Iowa Liquor Sales dataset, starting from January 1, 2022 through the last fully completed month, which two liquor categories, each contributing an average of at least 1% to the monthly sales volume over at least 24 months of available data, have the lowest Pearson correlation coefficient when comparing their monthly percentages of total liquor sales across those months, and what are their names?",false,false,true,true,false,azure/o3,,filtered_sales: Sales on or after 2022-01-01 through last fully completed month; monthly_totals: Aggregate monthly volume per category and overall monthly total; monthly_shares: Compute each category's percentage of total monthly volume; qualified_categories: Filter to categories with ≥24 months and ≥1% average monthly share; share_series: Assemble month-aligned share array for every qualified category; category_pairs: Generate unique category pairs from qualified list; pair_correlations: Calculate Pearson correlation per pair and select lowest coefficient,filtered_sales: Sales on or after 2022-01-01 through last fully completed month; monthly_totals: Aggregate monthly volume per category and overall monthly total; monthly_shares: Compute each category's percentage of total monthly volume; qualified_categories: Filter to categories with ≥24 months and ≥1% average monthly share; share_series: Assemble month-aligned share array for every qualified category; category_pairs: Generate unique category pairs from qualified list; pair_correlations: Calculate Pearson correlation per pair and select lowest coefficient,"{""target_db"": ""IOWA_LIQUOR_SALES"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:21:32
sf_bq044,"For bladder cancer patients who have mutations in the CDKN2A (cyclin-dependent kinase inhibitor 2A) gene, using clinical data from the Genomic Data Commons Release 39, what types of mutations are they, what is their gender, vital status, and days to death - and for four downstream genes (MDM2 (MDM2 proto-oncogene), TP53 (tumor protein p53), CDKN1A (cyclin-dependent kinase inhibitor 1A), and CCNE1 (Cyclin E1)), what are the gene expression levels for each patient?",false,false,true,true,true,azure/o3,,"bladder_clinical: Filter clinical table to BLCA cases, keeping case_id, gender, vital_status, days_to_death; cdkn2a_mutations: Select CDKN2A mutations with case_id and mutation_type; bladder_cdkn2a_patients: Join bladder_clinical with cdkn2a_mutations to retain affected patients; downstream_expression: Fetch expression levels for MDM2, TP53, CDKN1A, CCNE1 for these case_ids; final_dataset: Combine clinical, mutation type, and gene expression per patient for output","bladder_clinical: Filter clinical table to BLCA cases, keeping case_id, gender, vital_status, days_to_death; cdkn2a_mutations: Select CDKN2A mutations with case_id and mutation_type; bladder_cdkn2a_patients: Join bladder_clinical with cdkn2a_mutations to retain affected patients; downstream_expression: Fetch expression levels for MDM2, TP53, CDKN1A, CCNE1 for these case_ids; final_dataset: Combine clinical, mutation type, and gene expression per patient for output","{""target_db"": ""TCGA"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:21:47
sf_bq043,"What are the RNA expression levels of the genes MDM2, TP53, CDKN1A, and CCNE1, along with associated clinical information, in bladder cancer patients with CDKN2A mutations in the 'TCGA-BLCA' project?  Use clinical data from the Genomic Data Commons Release 39, data about somatic mutations derived from the hg19 human genome reference in Feb 2017.",false,false,true,true,false,azure/o3,,"cdkn2a_mutated_cases: Select TCGA-BLCA case_ids having CDKN2A somatic mutations from hg19 Feb2017 dataset; target_gene_expression: Fetch RNA expression for MDM2, TP53, CDKN1A, CCNE1 in TCGA-BLCA; expression_pivot: Pivot expressions to wide format per case; clinical_info: Extract age, gender, race, pathologic_stage for TCGA-BLCA from GDC Release39 clinical; combined_result: Join expression_pivot with clinical_info restricted to cdkn2a_mutated_cases","cdkn2a_mutated_cases: Select TCGA-BLCA case_ids having CDKN2A somatic mutations from hg19 Feb2017 dataset; target_gene_expression: Fetch RNA expression for MDM2, TP53, CDKN1A, CCNE1 in TCGA-BLCA; expression_pivot: Pivot expressions to wide format per case; clinical_info: Extract age, gender, race, pathologic_stage for TCGA-BLCA from GDC Release39 clinical; combined_result: Join expression_pivot with clinical_info restricted to cdkn2a_mutated_cases","{""target_db"": ""TCGA"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:22:07
sf_bq147,"Can you identify the TCGA breast cancer cases from the RNA sequencing hg38 r35` where the protein_coding gene and the project TCGA-BRCA, and which have RNA sequencing samples of multiple tissue types—including ""Solid Tissue Normal""—within the same case?",false,false,true,true,false,azure/o3,,filtered_metadata: TCGA-BRCA RNA-Seq sample metadata from hg38 r38 table; case_tissue_summary: aggregate distinct sample_type_name and counts per case; qualified_cases: retain cases with ≥2 tissue types including 'Solid Tissue Normal'; final_output: list distinct case barcodes and GDC IDs satisfying requirements,filtered_metadata: TCGA-BRCA RNA-Seq sample metadata from hg38 r38 table; case_tissue_summary: aggregate distinct sample_type_name and counts per case; qualified_cases: retain cases with ≥2 tissue types including 'Solid Tissue Normal'; final_output: list distinct case barcodes and GDC IDs satisfying requirements,"{""target_db"": ""TCGA"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:22:23
sf_bq148,Could you identify the top five protein-coding genes that exhibit the highest variance in their expression levels (measured as fpkm_uq_unstranded) specifically within 'Solid Tissue Normal' samples? Please limit the analysis to TCGA-BRCA project cases that include at least one 'Solid Tissue Normal' sample type.,false,false,true,true,false,azure/o3,,brca_cases: TCGA-BRCA cases having at least one 'Solid Tissue Normal' sample; normal_samples: Solid Tissue Normal sample IDs linked to selected cases; protein_coding_expr: Expression values (fpkm_uq_unstranded) for protein-coding genes in selected normal samples; gene_variances: Variance of expression per gene across all selected normal samples; top5_genes: Top five genes ordered by highest variance,brca_cases: TCGA-BRCA cases having at least one 'Solid Tissue Normal' sample; normal_samples: Solid Tissue Normal sample IDs linked to selected cases; protein_coding_expr: Expression values (fpkm_uq_unstranded) for protein-coding genes in selected normal samples; gene_variances: Variance of expression per gene across all selected normal samples; top5_genes: Top five genes ordered by highest variance,"{""target_db"": ""TCGA"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:22:32
sf_bq175,"Identify cytoband names on chromosome 1 in the TCGA-KIRC segment allelic dataset where the frequency of amplifications, gains, and heterozygous deletions each rank within the top 11. Calculate these rankings based on the maximum copy number observed across various genomic studies of kidney cancer, reflecting the severity of genetic alterations.",false,false,true,true,true,azure/o3,,"cyto_chr1: chromosome 1 cytoband names with hg38 start/stop; kirc_segments: TCGA-KIRC segment allelic rows for chromosome 1 with coordinates and copy_number; mapped_cnv: join segments to cytobands using positional overlap; event_counts: classify copy_number into amplification/gain/het_del and count events per cytoband; top11_per_type: rank cytobands by event counts within each event_type, keeping top 11; intersect_top: select cytobands appearing in the top-11 lists of all three event_types","cyto_chr1: chromosome 1 cytoband names with hg38 start/stop; kirc_segments: TCGA-KIRC segment allelic rows for chromosome 1 with coordinates and copy_number; mapped_cnv: join segments to cytobands using positional overlap; event_counts: classify copy_number into amplification/gain/het_del and count events per cytoband; top11_per_type: rank cytobands by event counts within each event_type, keeping top 11; intersect_top: select cytobands appearing in the top-11 lists of all three event_types","{""target_db"": ""TCGA_MITELMAN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:22:52
sf_bq176,"Identify the case barcodes from the TCGA-LAML study with the highest weighted average copy number in cytoband 15q11 on chromosome 15, using segment data and cytoband overlaps from TCGA's genomic and Mitelman databases.",false,false,true,true,false,azure/o3,,"cytoband_15q11: Retrieve chr15 15q11 start and end positions from cytoband table; laml_cases: Collect TCGA-LAML case and sample barcodes from metadata; laml_segments_15: Fetch copy-number segments on chr15 for LAML samples; overlap_segments: Join segments to 15q11 coordinates, computing overlap length; case_weighted_cn: Calculate per-case overlap-length-weighted average copy number; top_cn_cases: Identify case barcodes with highest weighted average value","cytoband_15q11: Retrieve chr15 15q11 start and end positions from cytoband table; laml_cases: Collect TCGA-LAML case and sample barcodes from metadata; laml_segments_15: Fetch copy-number segments on chr15 for LAML samples; overlap_segments: Join segments to 15q11 coordinates, computing overlap length; case_weighted_cn: Calculate per-case overlap-length-weighted average copy number; top_cn_cases: Identify case barcodes with highest weighted average value","{""target_db"": ""TCGA_MITELMAN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:23:14
sf_bq170,"For breast cancer cases (TCGA-BRCA) from Release 23 of the active GDC archive, identify and categorize copy number variations (CNVs) across all cytobands on every chromosome. For each cytoband and each case, determine the overlap between the cytoband region and the case's copy number segments, and compute the overlap-weighted average copy number for that cytoband in the case, rounding to the nearest whole number. Classify the rounded copy number into CNV types as follows: homozygous deletions (0), heterozygous deletions (1), normal diploid state (2), gains (3), and amplifications (greater than 3). For each cytoband, provide its name and start/end positions, and calculate the frequency of each CNV type across all cases as a percentage of the total number of cases, rounded to two decimal places.",false,false,true,true,true,azure/o3,,"brca_cases: select TCGA-BRCA case_ids from GDC Release 23 clinical data; brca_segments: copy-number segments for brca_cases with chromosome,start,end,copy_value; cytoband_ref: cytoband names with chromosome,hg38_start,hg38_end coordinates; band_overlap: join segments to cytobands on overlap, compute bp_overlap and copy_overlap_product; band_weighted_cn: derive weighted average copy number per case+cytoband, rounded; band_cnv_class: assign CNV category from rounded copy number; cnv_frequency: compute percent frequency of each CNV class per cytoband across brca_cases","brca_cases: select TCGA-BRCA case_ids from GDC Release 23 clinical data; brca_segments: copy-number segments for brca_cases with chromosome,start,end,copy_value; cytoband_ref: cytoband names with chromosome,hg38_start,hg38_end coordinates; band_overlap: join segments to cytobands on overlap, compute bp_overlap and copy_overlap_product; band_weighted_cn: derive weighted average copy number per case+cytoband, rounded; band_cnv_class: assign CNV category from rounded copy number; cnv_frequency: compute percent frequency of each CNV class per cytoband across brca_cases","{""target_db"": ""TCGA_MITELMAN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:23:29
sf_bq150,"Assess whether different genetic variants affect the log10-transformed TP53 expression levels in TCGA-BRCA samples using sequencing and mutation data. Provide the total number of samples, the number of mutation types, the mean square between groups, the mean square within groups, and the F-statistic.",false,false,true,true,true,azure/o3,,"tp53_expr: Select TP53 expression in TCGA-BRCA; filter positive counts; compute log10_expression per sample; tp53_mut: Retrieve TP53 mutation records for TCGA-BRCA; assign primary variant_classification per sample; expr_mut: Inner join tp53_expr and tp53_mut on case_barcode; keep samples with both data; group_stats: Compute sample_count and mean_log_expr per variant; derive overall_grand_mean; sumsq_parts: Calculate SSB, SSW, df_between, df_within using group_stats and expr_mut; anova_metrics: Compute MS_between, MS_within, F_stat, total_samples, variant_count for final report","tp53_expr: Select TP53 expression in TCGA-BRCA; filter positive counts; compute log10_expression per sample; tp53_mut: Retrieve TP53 mutation records for TCGA-BRCA; assign primary variant_classification per sample; expr_mut: Inner join tp53_expr and tp53_mut on case_barcode; keep samples with both data; group_stats: Compute sample_count and mean_log_expr per variant; derive overall_grand_mean; sumsq_parts: Calculate SSB, SSW, df_between, df_within using group_stats and expr_mut; anova_metrics: Compute MS_between, MS_within, F_stat, total_samples, variant_count for final report","{""target_db"": ""TCGA_HG19_DATA_V0"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:23:41
sf_bq152,"For breast cancer cases (TCGA-BRCA) from Release 23 of the active GDC archive, identify and categorize copy number variations (CNVs) across all cytobands on every chromosome. For each cytoband and each case, determine the overlap between the cytoband region and the case's copy number segments, and compute the overlap-weighted average copy number for that cytoband in the case, rounding to the nearest whole number. Classify the rounded copy number into CNV types as follows: homozygous deletions (0), heterozygous deletions (1), normal diploid state (2), gains (3), and amplifications (greater than 3). For each cytoband, provide its name and start/end positions, and calculate the frequency of each CNV type across all cases as a percentage of the total number of cases, rounded to two decimal places.",false,false,true,true,false,azure/o3,,"filtered_segments: Filter COPY_NUMBER_SEGMENT_MASKED for TCGA-BRCA Release 23; select case_barcode, chromosome, start_pos, end_pos, segment_mean; cytobands: Extract chromosome, start, end, cytoband_name from reference cytoband table; segment_cytoband_overlap: Calculate overlap_length between each filtered segment and cytoband interval; cytoband_weighted_cn: Derive overlap-weighted average segment_mean per case+cytoband; round to nearest integer; classified_cnv: Translate rounded copy number into CNV category 0–4 per case+cytoband; total_cases: Determine total distinct TCGA-BRCA cases in dataset; cnv_frequency: Aggregate classified_cnv by cytoband and category; compute percentage of total_cases; include cytoband coordinates","filtered_segments: Filter COPY_NUMBER_SEGMENT_MASKED for TCGA-BRCA Release 23; select case_barcode, chromosome, start_pos, end_pos, segment_mean; cytobands: Extract chromosome, start, end, cytoband_name from reference cytoband table; segment_cytoband_overlap: Calculate overlap_length between each filtered segment and cytoband interval; cytoband_weighted_cn: Derive overlap-weighted average segment_mean per case+cytoband; round to nearest integer; classified_cnv: Translate rounded copy number into CNV category 0–4 per case+cytoband; total_cases: Determine total distinct TCGA-BRCA cases in dataset; cnv_frequency: Aggregate classified_cnv by cytoband and category; compute percentage of total_cases; include cytoband coordinates","{""target_db"": ""TCGA_HG38_DATA_V0"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:23:56
sf_bq155,"In the TCGA-BRCA cohort of patients who are 80 years old or younger at diagnosis and have a pathological stage of Stage I, Stage II, or Stage IIA, calculate the t-statistic derived from the Pearson correlation between the log10-transformed average RNA-Seq expression levels (using HTSeq__Counts + 1) of the gene SNORA31 and the average microRNA-Seq expression levels of all unique microRNAs, only considering pairs with more than 25 samples and where the absolute Pearson correlation coefficient is between 0.3 and 1.0",false,false,true,true,false,azure/o3,,"eligible_cases: BRCA case_barcodes with age_at_diagnosis ≤80 and pathologic_stage in Stage I, Stage II, Stage IIA; snora31_expr: Log10‐transformed mean HTSeq__Counts+1 for gene SNORA31 per eligible case; mirna_case_avg: Average reads_per_million_miRNA_mapped per microRNA per eligible case; paired_expr: Combine SNORA31 and microRNA expression for each case to build analysis matrix; corr_stats: Calculate Pearson correlation coefficient and sample count per microRNA across cases; filtered_stats: Keep microRNAs with samples>25 and |r| between 0.3–1; compute corresponding t-statistic","eligible_cases: BRCA case_barcodes with age_at_diagnosis ≤80 and pathologic_stage in Stage I, Stage II, Stage IIA; snora31_expr: Log10‐transformed mean HTSeq__Counts+1 for gene SNORA31 per eligible case; mirna_case_avg: Average reads_per_million_miRNA_mapped per microRNA per eligible case; paired_expr: Combine SNORA31 and microRNA expression for each case to build analysis matrix; corr_stats: Calculate Pearson correlation coefficient and sample count per microRNA across cases; filtered_stats: Keep microRNAs with samples>25 and |r| between 0.3–1; compute corresponding t-statistic","{""target_db"": ""TCGA_HG38_DATA_V0"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:24:26
sf_bq141,"Using the TCGA-KIRP dataset, select patients from the 'TCGA_bioclin_v0.Clinical' table who have a non-null clinical_stage and a disease_code of 'KIRP.' Retrieve their gene expression data from the 'TCGA_hg38_data_v0.RNAseq_Gene_Expression' table for the genes 'MT-CO3,' 'MT-CO1,' and 'MT-CO2,' and randomly split the patients into a training set (90%) and a test set (10%) based on their case_barcode via the FARM_FINGERPRINT method. For each clinical stage in the training set, calculate the average HTSeq__FPKM_UQ expression of the three genes. For each patient in the test set, compute the Euclidean distance between the patient’s expression values and the stage-specific averages, and assign that patient to the clinical stage whose average is closest. Finally, output the case_barcode and the predicted clinical stage.",false,false,true,true,false,azure/o3,,"kirp_patients: Patients with disease_code='KIRP' and non-null clinical_stage; selected_expr: Expression rows for kirp_patients and genes MT-CO1, MT-CO2, MT-CO3; expr_wide: Pivot selected_expr to one row per patient with separate gene columns; patient_features: Join kirp_patients with expr_wide to attach expression vectors; split_sets: Assign train or test using FARM_FINGERPRINT(case_barcode) 90/10 split; stage_means: Calculate mean gene expressions per clinical_stage from training data; predictions: For each test patient compute Euclidean distances to stage_means and choose closest stage","kirp_patients: Patients with disease_code='KIRP' and non-null clinical_stage; selected_expr: Expression rows for kirp_patients and genes MT-CO1, MT-CO2, MT-CO3; expr_wide: Pivot selected_expr to one row per patient with separate gene columns; patient_features: Join kirp_patients with expr_wide to attach expression vectors; split_sets: Assign train or test using FARM_FINGERPRINT(case_barcode) 90/10 split; stage_means: Calculate mean gene expressions per clinical_stage from training data; predictions: For each test patient compute Euclidean distances to stage_means and choose closest stage","{""target_db"": ""TCGA_HG38_DATA_V0"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:24:42
sf_bq153,"Calculate, for each histology type specified in the 'icd_o_3_histology' field (excluding those enclosed in square brackets), the average of the per-patient average log10(normalized_count + 1) expression levels of the IGF2 gene among LGG patients with valid IGF2 expression data. Match gene expression and clinical data using the ParticipantBarcode field.",false,false,true,true,false,azure/o3,,lgg_clinical: LGG patients with non-bracketed icd_o_3_histology and valid ParticipantBarcode; igf2_expression: IGF2 expression records with log10(normalized_count+1) value per sample; patient_avg_expr: Average IGF2 log expression per ParticipantBarcode; histology_avg_expr: Mean of patient averages for each icd_o_3_histology,lgg_clinical: LGG patients with non-bracketed icd_o_3_histology and valid ParticipantBarcode; igf2_expression: IGF2 expression records with log10(normalized_count+1) value per sample; patient_avg_expr: Average IGF2 log expression per ParticipantBarcode; histology_avg_expr: Mean of patient averages for each icd_o_3_histology,"{""target_db"": ""PANCANCER_ATLAS_1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:24:59
sf_bq154,"Calculate the Kruskal-Wallis H-score among groups of LGG patients for IGF2 gene expression, where each patient’s IGF2 expression is determined by applying log10(normalized_count + 1) and then averaging across samples. Group the patients by ICD-O-3 histology codes, exclude any codes fully enclosed in square brackets, only include groups with more than one patient, and ensure that normalized count is not null. Finally, return the total number of groups, the total number of samples, and the Kruskal-Wallis H-score in descending order.",false,false,true,true,true,azure/o3,,"lgg_clinical: LGG patients with ICD-O-3 histology excluding bracketed codes; igf2_samples: IGF2 sample-level rows with non-null normalized_count; patient_avg_expr: log10(normalized_count+1) averaged per patient; ranked_patient_expr: add overall average rank to each patient’s expression; group_sums: per histology compute n_i, Σr_i, Σr_i², keep n_i>1; final_stats: derive total_groups, total_samples, Kruskal-Wallis H-score","lgg_clinical: LGG patients with ICD-O-3 histology excluding bracketed codes; igf2_samples: IGF2 sample-level rows with non-null normalized_count; patient_avg_expr: log10(normalized_count+1) averaged per patient; ranked_patient_expr: add overall average rank to each patient’s expression; group_sums: per histology compute n_i, Σr_i, Σr_i², keep n_i>1; final_stats: derive total_groups, total_samples, Kruskal-Wallis H-score","{""target_db"": ""PANCANCER_ATLAS_1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:25:14
sf_bq156,"Compute the t-score (rounded to 2 decimals) to compare the difference in mean expression levels of the gene DRG2 between two groups (TP53 mutated vs. non-mutated) in the Lower Grade Glioma (LGG) study, where the expression levels are calculated as the average of log10(normalized_count + 1) for each participant, only considering samples with TP53 mutations that have a 'FILTER' status of 'PASS' in the mutation data, and ignoring any groups with fewer than 10 samples or with zero variance; refer to `t_score.md` for the method of computing the t-score.",false,false,true,true,true,azure/o3,,"lgg_tp53_pass: LGG TP53 mutation participants with FILTER=PASS; drg2_expr: LGG DRG2 expression with log10(normalized_count+1); participant_avg_expr: average DRG2 expression per participant; group_assignment: classify participants as mutated or non_mutated; group_metrics: compute count, mean, variance per group, enforce size≥10 and variance>0; t_score_result: calculate and round Welch t-score between groups","lgg_tp53_pass: LGG TP53 mutation participants with FILTER=PASS; drg2_expr: LGG DRG2 expression with log10(normalized_count+1); participant_avg_expr: average DRG2 expression per participant; group_assignment: classify participants as mutated or non_mutated; group_metrics: compute count, mean, variance per group, enforce size≥10 and variance>0; t_score_result: calculate and round Welch t-score between groups","{""target_db"": ""PANCANCER_ATLAS_1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:25:33
sf_bq157,"Please compute the T-score to determine the statistical difference in the expression of the DRG2 gene between LGG patients with and without TP53 mutation: for each patient, calculate the average of log10(normalized_count + 1) of DRG2 expression across all their samples, using only samples present in the `MC3_MAF_V5_one_per_tumor_sample` table for the LGG study; identify patients with TP53 mutations from this table where `Hugo_Symbol` is 'TP53' and `FILTER` is 'PASS'; then perform a T-test comparing the mean averaged log-transformed DRG2 expression between patients with and without TP53 mutation.",false,false,true,true,true,azure/o3,,tp53_mutations: LGG participant list with 'PASS' TP53 mutations from MC3_MAF; drg2_expression: per LGG participant mean log10(normalized_count+1) DRG2 expression; labeled_expression: join expression with mutation list to flag mutated status; group_stats: compute count mean variance sums per mutation group; t_score: calculate Welch T-score comparing mutated versus non-mutated groups,tp53_mutations: LGG participant list with 'PASS' TP53 mutations from MC3_MAF; drg2_expression: per LGG participant mean log10(normalized_count+1) DRG2 expression; labeled_expression: join expression with mutation list to flag mutated status; group_stats: compute count mean variance sums per mutation group; t_score: calculate Welch T-score comparing mutated versus non-mutated groups,"{""target_db"": ""PANCANCER_ATLAS_1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:25:56
sf_bq158,Which top five histological types of breast cancer (BRCA) in the PanCancer Atlas exhibit the highest percentage of CDH1 gene mutations?,false,false,true,true,false,azure/o3,,"brca_clinical: BRCA patient barcodes with histological subtype from clinical data; cdh1_mut_patients: Distinct BRCA patient barcodes harboring CDH1 mutation; histology_mut_stats: For each histological subtype, count total patients and CDH1-mutated patients, calculate mutation percentage; ranked_histologies: Order subtypes by mutation percentage descending; top_five_histologies: Select top five subtypes for final result","brca_clinical: BRCA patient barcodes with histological subtype from clinical data; cdh1_mut_patients: Distinct BRCA patient barcodes harboring CDH1 mutation; histology_mut_stats: For each histological subtype, count total patients and CDH1-mutated patients, calculate mutation percentage; ranked_histologies: Order subtypes by mutation percentage descending; top_five_histologies: Select top five subtypes for final result","{""target_db"": ""PANCANCER_ATLAS_1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:26:12
sf_bq159,Calculate the chi-square value to assess the association between histological types and the presence of CDH1 gene mutations in BRCA patients using data from the PanCancer Atlas. Focus on patients with known histological types and consider only reliable mutation entries.  Exclude any histological types or mutation statuses with marginal totals less than or equal to 10. Match clinical and mutation data using ParticipantBarcode,false,false,true,true,false,azure/o3,,brca_clin: BRCA patients with non-null histological type and valid ParticipantBarcode; cdh1_mutations: PASS-quality CDH1 mutation entries grouped by ParticipantBarcode; histology_with_status: Join brca_clin to cdh1_mutations flagging mutated vs wildtype per patient; contingency_counts: Count patients by histological_type and mutation_status with row and column totals; filtered_contingency: Keep counts where both row and column totals exceed 10 for chi-square analysis,brca_clin: BRCA patients with non-null histological type and valid ParticipantBarcode; cdh1_mutations: PASS-quality CDH1 mutation entries grouped by ParticipantBarcode; histology_with_status: Join brca_clin to cdh1_mutations flagging mutated vs wildtype per patient; contingency_counts: Count patients by histological_type and mutation_status with row and column totals; filtered_contingency: Keep counts where both row and column totals exceed 10 for chi-square analysis,"{""target_db"": ""PANCANCER_ATLAS_1"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:26:21
sf_bq163,Which 20 genes in the HTAN scRNAseq MSK-SCLC combined samples dataset show the greatest difference in average X_value expression between female and male epithelial cells specifically in cluster 41 of 74-year-old human stage patients? Please calculate the difference by subtracting male average X_value from female average X_value for each gene,false,false,true,true,false,azure/o3,,"filtered_cells: Filter epithelial cells in cluster 41 from 74-year-old human samples; sex_avg: Calculate average X_value per gene and sex within filtered_cells; sex_diff: Join female and male averages per gene, compute female_minus_male difference; top_genes: Select top 20 genes ordered by largest positive difference","filtered_cells: Filter epithelial cells in cluster 41 from 74-year-old human samples; sex_avg: Calculate average X_value per gene and sex within filtered_cells; sex_diff: Join female and male averages per gene, compute female_minus_male difference; top_genes: Select top 20 genes ordered by largest positive difference","{""target_db"": ""HTAN_2"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:26:29
sf_bq164,"Consolidate metadata from spatial transcriptomics and scRNAseq datasets—including levels 1 through 4 and auxiliary files—for the run ID 'HT264P1-S1H2Fc2U1Z1Bs1-H2Bs2-Test'. Include Filename, HTAN Parent Biospecimen ID, Component, File Format, Entity ID, and Run ID.",false,false,true,true,false,azure/o3,,"l1_scrnaseq_metadata: Select required columns from SCRNASEQ_LEVEL1 table for given Run ID; spatial_tx_metadata: Select required columns from spatial transcriptomics metadata tables for given Run ID; aux_files: Gather auxiliary file rows across relevant metadata tables for Run ID; unified_metadata: Standardize column names and UNION ALL metadata from levels 1-4 and auxiliary sets; ordered_output: Deduplicate unified data and sort by Component, Filename","l1_scrnaseq_metadata: Select required columns from SCRNASEQ_LEVEL1 table for given Run ID; spatial_tx_metadata: Select required columns from spatial transcriptomics metadata tables for given Run ID; aux_files: Gather auxiliary file rows across relevant metadata tables for Run ID; unified_metadata: Standardize column names and UNION ALL metadata from levels 1-4 and auxiliary sets; ordered_output: Deduplicate unified data and sort by Component, Filename","{""target_db"": ""HTAN_2"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:26:44
sf_bq166,"Using segment-level copy number data from the copy_number_segment_allelic_hg38_gdc_r23 dataset restricted to 'TCGA-KIRC' samples, merge these segments with the cytogenetic band definitions in 'CytoBands_hg38' to identify each sample’s maximum copy number per cytoband. Classify these maximum copy numbers into amplifications (>3), gains (=3), homozygous deletions (=0), heterozygous deletions (=1), or normal (=2), then calculate the frequency of each subtype out of the total number of distinct cases, and finally present these frequencies as percentages sorted by chromosome and cytoband.",false,false,true,true,true,azure/o3,,"kirc_segments: Filter CNV segments to project_short_name 'TCGA-KIRC', keep chromosome, start_position, end_position, copy_number, case_barcode; segment_band_overlap: Join kirc_segments with cyto_bands on matching chromosome where segment overlaps band genomic coordinates; cytoband_max_copy: Aggregate overlaps to obtain maximum copy_number per case_barcode and cytoband; subtype_classification: Map max copy_number to amplification, gain, normal, heterozygous_deletion, or homozygous_deletion using specified thresholds; subtype_counts: Count distinct cases for each chromosome, cytoband, subtype; total_cases: Capture total number of distinct cases in kirc_segments; frequency_calc: Compute percentage frequency = subtype_counts / total_cases and prepare final output ordered by chromosome and cytoband","kirc_segments: Filter CNV segments to project_short_name 'TCGA-KIRC', keep chromosome, start_position, end_position, copy_number, case_barcode; segment_band_overlap: Join kirc_segments with cyto_bands on matching chromosome where segment overlaps band genomic coordinates; cytoband_max_copy: Aggregate overlaps to obtain maximum copy_number per case_barcode and cytoband; subtype_classification: Map max copy_number to amplification, gain, normal, heterozygous_deletion, or homozygous_deletion using specified thresholds; subtype_counts: Count distinct cases for each chromosome, cytoband, subtype; total_cases: Capture total number of distinct cases in kirc_segments; frequency_calc: Compute percentage frequency = subtype_counts / total_cases and prepare final output ordered by chromosome and cytoband","{""target_db"": ""TCGA_MITELMAN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:27:09
sf_bq415,List the top 10 samples in the genome data that have the highest number of positions where there is exactly one alternate allele and the sample's genotype is homozygous for the reference allele (both alleles are 0). Order the results in descending order of these counts.,false,false,true,true,true,azure/o3,,single_alt_variants: variants with exactly one alternate_bases entry; hom_ref_calls: exploded call rows where genotype is homozygous reference; sample_position_counts: count qualifying positions per sample; top_samples: select top 10 samples by count descending,single_alt_variants: variants with exactly one alternate_bases entry; hom_ref_calls: exploded call rows where genotype is homozygous reference; sample_position_counts: count qualifying positions per sample; top_samples: select top 10 samples by count descending,"{""target_db"": ""HUMAN_GENOME_VARIANTS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:27:24
sf_bq283,"Among all stations that are currently active, identify those that rank in the top 15 (including ties) based on the total number of trips that start at each station. For each of these stations, return the station ID, the total number of starting trips, the percentage of those trips out of the overall starting trips from active stations, and the average trip duration in minutes. Order the results by the station’s rank.",false,false,true,true,false,azure/o3,,"active_stations: filter stations to currently active records; active_station_trips: join trips with active_stations to keep valid starts; station_trip_stats: aggregate per station total trips and average duration_minutes; total_active_trips: compute overall trip count from active stations; ranked_stations: add dense_rank by trip_count, calculate percentage, retain ranks <=15","active_stations: filter stations to currently active records; active_station_trips: join trips with active_stations to keep valid starts; station_trip_stats: aggregate per station total trips and average duration_minutes; total_active_trips: compute overall trip count from active stations; ranked_stations: add dense_rank by trip_count, calculate percentage, retain ranks <=15","{""target_db"": ""AUSTIN"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:27:40
sf_bq412,"Please retrieve the page URLs, first shown time, last shown time, removal reason, violation category, and the lower and upper bounds of times shown for the five most recently removed ads in the Croatia region (region code 'HR'), where the times shown availability date is null, the times shown lower bound exceeds 10,000, the times shown upper bound is below 25,000, and the ads used at least one non-unused audience selection approach among demographics, geographic location, contextual signals, customer lists, or topics of interest, ordering the resulting ads by their last shown time in descending order.",false,false,true,true,false,azure/o3,,"removed_hr: pull removed_creative_stats rows and HR region_stats; stats_parsed: extract first_shown, last_shown, availability_date, times_lower, times_upper from HR stats; valid_audience: keep creative_ids with at least one audience tactic not 'UNUSED'; filtered_ads: join parsed stats with valid_audience, apply availability null and 10k<lower<25k upper; top5_removed: order by last_shown desc, limit 5, select required fields","removed_hr: pull removed_creative_stats rows and HR region_stats; stats_parsed: extract first_shown, last_shown, availability_date, times_lower, times_upper from HR stats; valid_audience: keep creative_ids with at least one audience tactic not 'UNUSED'; filtered_ads: join parsed stats with valid_audience, apply availability null and 10k<lower<25k upper; top5_removed: order by last_shown desc, limit 5, select required fields","{""target_db"": ""GOOGLE_ADS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:27:57
sf_bq423,"Between January 1, 2023, and January 1, 2024, which image-type advertisement on the topic of Health, published by a verified advertiser located in Cyprus, was shown in Croatia, has times_shown_availability_date as NULL (meaning the times shown data is available), utilized demographic information, geo-location targeting, contextual signals, customer lists, and topics of interest without any of these selection methods being unused, and additionally had its first shown date strictly after January 1, 2023, and last shown date strictly before January 1, 2024? Among such ads, provide the page URL of the one with the highest upper bound of times shown.",false,false,true,true,false,azure/o3,,filtered_creatives: filter 2023-window image ads on Health by verified Cyprus advertisers with available times_shown; croatia_shown: unnest region_stats to retain creatives shown in Croatia; targeting_used: keep creatives where all required audience selection methods are marked used; eligible_ads: intersect croatia_shown with targeting_used to list qualified creatives; ranked_ads: rank eligible_ads by upper_bound_times_shown desc; top_ad: select creative_page_url for rank 1,filtered_creatives: filter 2023-window image ads on Health by verified Cyprus advertisers with available times_shown; croatia_shown: unnest region_stats to retain creatives shown in Croatia; targeting_used: keep creatives where all required audience selection methods are marked used; eligible_ads: intersect croatia_shown with targeting_used to list qualified creatives; ranked_ads: rank eligible_ads by upper_bound_times_shown desc; top_ad: select creative_page_url for rank 1,"{""target_db"": ""GOOGLE_ADS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:28:16
sf_bq070,"Could you provide a clean, structured dataset from dicom_all table that only includes SM images marked as VOLUME from the TCGA-LUAD and TCGA-LUSC collections, excluding any slides with compression type “other,” where the specimen preparation step explicitly has “Embedding medium” set to “Tissue freezing medium,” and ensuring that the tissue type is only “normal” or “tumor” and the cancer subtype is reported accordingly?",false,false,true,true,true,azure/o3,,volume_sm_images: Select SM images tagged VOLUME with JPEG/JPEG2000 compression from DICOM tables; tcga_collection: Restrict to slides from TCGA-LUAD or TCGA-LUSC collections; embedding_ok: Filter for specimen embedding medium equal to 'Tissue freezing medium'; tissue_labeled: Keep slides with tissue codes normal/tumor and assign tissue_type label; subtype_labeled: Join clinical data to map project to cancer_subtype luad or lscc; final_ordered: Assemble requested fields and order results by SOPInstanceUID ascending,volume_sm_images: Select SM images tagged VOLUME with JPEG/JPEG2000 compression from DICOM tables; tcga_collection: Restrict to slides from TCGA-LUAD or TCGA-LUSC collections; embedding_ok: Filter for specimen embedding medium equal to 'Tissue freezing medium'; tissue_labeled: Keep slides with tissue codes normal/tumor and assign tissue_type label; subtype_labeled: Join clinical data to map project to cancer_subtype luad or lscc; final_ordered: Assemble requested fields and order results by SOPInstanceUID ascending,"{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:28:31
sf_bq320,"In the dicom_pivot table, how many unique StudyInstanceUID values exactly match the SegmentedPropertyTypeCodeSequence of ""15825003"" (case-insensitive) and also have a collection_id of either ""Community"" or ""nsclc_radiomics""?",false,false,true,true,false,azure/o3,,"filtered_pivot: rows where SegmentedPropertyTypeCodeSequence equals ""15825003"" case-insensitive and collection_id in ('Community','nsclc_radiomics'); distinct_study_uids: unique StudyInstanceUID values from filtered_pivot; study_uid_count: count of distinct StudyInstanceUIDs","filtered_pivot: rows where SegmentedPropertyTypeCodeSequence equals ""15825003"" case-insensitive and collection_id in ('Community','nsclc_radiomics'); distinct_study_uids: unique StudyInstanceUID values from filtered_pivot; study_uid_count: count of distinct StudyInstanceUIDs","{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:28:40
sf_bq321,"How many unique StudyInstanceUIDs are there from the DWI, T2 Weighted Axial, Apparent Diffusion Coefficient series, and T2 Weighted Axial Segmentations in the 'qin_prostate_repeatability' collection?",false,false,true,true,false,azure/o3,,collection_series: Filter DICOM_PIVOT for qin_prostate_repeatability and SeriesDescription in target list; segmentations_filtered: Join SEGMENTATIONS to DICOM_PIVOT to find T2 Weighted Axial segmentations in collection; study_uids: Union distinct StudyInstanceUIDs from collection_series and segmentations_filtered; uid_counts: Count distinct StudyInstanceUIDs in study_uids for final answer,collection_series: Filter DICOM_PIVOT for qin_prostate_repeatability and SeriesDescription in target list; segmentations_filtered: Join SEGMENTATIONS to DICOM_PIVOT to find T2 Weighted Axial segmentations in collection; study_uids: Union distinct StudyInstanceUIDs from collection_series and segmentations_filtered; uid_counts: Count distinct StudyInstanceUIDs in study_uids for final answer,"{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:29:01
sf_bq323,"Within the 'prostatex' collection, for MRI sequences where the Modality is 'MR', assign the label 't2w_prostateX' to sequences whose SeriesDescription contains 't2_tse_tra' and 'adc_prostateX' to sequences whose SeriesDescription contains 'ADC'. For all sequences labeled as 't2w_prostateX' or 'adc_prostateX', calculate the average Repetition Time, the average Echo Time, and the average Slice Thickness, and then compute the sum of these averages to obtain the combined overall average.",false,false,true,true,false,azure/o3,,"prostatex_mr: Filter DICOM_ALL to prostatex collection with Modality='MR', selecting SeriesInstanceUID, SeriesDescription, RepetitionTime, EchoTime; labeled_series: Tag sequences as t2w_prostateX for '%t2_tse_tra%' or adc_prostateX for '%ADC%'; metrics_enriched: Join labeled_series with DICOM_PIVOT via SeriesInstanceUID to append SliceThickness; avg_metrics: Calculate average RepetitionTime, EchoTime, and SliceThickness across labeled sequences; combined_average: Sum the three averages into one combined_overall_average value","prostatex_mr: Filter DICOM_ALL to prostatex collection with Modality='MR', selecting SeriesInstanceUID, SeriesDescription, RepetitionTime, EchoTime; labeled_series: Tag sequences as t2w_prostateX for '%t2_tse_tra%' or adc_prostateX for '%ADC%'; metrics_enriched: Join labeled_series with DICOM_PIVOT via SeriesInstanceUID to append SliceThickness; avg_metrics: Calculate average RepetitionTime, EchoTime, and SliceThickness across labeled sequences; combined_average: Sum the three averages into one combined_overall_average value","{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:29:24
sf_bq417,"Please provide identification details, study and series information, storage location, and total size in MB for the medical images belonging to male patients who are exactly 18 years old based on the numeric portion of the PatientAge field, where the BodyPartExamined is set to 'MEDIASTINUM' and the study date is strictly after September 1, 2014.",false,false,true,true,true,azure/o3,,"parsed_age: Extract numeric years from PatientAge as age_years; filtered_instances: Keep instances where age_years=18, PatientSex='M', BodyPartExamined='MEDIASTINUM', StudyDate>'20140901'; series_totals: Sum instance_size per SeriesInstanceUID to total_size_mb and keep PatientID, StudyInstanceUID; storage_links: Fetch series_aws_url and series_gcs_url from AUXILIARY_METADATA for matching SeriesInstanceUID; final_dataset: Join series_totals with storage_links for identification, study, series, storage locations, total_size_mb","parsed_age: Extract numeric years from PatientAge as age_years; filtered_instances: Keep instances where age_years=18, PatientSex='M', BodyPartExamined='MEDIASTINUM', StudyDate>'20140901'; series_totals: Sum instance_size per SeriesInstanceUID to total_size_mb and keep PatientID, StudyInstanceUID; storage_links: Fetch series_aws_url and series_gcs_url from AUXILIARY_METADATA for matching SeriesInstanceUID; final_dataset: Join series_totals with storage_links for identification, study, series, storage locations, total_size_mb","{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:29:42
sf_bq455,"Identify the top five CT scan series by size (in MiB), including their SeriesInstanceUID, series number, patient ID, and series size. These series must be from the CT modality and not part of the 'nlst' collection. Exclude any series where the ImageType is classified as 'LOCALIZER' or where the TransferSyntaxUID is either '1.2.840.10008.1.2.4.70' or '1.2.840.10008.1.2.4.51' (i.e., JPEG compressed). The selected series must have consistent slice intervals, exposure levels, image orientation (with only one unique ImageOrientationPatient value), pixel spacing, image positions (both z-axis and xy positions), and pixel dimensions (rows and columns). Ensure that the number of images matches the number of unique z-axis positions, indicating no duplicate slices. Additionally, the z-axis component of the cross product of the x and y direction cosines from ImageOrientationPatient must have an absolute value between 0.99 and 1.01, ensuring alignment with the expected imaging plane. Finally, order the results by series size in descending order and limit the output to the top five series satisfying these conditions.",false,false,true,true,false,azure/o3,,"filtered_instances: CT modality instances excluding 'nlst' collection, LOCALIZER images, and compressed TransferSyntaxUIDs; orientation_valid: series from filtered set with single ImageOrientationPatient and |cross_z| 0.99-1.01; pixel_consistent: orientation_valid series having uniform Rows, Columns, PixelSpacing across images; slice_consistent: pixel_consistent series with uniform slice interval and image count equals unique z positions; series_agg: sum instance_size per slice_consistent series, retain PatientID and SeriesNumber, select top five by size","filtered_instances: CT modality instances excluding 'nlst' collection, LOCALIZER images, and compressed TransferSyntaxUIDs; orientation_valid: series from filtered set with single ImageOrientationPatient and |cross_z| 0.99-1.01; pixel_consistent: orientation_valid series having uniform Rows, Columns, PixelSpacing across images; slice_consistent: pixel_consistent series with uniform slice interval and image count equals unique z positions; series_agg: sum instance_size per slice_consistent series, retain PatientID and SeriesNumber, select top five by size","{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:29:58
sf_bq456,"Please retrieve from the dicom_all table each PatientID, StudyInstanceUID, StudyDate, and the CodeMeaning of the FindingSite for patients whose StudyDate is in the year 2001, along with the maximum values of each of the following measurements identified by their CodeMeaning (Elongation, Flatness, Least Axis in 3D Length, Major Axis in 3D Length, Maximum 3D Diameter of a Mesh, Minor Axis in 3D Length, Sphericity, Surface Area of Mesh, Surface to Volume Ratio, Volume from Voxel Summation, and Volume of Mesh), ensuring that the quantitative_measurements table is joined on segmentationInstanceUID matching the SOPInstanceUID in dicom_all, and grouping by PatientID, StudyInstanceUID, StudyDate, and FindingSite CodeMeaning.",false,false,true,true,false,azure/o3,,"studies_2001: Patient and study info from dicom_all where StudyDate in 2001; finding_site_codes: Extract FindingSite CodeMeaning per SOPInstanceUID; filtered_metrics: quantitative_measurements limited to required measurement CodeMeanings; max_metric_values: Maximum Value per segmentationInstanceUID and Quantity; study_metric_join: Join studies_2001, finding_site_codes and max_metric_values on SOPInstanceUID = segmentationInstanceUID; final_agg: Group by PatientID, StudyInstanceUID, StudyDate, FindingSite CodeMeaning returning maximum values per measurement","studies_2001: Patient and study info from dicom_all where StudyDate in 2001; finding_site_codes: Extract FindingSite CodeMeaning per SOPInstanceUID; filtered_metrics: quantitative_measurements limited to required measurement CodeMeanings; max_metric_values: Maximum Value per segmentationInstanceUID and Quantity; study_metric_join: Join studies_2001, finding_site_codes and max_metric_values on SOPInstanceUID = segmentationInstanceUID; final_agg: Group by PatientID, StudyInstanceUID, StudyDate, FindingSite CodeMeaning returning maximum values per measurement","{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:30:56
sf_bq324,How many frames in total are present across all whole slide microscopy images from the TCGA-BRCA collection that use the SM modality and include an eosin-based staining step in their SpecimenPreparationSequence?,false,false,true,true,false,azure/o3,,"tcga_sm_instances: Filter DICOM_PIVOT to TCGA-BRCA collection and modality SM, returning unique SOPInstanceUIDs; stain_steps: Extract and flatten SpecimenPreparationSequence JSON from metadata for each instance, yielding one row per stain name; eosin_instances: Select instances whose stain name ILIKE '%eosin%', ensuring at least one eosin-based step present; instance_frames: Derive frame count for each eosin instance using metadata.ImageDimensions or related frame attributes; total_frames: Sum frame counts across all qualifying instances to produce final total","tcga_sm_instances: Filter DICOM_PIVOT to TCGA-BRCA collection and modality SM, returning unique SOPInstanceUIDs; stain_steps: Extract and flatten SpecimenPreparationSequence JSON from metadata for each instance, yielding one row per stain name; eosin_instances: Select instances whose stain name ILIKE '%eosin%', ensuring at least one eosin-based step present; instance_frames: Derive frame count for each eosin instance using metadata.ImageDimensions or related frame attributes; total_frames: Sum frame counts across all qualifying instances to produce final total","{""target_db"": ""IDC"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:31:24
sf_bq331,"Find the top three users who have authored the first message in forum topics, ranked in descending order by their message scores, where a message score is defined as the number of distinct users who voted on that message. For each of these users, provide their username and the absolute difference between their message score and the average message score across all first messages in forum topics.",false,false,true,true,false,azure/o3,,missing_task: no task details provided,missing_task: no task details provided,"{""target_db"": ""META_KAGGLE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:31:43
sf_bq380,"Using the data from Forum Message Votes and Users tables, find the top three users who have received the most distinct upvotes on the Kaggle forum. For each of these users, list their username, the total number of distinct upvotes they have received (based on the ToUserId field), and the total number of distinct upvotes they have given (based on the FromUserId field), sorted by the number of upvotes received in descending order and restricted to only the top three results.",false,false,true,true,false,azure/o3,,"distinct_votes: Deduplicate ForumMessageVotes to unique From-To user pairs representing one upvote; received_counts: Aggregate distinct_votes to count upvotes received per ToUserId; given_counts: Aggregate distinct_votes to count upvotes given per FromUserId; top_users: Select three users with highest received_counts; final_stats: Join top_users with given_counts and Users to return username, received and given totals","distinct_votes: Deduplicate ForumMessageVotes to unique From-To user pairs representing one upvote; received_counts: Aggregate distinct_votes to count upvotes received per ToUserId; given_counts: Aggregate distinct_votes to count upvotes given per FromUserId; top_users: Select three users with highest received_counts; final_stats: Join top_users with given_counts and Users to return username, received and given totals","{""target_db"": ""META_KAGGLE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:32:02
sf_bq370,"How many customers have orders and invoices that match at the line-item level and, when aggregated, result in each customer having an equal count of orders and invoices as well as an identical total value for the orders and invoices?",false,false,true,true,false,azure/o3,,"order_line_totals: Sum quantity*unit_price per OrderID to get order_total with CustomerID; invoice_totals: Aggregate transaction_amount per InvoiceID to get invoice_total with OrderID and CustomerID; matched_order_invoice: Join order_line_totals to invoice_totals on OrderID where totals and customer match; customer_level_sums: Summarize matched rows per CustomerID with order_count, invoice_count, orders_value, invoices_value; qualified_customers: Filter customer_level_sums where counts and totals are equal; customer_match_count: Return total number of qualified customers","order_line_totals: Sum quantity*unit_price per OrderID to get order_total with CustomerID; invoice_totals: Aggregate transaction_amount per InvoiceID to get invoice_total with OrderID and CustomerID; matched_order_invoice: Join order_line_totals to invoice_totals on OrderID where totals and customer match; customer_level_sums: Summarize matched rows per CustomerID with order_count, invoice_count, orders_value, invoices_value; qualified_customers: Filter customer_level_sums where counts and totals are equal; customer_match_count: Return total number of qualified customers","{""target_db"": ""WIDE_WORLD_IMPORTERS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:32:21
sf_bq371,"In the year 2013, considering each invoice’s total value as the product of unit price and quantity and grouping by the quarter (Q1, Q2, Q3, Q4) in which the invoice date occurs, what is the difference between the maximum and minimum average invoice values across these quarters?",false,false,true,true,false,azure/o3,,"invoice_lines: Join invoices with orderlines for 2013, compute line_value quantity*unit_price; invoice_totals: Sum line_value per invoice, retain invoice quarter; quarter_avgs: Compute average invoice_total per quarter; extremes: Select max and min quarterly averages for difference","invoice_lines: Join invoices with orderlines for 2013, compute line_value quantity*unit_price; invoice_totals: Sum line_value per invoice, retain invoice quarter; quarter_avgs: Compute average invoice_total per quarter; extremes: Select max and min quarterly averages for difference","{""target_db"": ""WIDE_WORLD_IMPORTERS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:32:28
sf_bq372,"Among all orders that do not appear in the invoice table, for each customer category calculate the maximum lost order value, then determine which customer category’s maximum lost order value is closest to the overall average of these maximum lost order values across all categories?",false,false,true,true,false,azure/o3,,order_totals: total order value aggregated from orderlines; lost_orders: orders not present in invoices with customer category and value; category_max_values: maximum lost order value per customer category; avg_max_value: overall average of category_max_values values; closest_category: category whose max lost value has minimal difference from overall average,order_totals: total order value aggregated from orderlines; lost_orders: orders not present in invoices with customer category and value; category_max_values: maximum lost order value per customer category; avg_max_value: overall average of category_max_values values; closest_category: category whose max lost value has minimal difference from overall average,"{""target_db"": ""WIDE_WORLD_IMPORTERS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:32:44
sf_bq373,"Using the invoice date to determine each month of the year 2014, and summing the total invoice line amounts for each customer across these months, what is the median of the resulting average monthly spending across all customers?",false,false,true,true,false,azure/o3,,"months_2014: Generate one row per month of 2014 for zero-spend padding; invoices_2014: Select invoices from 2014 with customer and invoice identifiers; line_items_2014: Join customer transactions to 2014 invoices to capture line amounts and months; monthly_totals: Sum line amounts per customer and month, left joining months_2014 to include zero spends; customer_avg_monthly: Calculate average monthly spend per customer across 12 months; median_avg_spend: Compute median of customers' average monthly spending","months_2014: Generate one row per month of 2014 for zero-spend padding; invoices_2014: Select invoices from 2014 with customer and invoice identifiers; line_items_2014: Join customer transactions to 2014 invoices to capture line amounts and months; monthly_totals: Sum line amounts per customer and month, left joining months_2014 to include zero spends; customer_avg_monthly: Calculate average monthly spend per customer across 12 months; median_avg_spend: Compute median of customers' average monthly spending","{""target_db"": ""WIDE_WORLD_IMPORTERS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:33:29
sf_bq160,"Please provide the creation date, title, parent forum title, reply count, distinct user replies count, total upvotes, and total views for the earliest five forum topics that belong to any sub-forum under the parent forum titled ""General"". The reply count should be calculated as the total number of messages associated with each topic, and the distinct user replies count should be the number of unique users who have posted messages in the topic. The upvotes should be calculated as the total number of upvotes on all messages within each topic. If any values are missing or None, please treat them as zero",false,false,true,true,false,azure/o3,,"general_parent: select Id for forum titled 'General'; sub_forums: list forum Ids with ParentForumId = general_parent; topics_in_scope: topics under sub_forums with creation date title views; message_agg: per-topic reply count and distinct posting users; vote_agg: per-topic total upvotes via message votes; topic_metrics: combine topics_in_scope, message_agg, vote_agg, coalescing nulls","general_parent: select Id for forum titled 'General'; sub_forums: list forum Ids with ParentForumId = general_parent; topics_in_scope: topics under sub_forums with creation date title views; message_agg: per-topic reply count and distinct posting users; vote_agg: per-topic total upvotes via message votes; topic_metrics: combine topics_in_scope, message_agg, vote_agg, coalescing nulls","{""target_db"": ""META_KAGGLE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:33:44
sf_bq167,"Identify the pair of Kaggle users involved in ForumMessageVotes such that one user has given the other the greatest distinct number of upvotes, then also display how many upvotes that recipient returned. Present the usernames of both users, the total distinct upvotes one received from the other, and the upvotes they gave back, sorting by the highest received count and then by the highest given count, and show only the top result.",false,false,true,true,false,azure/o3,,"raw_votes: Distinct (from_user, to_user, message_id) upvote rows from ForumMessageVotes; pair_vote_counts: Aggregate raw_votes to total distinct upvotes per user pair; ranked_pairs: Add row_number ordering by received upvotes desc to identify top pair; reciprocal_votes: Calculate upvotes the recipient gave back to original giver for top pair; named_result: Join ranked_pairs and reciprocal_votes with Users to fetch usernames for output","raw_votes: Distinct (from_user, to_user, message_id) upvote rows from ForumMessageVotes; pair_vote_counts: Aggregate raw_votes to total distinct upvotes per user pair; ranked_pairs: Add row_number ordering by received upvotes desc to identify top pair; reciprocal_votes: Calculate upvotes the recipient gave back to original giver for top pair; named_result: Join ranked_pairs and reciprocal_votes with Users to fetch usernames for output","{""target_db"": ""META_KAGGLE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:34:01
sf_bq171,"Whose Forum message upvotes are closest to the average in 2019? If there’s a tie, tell me the one with the alphabetically first username.",false,false,true,true,false,azure/o3,,"messages_2019: Filter ForumMessages where PostDate in 2019, returning Id and PostUserId; votes_per_message: Aggregate ForumMessageVotes counting rows per ForumMessageId; message_upvotes: Left join messages_2019 with votes_per_message to get upvote_count per message, default zero; avg_upvotes: Compute overall average upvote_count from message_upvotes; ranked_candidates: Join message_upvotes to USERS, calculate abs difference to average, rank by difference then username","messages_2019: Filter ForumMessages where PostDate in 2019, returning Id and PostUserId; votes_per_message: Aggregate ForumMessageVotes counting rows per ForumMessageId; message_upvotes: Left join messages_2019 with votes_per_message to get upvote_count per message, default zero; avg_upvotes: Compute overall average upvote_count from message_upvotes; ranked_candidates: Join message_upvotes to USERS, calculate abs difference to average, rank by difference then username","{""target_db"": ""META_KAGGLE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:34:33
sf_bq118,"Among individuals identified as white, how much higher is the average number of deaths from ICD-10 codes whose descriptions contain the word “discharge” (specifically excluding “Urethral discharge,” “Discharge of firework,” and “Legal intervention involving firearm discharge”) compared to the average number of deaths from ICD-10 codes whose descriptions contain the word “vehicle,” when aggregated by age groups?",false,false,true,true,false,azure/o3,,"discharge_codes: ICD10 codes with 'discharge' description excluding specified phrases; vehicle_codes: ICD10 codes with 'vehicle' in description; white_deaths: Death records where race is white, joined to ICD descriptions; categorized_deaths: White deaths classified as discharge or vehicle based on code lists; age_group_totals: Count deaths per age group and category; age_group_comparison: Compute difference between discharge and vehicle counts per age group","discharge_codes: ICD10 codes with 'discharge' description excluding specified phrases; vehicle_codes: ICD10 codes with 'vehicle' in description; white_deaths: Death records where race is white, joined to ICD descriptions; categorized_deaths: White deaths classified as discharge or vehicle based on code lists; age_group_totals: Count deaths per age group and category; age_group_comparison: Compute difference between discharge and vehicle counts per age group","{""target_db"": ""DEATH"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:34:57
sf_bq072,"Please provide, for each age from 12 through 18 (inclusive), the total number of deaths and the number of deaths among individuals identified as Black (based on race descriptions containing the word ‘black’), specifically for deaths associated with ICD-10 codes whose descriptions include the word ‘vehicle’ and for deaths associated with ICD-10 codes whose descriptions include the word ‘firearm.’ Use the EntityAxisConditions table to determine which ICD-10 codes were involved in each death, rather than joining ICD-10 code information directly on the death records.",false,false,true,true,false,azure/o3,,"age_filtered_deaths: Death records aged 12–18 with race id; vehicle_firearm_codes: ICD10 codes whose descriptions include ""vehicle"" or ""firearm"" plus cause_type flag; death_cause_matches: Join age_filtered_deaths to EntityAxisConditions then vehicle_firearm_codes for relevant deaths; race_classified_deaths: Mark is_black when associated race description contains ""black""; age_cause_counts: Aggregate by age and cause_type, counting total and black deaths","age_filtered_deaths: Death records aged 12–18 with race id; vehicle_firearm_codes: ICD10 codes whose descriptions include ""vehicle"" or ""firearm"" plus cause_type flag; death_cause_matches: Join age_filtered_deaths to EntityAxisConditions then vehicle_firearm_codes for relevant deaths; race_classified_deaths: Mark is_black when associated race description contains ""black""; age_cause_counts: Aggregate by age and cause_type, counting total and black deaths","{""target_db"": ""DEATH"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:35:18
sf001,"Assuming today is April 1, 2024, I would like to know the daily snowfall amounts greater than 6 inches for each U.S. postal code during the week ending after the first two full weeks of the previous year. Show the postal code, date, and snowfall amount.",false,false,true,true,false,azure/o3,,"prev_year_week: Derive start and end dates for the week after first two complete weeks of prior year; snowfall_week: Filter HISTORY_DAY rows to that date range with snowfall > 6 inches; ordered_results: Select postal_code, date_valid_std, tot_snowfall_in and order by postal_code, date","prev_year_week: Derive start and end dates for the week after first two complete weeks of prior year; snowfall_week: Filter HISTORY_DAY rows to that date range with snowfall > 6 inches; ordered_results: Select postal_code, date_valid_std, tot_snowfall_in and order by postal_code, date","{""target_db"": ""GLOBAL_WEATHER__CLIMATE_DATA_FOR_BI"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:35:58
sf003,"For each year from 2015 to 2020, which Census Zip Code Tabulation Area had the second-highest annual population growth rate? Include only areas with a population estimate of at least 25,000 people in that year (based on 5-Year American Community Survey estimates). For each year, provide the zip code, state abbreviation, and the annual growth rate percentage.",false,false,true,true,false,azure/o3,,"annual_pop: Extract 2014-2020 ACS total population by ZCTA with year; yoy_growth: Compute 2015-2020 year-over-year population growth percentage per ZCTA; eligible_growth: Filter yoy results where current-year population ≥25,000; ranked_growth: Rank ZCTAs by growth_rate descending within each year; second_highest: Select rank = 2 entries per year; add_state_info: Join second-highest ZCTAs to geography table for state abbreviation and zip code","annual_pop: Extract 2014-2020 ACS total population by ZCTA with year; yoy_growth: Compute 2015-2020 year-over-year population growth percentage per ZCTA; eligible_growth: Filter yoy results where current-year population ≥25,000; ranked_growth: Rank ZCTAs by growth_rate descending within each year; second_highest: Select rank = 2 entries per year; add_state_info: Join second-highest ZCTAs to geography table for state abbreviation and zip code","{""target_db"": ""GLOBAL_GOVERNMENT"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:36:11
sf002,"As of December 31, 2022, list the top 10 active banks with assets exceeding $10 billion, ranked by the highest percentage of uninsured assets, where the percentage is calculated as one minus the value of the '% Insured (Estimated)' variable from quarterly estimates. Provide the names of these banks and their respective percentages of uninsured assets.",false,false,true,true,false,azure/o3,,"q4_data: Select 2022-12-31 timeseries rows for 'Total Assets' and '% Insured (Estimated)'; assets_cte: Aggregate total asset value per bank id from q4_data; insured_cte: Extract insured percentage per bank id from q4_data; bank_metrics: Join assets_cte and insured_cte, compute uninsured_pct as 1 minus insured percentage; active_top10: Join bank_metrics with entities, filter active, assets>10B, order by uninsured_pct desc, limit 10","q4_data: Select 2022-12-31 timeseries rows for 'Total Assets' and '% Insured (Estimated)'; assets_cte: Aggregate total asset value per bank id from q4_data; insured_cte: Extract insured percentage per bank id from q4_data; bank_metrics: Join assets_cte and insured_cte, compute uninsured_pct as 1 minus insured percentage; active_top10: Join bank_metrics with entities, filter active, assets>10B, order by uninsured_pct desc, limit 10","{""target_db"": ""FINANCE__ECONOMICS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:36:31
sf044,"What was the percentage change in post-market close prices for the Magnificent 7 tech companies from January 1 to June 30, 2024?",false,false,true,true,false,azure/o3,,magnificent_7_companies: filter COMPANY_INDEX for the seven tech firms and extract primary tickers; post_close_window: select post-market close prices for those tickers from 2024-01-01 to 2024-06-30; boundary_prices: capture each ticker's price on Jan 1 and Jun 30; pct_change_calc: compute percentage change between boundary prices per ticker; ordered_results: join company names and sort by highest percentage change,magnificent_7_companies: filter COMPANY_INDEX for the seven tech firms and extract primary tickers; post_close_window: select post-market close prices for those tickers from 2024-01-01 to 2024-06-30; boundary_prices: capture each ticker's price on Jan 1 and Jun 30; pct_change_calc: compute percentage change between boundary prices per ticker; ordered_results: join company names and sort by highest percentage change,"{""target_db"": ""FINANCE__ECONOMICS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:36:53
sf006,"For each U.S. state, find how the number of active financial branch entities has changed from March 1, 2020, to December 31, 2021. An entity is considered active on a specific date if its start date is on or before that date and its end date is either null or on or after that date. For each state, calculate the number of entities active on March 1, 2020, the number of entities active on December 31, 2021, and the percentage change in these counts",false,false,true,true,false,azure/o3,,"branch_base: select id, state_abbreviation, start_date, end_date from branch table; active_march2020: count branches active on 2020-03-01 per state; active_dec2021: count branches active on 2021-12-31 per state; state_change: merge period counts by state and calculate absolute and percentage change","branch_base: select id, state_abbreviation, start_date, end_date from branch table; active_march2020: count branches active on 2020-03-01 per state; active_dec2021: count branches active on 2021-12-31 per state; state_change: merge period counts by state and calculate absolute and percentage change","{""target_db"": ""FINANCE__ECONOMICS"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:36:58
sf008,"Determine the percentage change in gross income inflow and the seasonally-adjusted purchase-only home price index for the Phoenix-Mesa-Scottsdale, AZ Metro Area from January 1, 2023, to December 31, 2023. Gross income inflow refers to the total adjusted gross income from all financial entities within the specified metro area",false,false,true,true,false,azure/o3,,geo_phx: Get GEO_ID for Phoenix-Mesa-Scottsdale AZ metro area; gross_income_2023: Select Phoenix total adjusted gross income values for 2023; income_change: Calculate gross income percent change Jan 1 2023 vs Dec 31 2023; hpi_2023: Select seasonally-adjusted purchase-only home price index for Phoenix in 2023; hpi_change: Calculate home price index percent change Jan 1 2023 vs Dec 31 2023; final_metrics: Combine gross income and home price percent changes into one row,geo_phx: Get GEO_ID for Phoenix-Mesa-Scottsdale AZ metro area; gross_income_2023: Select Phoenix total adjusted gross income values for 2023; income_change: Calculate gross income percent change Jan 1 2023 vs Dec 31 2023; hpi_2023: Select seasonally-adjusted purchase-only home price index for Phoenix in 2023; hpi_change: Calculate home price index percent change Jan 1 2023 vs Dec 31 2023; final_metrics: Combine gross income and home price percent changes into one row,"{""target_db"": ""US_REAL_ESTATE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:37:16
sf010,"What are the cumulative ratios of mortgages near default in California for each recorded date in 2023, including those that are 90 to 180 days past due, in forbearance, or undergoing foreclosure, bankruptcy, or deed-in-lieu processes?",false,false,true,true,false,azure/o3,,"attr_vars: Identify variable codes for 90–180 day delinquent, forbearance, foreclosure, bankruptcy, deed-in-lieu, and total loans; ca_timeseries: Join timeseries with attr_vars, filter GEO_ID for California and 2023 dates; near_default_daily: Sum distress variable values per date to get near-default count; total_daily: Select total loan values per date for California; ratio_daily: Compute near-default count divided by total loans per date; cumulative_ratio: Calculate running cumulative ratio across 2023 dates for final output","attr_vars: Identify variable codes for 90–180 day delinquent, forbearance, foreclosure, bankruptcy, deed-in-lieu, and total loans; ca_timeseries: Join timeseries with attr_vars, filter GEO_ID for California and 2023 dates; near_default_daily: Sum distress variable values per date to get near-default count; total_daily: Select total loan values per date for California; ratio_daily: Compute near-default count divided by total loans per date; cumulative_ratio: Calculate running cumulative ratio across 2023 dates for final output","{""target_db"": ""US_REAL_ESTATE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:37:37
sf037,"How can we find the shortest straight-line distance in miles between each 'The Home Depot' store and its nearest 'Lowe's Home Improvement' location? Using the US_REAL_ESTATE.CYBERSYN database, join the point_of_interest_index table with point_of_interest_addresses_relationships and us_addresses tables to get geographic coordinates. For each 'The Home Depot' location (identified by its poi_id), calculate its distance to all 'Lowe's Home Improvement' stores using ST_DISTANCE and ST_MAKEPOINT functions, convert the distance from meters to miles (dividing by 1609), and return only the record with the minimum distance for each 'The Home Depot' store using QUALIFY with ROW_NUMBER().",false,false,true,true,false,azure/o3,,"poi_coords: Join poi index, address relationships, and us_addresses to attach latitude and longitude to every poi_id; home_depot_stores: Select The Home Depot rows from poi_coords with poi_id, name, lat, lon; lowes_stores: Select Lowes Home Improvement rows from poi_coords with poi_id, name, lat, lon; hd_lowes_distances: Cross join home_depot_stores to lowes_stores, compute ST_DISTANCE in meters then divide by 1609 as distance_miles; nearest_lowes: Assign row_number over distance per home_depot poi_id and keep the nearest Lowes with distance_miles","poi_coords: Join poi index, address relationships, and us_addresses to attach latitude and longitude to every poi_id; home_depot_stores: Select The Home Depot rows from poi_coords with poi_id, name, lat, lon; lowes_stores: Select Lowes Home Improvement rows from poi_coords with poi_id, name, lat, lon; hd_lowes_distances: Cross join home_depot_stores to lowes_stores, compute ST_DISTANCE in meters then divide by 1609 as distance_miles; nearest_lowes: Assign row_number over distance per home_depot poi_id and keep the nearest Lowes with distance_miles","{""target_db"": ""US_REAL_ESTATE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:37:55
sf012,"Using data from the FEMA National Flood Insurance Program Claim Index, for each year from 2010 through 2019, what were the total building damage amounts and total contents damage amounts reported under the National Flood Insurance Program for the NFIP community named 'City Of New York,' grouped by each year of loss?",false,false,true,true,false,azure/o3,,"raw_claims: select needed loss date, community, building and contents damage columns; nyc_filtered: keep rows for 'City Of New York' with loss dates 2010-2019; yearly_totals: group by loss year and sum building_damage_amount and contents_damage_amount","raw_claims: select needed loss date, community, building and contents damage columns; nyc_filtered: keep rows for 'City Of New York' with loss dates 2010-2019; yearly_totals: group by loss year and sum building_damage_amount and contents_damage_amount","{""target_db"": ""WEATHER__ENVIRONMENT"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:38:07
sf018,"Examine user engagement with push notifications within a specified one-hour window on June 1, 2023.",false,false,true,true,true,azure/o3,,"send_events_hour: filter push send events for 2023-06-01 08:00–09:00, selecting user, device, app, campaign, send_id; open_events_hour: filter push open events within window, capturing user and campaign identifiers; ios_fg_events_hour: isolate iOS foreground opens during window for engagement context; open_shared_hour: extract shared slide-action opens in window with key identifiers; engagement_summary: join hourly CTEs to compute per-campaign totals and unique users for sends, opens, foreground opens, and shared opens","send_events_hour: filter push send events for 2023-06-01 08:00–09:00, selecting user, device, app, campaign, send_id; open_events_hour: filter push open events within window, capturing user and campaign identifiers; ios_fg_events_hour: isolate iOS foreground opens during window for engagement context; open_shared_hour: extract shared slide-action opens in window with key identifiers; engagement_summary: join hourly CTEs to compute per-campaign totals and unique users for sends, opens, foreground opens, and shared opens","{""target_db"": ""BRAZE_USER_EVENT_DEMO_DATASET"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:38:16
sf035,"How many unique users started sessions each day within each app group between June 1, 2023, and June 7, 2023? Also show the app group ID and the start day of the session.",false,false,true,true,false,azure/o3,,"raw_first_sessions: select first-session events between 2023-06-01 and 2023-06-07; distinct_user_day: isolate unique user per app_group per session_date; daily_counts: aggregate distinct_user_day to get user_count by app_group and session_date; ordered_results: order daily_counts by app_group_id, session_date ascending","raw_first_sessions: select first-session events between 2023-06-01 and 2023-06-07; distinct_user_day: isolate unique user per app_group per session_date; daily_counts: aggregate distinct_user_day to get user_count by app_group and session_date; ordered_results: order daily_counts by app_group_id, session_date ascending","{""target_db"": ""BRAZE_USER_EVENT_DEMO_DATASET"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:38:30
sf029,"Generate a daily detailed sales report for each product under the 'Manufacturing' distributor view, covering the 30 days leading up to February 6, 2022, by joining the sales, traffic, inventory, and net PPM data on date, ASIN, program, period, and distributor_view. The report must include total ordered units, ordered revenue, average selling price, glance views, conversion rate, shipped units, shipped revenue, average net PPM, average procurable product OOS, total on-hand units and value, net received units and value, open purchase order quantities, unfilled customer ordered units, and average vendor confirmation rate, receive fill rate, sell-through rate, and vendor lead time.",false,false,true,true,false,azure/o3,,"date_span: Build 30-day calendar ending 2022-02-06 for consistent joins; sales_daily: Manufacturing sales filtered to date_span, aggregating ordered/shipped units and revenue by date, ASIN, program; traffic_daily: Manufacturing traffic filtered to date_span, summing glance views and computing conversion rate by date, ASIN, program; inventory_daily: Manufacturing inventory filtered to date_span, aggregating on-hand units/value, OOS%, open PO qty, net received, vendor metrics by date, ASIN, program; ppm_daily: Manufacturing net_ppm filtered to date_span, calculating average net PPM by date, ASIN, program; final_report: Join calendar with all aggregates on date, ASIN, program to output comprehensive daily product report","date_span: Build 30-day calendar ending 2022-02-06 for consistent joins; sales_daily: Manufacturing sales filtered to date_span, aggregating ordered/shipped units and revenue by date, ASIN, program; traffic_daily: Manufacturing traffic filtered to date_span, summing glance views and computing conversion rate by date, ASIN, program; inventory_daily: Manufacturing inventory filtered to date_span, aggregating on-hand units/value, OOS%, open PO qty, net received, vendor metrics by date, ASIN, program; ppm_daily: Manufacturing net_ppm filtered to date_span, calculating average net PPM by date, ASIN, program; final_report: Join calendar with all aggregates on date, ASIN, program to output comprehensive daily product report","{""target_db"": ""AMAZON_VENDOR_ANALYTICS__SAMPLE_DATASET"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:38:49
sf040,"Find the top 10 northernmost addresses in Florida's largest zip code area. What are their address numbers, street names, and types?",false,false,true,true,false,azure/o3,,fl_addresses: Florida-only records; zip_counts: count addresses per zip; largest_zip: zip with maximum address count; zip_addresses: addresses in largest zip; ranked_addresses: top 10 addresses ordered by descending latitude,fl_addresses: Florida-only records; zip_counts: count addresses per zip; largest_zip: zip with maximum address count; zip_addresses: addresses in largest zip; ranked_addresses: top 10 addresses ordered by descending latitude,"{""target_db"": ""US_ADDRESSES__POI"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:39:07
sf009,"A real estate company needs a detailed side-by-side comparison of buildings in Amsterdam and Rotterdam. They require a report showing each building class and subclass, with the total surface area (in square meters) and the total number of buildings for each classification category in both cities. The data should be organized by building class and subclass in ascending order, with Amsterdam and Rotterdam statistics presented in parallel columns to facilitate direct comparison. Can you generate this comprehensive building classification comparison report?",false,false,true,true,false,azure/o3,,"target_cities: select Amsterdam and Rotterdam city administrative boundaries; city_buildings: join buildings to target cities via spatial/quadkey, keep class, subclass, surface area, city; stats_by_city_class: aggregate building count and total surface per city, class, subclass; pivot_comparison: pivot aggregated stats into Amsterdam and Rotterdam side-by-side columns; ordered_result: order pivoted output by class and subclass ascending for final report","target_cities: select Amsterdam and Rotterdam city administrative boundaries; city_buildings: join buildings to target cities via spatial/quadkey, keep class, subclass, surface area, city; stats_by_city_class: aggregate building count and total surface per city, class, subclass; pivot_comparison: pivot aggregated stats into Amsterdam and Rotterdam side-by-side columns; ordered_result: order pivoted output by class and subclass ascending for final report","{""target_db"": ""NETHERLANDS_OPEN_MAP_DATA"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:39:30
sf013,"Compare the total road lengths in Amsterdam and Rotterdam by creating a side-by-side analysis of both cities. For each combination of road class and subclass, calculate the total length of roads (in meters) specifically for QUADKEY segments '12020210' and '12020211'. Present the results with columns for class, subclass, Amsterdam's road lengths, and Rotterdam's road lengths.",false,false,true,true,false,azure/o3,,"selected_roads: Filter V_ROAD for quadkeys 12020210 and 12020211, keeping class, subclass, length_m, municipality; city_length_totals: Sum length_m by class, subclass, municipality for Amsterdam and Rotterdam; pivoted_lengths: Pivot/join city totals into columns length_amsterdam and length_rotterdam for final output","selected_roads: Filter V_ROAD for quadkeys 12020210 and 12020211, keeping class, subclass, length_m, municipality; city_length_totals: Sum length_m by class, subclass, municipality for Amsterdam and Rotterdam; pivoted_lengths: Pivot/join city totals into columns length_amsterdam and length_rotterdam for final output","{""target_db"": ""NETHERLANDS_OPEN_MAP_DATA"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:39:50
sf041,"Produce a report for ERCOT on October 1, 2022, that combines hourly data on day-ahead and real-time prices from node ID 10000697078, load forecasts (datatypeid 19060) and actual loads, plus wind (forecast datatypeid 9285, actual datatypeid 16) and solar (forecast datatypeid 662, actual datatypeid 650) generation forecasts and actuals from object ID 10000712973. This report should include time zone alignments, peak classifications, and net load calculations, providing insights into daily operational dynamics and efficiency.",false,false,true,true,true,azure/o3,,"price_hrs: Hourly day-ahead and real-time prices for node 10000697078 on 2022-10-01, converted to common timezone; load_hrs: Hourly load forecast (datatype 19060) and actual load for object 10000712973, unified timeline; wind_hrs: Hourly wind generation forecast (datatype 9285) and actual (datatype 16) for object 10000712973; solar_hrs: Hourly solar generation forecast (datatype 662) and actual (datatype 650) for object 10000712973; peak_flags: Peak/offpeak and weekday/weekend indicators from ISO_MARKET_TIMES_SAMPLE, with local and UTC timestamps; combined_metrics: Merge price, load, wind, solar and peak flags on hour; net_load_report: Compute forecast and real-time net load, output chronologically ordered report","price_hrs: Hourly day-ahead and real-time prices for node 10000697078 on 2022-10-01, converted to common timezone; load_hrs: Hourly load forecast (datatype 19060) and actual load for object 10000712973, unified timeline; wind_hrs: Hourly wind generation forecast (datatype 9285) and actual (datatype 16) for object 10000712973; solar_hrs: Hourly solar generation forecast (datatype 662) and actual (datatype 650) for object 10000712973; peak_flags: Peak/offpeak and weekday/weekend indicators from ISO_MARKET_TIMES_SAMPLE, with local and UTC timestamps; combined_metrics: Merge price, load, wind, solar and peak flags on hour; net_load_report: Compute forecast and real-time net load, output chronologically ordered report","{""target_db"": ""YES_ENERGY__SAMPLE_DATA"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:40:14
sf011,"Determine the population distribution within each block group relative to its census tract in New York State using 2021 ACS data. Include block group ID, census value, state county tract ID, total tract population, and the population ratio of each block group.",false,false,true,true,false,azure/o3,,ny_block_groups: select New York State block groups with BlockGroupID and StateCountyTractID; total_pop_metric: retrieve MetricID for 2021 total population measure; bg_pop_2021: get 2021 population per NY block group via MetricID join; tract_pop_2021: sum bg_pop_2021 by StateCountyTractID for tract totals; bg_tract_distribution: join bg_pop_2021 to tract_pop_2021 and calculate block-group share of tract population,ny_block_groups: select New York State block groups with BlockGroupID and StateCountyTractID; total_pop_metric: retrieve MetricID for 2021 total population measure; bg_pop_2021: get 2021 population per NY block group via MetricID join; tract_pop_2021: sum bg_pop_2021 by StateCountyTractID for tract totals; bg_tract_distribution: join bg_pop_2021 to tract_pop_2021 and calculate block-group share of tract population,"{""target_db"": ""CENSUS_GALAXY__ZIP_CODE_TO_BLOCK_GROUP_SAMPLE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:40:26
sf014,"What is the New York State ZIP code with the highest number of commuters traveling over one hour, according to 2021 ACS data? Include the zip code, the total commuters, state benchmark for this duration, and state population.",false,false,true,true,false,azure/o3,,target_metric: isolate MetricID for commuters traveling 60+ minutes to work; ny_zip_commuters: NY ZIP-level commuter counts for target metric; top_zip: highest commuter-count ZIP via descending rank; ny_state_benchmark: state benchmark value and total population for NY,target_metric: isolate MetricID for commuters traveling 60+ minutes to work; ny_zip_commuters: NY ZIP-level commuter counts for target metric; top_zip: highest commuter-count ZIP via descending rank; ny_state_benchmark: state benchmark value and total population for NY,"{""target_db"": ""CENSUS_GALAXY__AIML_MODEL_DATA_ENRICHMENT_SAMPLE"", ""candidates_total"": 42, ""same_db_total"": 0, ""used_same_db_pool"": ""true"", ""chosen_ids"": """"}",2025-10-29T19:40:41
